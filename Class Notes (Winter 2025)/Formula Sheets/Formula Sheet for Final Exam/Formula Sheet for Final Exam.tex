\documentclass{article}
%\documentclass[landscape, 12pt]{report}

% TOP
%\topmargin 0.1in 
%\headheight 0.1in 
%\usepackage{anysize}
%\marginsize{2cm}{2cm}{1cm}{1cm}

%\usepackage[margin=1.00in]{geometry}
\usepackage[margin=0.750in]{geometry}

\usepackage{amssymb,amscd}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage[all]{xy}
%\usepackage{fullpage}
\usepackage[pdftex]{graphicx}
\usepackage{multicol}
\usepackage[mathscr]{eucal}
\usepackage{MnSymbol}
\usepackage{multicol}
%\usepackage{mathabx}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{makecell}

%\usepackage[landscape]{geometry}


%\addtolength{\topmargin}{-0.25in}
%\addtolength{\textheight}{0.25in}
%\addtolength{\leftmargin}{0.25in}


%Command for drawing horizontal lines
%\newcommand{\HRule}{\rule{\linewidth}{0.1mm}}
%\newcommand{\HRule}{\rule{15.5cm}{0.25mm}}
%\newcommand{\HRuleLight}{\rule{15.5cm}{0.1mm}}
\newcommand{\HRule}{\rule{\linewidth}{0.25mm}}
\newcommand{\HRuleLight}{\rule{\linewidth}{0.1mm}}



%My new objects
%***************

\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{property}{Property}
\newtheorem{conjecture}{Conjecture}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{principle}{Principle}


% Custom chi square
%**********************
\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}} % inner command, used by \rchi



% ********************
% *  BEGIN DOCUMENT  *
% ********************

\setlength{\parindent}{0in}



\begin{document}



%   *****
%   Title
%   *****

%\title{
%\vspace{-0.75in}
%\Large
%    \textbf{
%    Department of Mathematics and Statistics    \\
%    University of Guelph                        \\
%    Fall 2014                                 \\
%    \hfill                                      \\
%    \vspace{-0.25cm}
%    STAT*2060: Statistics for Business Decisions                  \\
%    Formula Sheet \vspace{0.5cm}                \\
%    \small
%%    Prepared by \vspace{-0.25cm}                \\
%    \vspace{-0.250cm}
%    Nishan Mudalige}}
\date{}

\title{\vspace{-1.750cm} 
	\Large
	\textbf{
		STA258: Statistics with Applied Probability\\
    		Formula Sheet for Final Exam}
	}

\maketitle

\vspace{-1.75cm}
\HRule

\large

%\thispagestyle{empty}
\pagenumbering{gobble}

\vspace*{-0.50cm}
%********************************************
\section*{Probability Distributions}
%********************************************


\begin{center}
\begin{tabular}{| l | c | c | c | c | c | c |c |c |c |}
    \hline
    Distribution    & Distribution function & Support  &   Mean    &   Variance  & MGF \\
    \hline
    \hfill          &               &           &           &               & \\
    Bernoulli       & $f(x) = p^{x} (1 - p)^{1-x}$                & $x = 0, 1$    &   $p$     &   $p (1 - p)$   & $1 - p + p e^t$ \\
    \hfill          &               &           &           &               & \\
    \hline
    \hfill          &               &           &           &               & \\
    Binomial        & $f(x) = \displaystyle{n \choose x} p^{x} (1 - p)^{n-x}$  & $x = 0, 1, \ldots, n$    &   $np$     &   $n p (1 - p)$   & $(1 - p + p e^t)^n$ \\
    \hfill          &               &           &           &               & \\
    \hfill          &               &           &           &               & \\
    \hline
    \hfill          &               &           &           &               & \\
	Poisson   & $f(x) = \displaystyle\frac{\lambda^x e^{-\lambda}}{x!}$  & $x = 0, 1, 2, \dots$ & $\lambda$ & $\lambda$ & 
	$e^{\lambda(e^t - 1)}$ \\
    \hfill          &               &           &           &               & \\
    \hline
    \hfill          &               &           &           &               & \\
Normal          & $f(x) = \displaystyle\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^{2}}{2\sigma^{2}}}$  & $-\infty \leq x \leq +\infty$ & $\mu$ & $\sigma^{2}$ & $e^{\mu t + \frac{1}{2} \sigma^2 t^2}$ \\
    \hfill          &               &           &           &               & \\
    \hline
    \hfill          &               &           &           &               & \\
Gamma        & $f(x) = \displaystyle\frac{1}{ \Gamma(\alpha)\beta^{\alpha} } x^{\alpha-1} e^{-\frac{x}{\beta}}  $  & $x>0$ & $\alpha\beta$ & $\alpha\beta^2$ & $(1 - \beta t)^{-\alpha}, \,\, t < \frac{1}{\beta}$ \\
    \hfill          &               &           &           &               & \\
    \hline
    \hfill          &               &           &           &               & \\
Chi-Square   & $f(x) = \displaystyle \frac{1}{2^{k/2} \Gamma(k/2)} x^{(k/2) - 1} e^{-x/2} $  & $x>0$ 	& $k$    & $2k$ & $(1 - 2t)^{-k/2}, \,\, t < \frac{1}{2}$ \\
    \hfill          &               &           &           &               & \\
    \hline
%    \hfill          &               &           &           &               & \\
%$t$-Distribution   & $f(x) = \displaystyle\frac{\Gamma\left(\frac{k + 1}{2}\right)}{\sqrt{k \pi} \, \Gamma\left(\frac{k}{2}\right)} \left(1 + \frac{t^2}{k}\right)^{-\frac{k + 1}{2}} $  & $-\infty \leq x \leq +\infty$	& $0$    & $\displaystyle\frac{k}{k-2}, \quad k>2$ & Not defined \\
%    \hfill          &               &           &           &               & \\
%    \hline
\end{tabular}
\end{center}

%\vspace*{0.10cm}
\vspace*{-0.25cm}

\hfill\\
\HRule
\vspace*{-0.250cm}

%*****************************
\section*{Transformations}
%*****************************


%\begin{equation*}
%    \begin{array}{llll}
%        \text{Sample Z-score}           & = \frac{\displaystyle x - \bar{x}}{ \displaystyle s}\\
%    \end{array}
%\end{equation*}

Let $X$ be a normally distributed random variable with a mean $\mu$ and variance $\sigma^2$.
%\begin{equation*}
%    \begin{array}{rlll}
%        \text{$Z-$score for single observations} \quad  & ~=~ \frac{\displaystyle x - \mu }{ \displaystyle \sigma}\\
%    \end{array}
%\end{equation*}
\begin{equation*}
        Z	~=~ \frac{\displaystyle x - \mu }{ \displaystyle \sigma}
\end{equation*}



Let $\bar{x}$ represent the sample mean of $n$ independent observations from a distribution with finite mean $\mu$  
and finite variance $\sigma^2$.
For normal populations or sufficiently large $n$:
\begin{equation*}
        Z ~=~ \frac{\displaystyle \bar{x} - \mu }{ \displaystyle \sigma / \sqrt{n}}
\end{equation*}
%\begin{equation*}
%    \begin{array}{rlll}
%        \text{$Z-$score for averages}  \quad            & ~=~ \frac{\displaystyle \bar{x} - \mu }{ \displaystyle \sigma / \sqrt{n}}\\
%    \end{array}
%\end{equation*}

Let $\bar{x}$ and $s^2$ represent the sample mean and sample variance of $n$ independent observations from a distribution with finite mean $\mu$ and some unknown finite variance.
For normal populations or sufficiently large $n$:
\begin{equation*}
        T ~=~ \frac{\displaystyle \bar{x} - \mu }{ \displaystyle s / \sqrt{n}}
\end{equation*}


%\HRule
%\vspace*{-0.250cm}
%
%%************************************************************
%\section*{Inference Procedures for the Population Mean $\mu$}
%%************************************************************
%
%\subsection*{One-Sample}
%
%%%*****************************************************************
%%\subsubsection*{Inference Procedure for $\mu$ when $\sigma$ is known}
%%%*****************************************************************
%
%\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
%Confidence interval for $\mu$ when $\sigma$ is known:  \quad \quad \quad \quad 
%	&   Confidence interval for $\mu$ when $\sigma$ is unknown:\\
%&   \\
%$ \bar{x} \pm \displaystyle Z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}$
%&
%$ \bar{x} \pm \displaystyle t_{n-1, \alpha / 2} \frac{s}{\sqrt{n}}$
%\end{tabular*}
%%\hfill\\
%%\HRuleLight




\pagebreak
%************************************************************************************************
\section*{Continuity Correction for the Normal Approximation}
%************************************************************************************************

%\begin{table}[h!]
%\centering
%\rowcolors{2}{gray!15}{white} % Alternating row colors
%\begin{tabular}{@{}lll@{}}
%\toprule
%\textbf{Binomial Probability}        & \textbf{Continuity Correction}                & \textbf{Normal Approximation}                                                                 \\ \midrule
%$\displaystyle P(X = x)$             & $\displaystyle P(x - 0.5 \leq X \leq x + 0.5)$ & $\displaystyle P\left(\frac{x - 0.5 - \mu}{\sigma} \leq Z \leq \frac{x + 0.5 - \mu}{\sigma}\right)$ \\[1.00em] 
%$\displaystyle P(X \leq x)$          & $\displaystyle P(X \leq x + 0.5)$              & $\displaystyle P\left(Z \leq \frac{x + 0.5 - \mu}{\sigma}\right)$                                 \\[1.00em] 
%$\displaystyle P(X < x)$             & $\displaystyle P(X \leq x - 0.5)$              & $\displaystyle P\left(Z \leq \frac{x - 0.5 - \mu}{\sigma}\right)$                                 \\[1.00em] 
%$\displaystyle P(X \geq x)$          & $\displaystyle P(X \geq x - 0.5)$              & $\displaystyle P\left(Z \geq \frac{x - 0.5 - \mu}{\sigma}\right)$                                 \\[1.00em] 
%$\displaystyle P(X > x)$             & $\displaystyle P(X \geq x + 0.5)$              & $\displaystyle P\left(Z \geq \frac{x + 0.5 - \mu}{\sigma}\right)$                                 \\[1.00em] 
%$\displaystyle P(a \leq X \leq b)$   & $\displaystyle P(a - 0.5 \leq X \leq b + 0.5)$ & $\displaystyle P\left(\frac{a - 0.5 - \mu}{\sigma} \leq Z \leq \frac{b + 0.5 - \mu}{\sigma}\right)$ \\ \bottomrule
%\end{tabular}
%\end{table}


\begin{center}
\begin{tabular}{| l | c | c | c | c | }
\hline
\textbf{Binomial Probability}        & \textbf{Continuity Correction}                & \textbf{Normal Approximation}\\                                                             
\hline
\hfill	&	&\\
$\displaystyle P(X = x)$             & $\displaystyle P(x - 0.5 \leq X \leq x + 0.5)$ & $\displaystyle P\left(\frac{x - 0.5 - \mu}{\sigma} \leq Z \leq \frac{x + 0.5 - \mu}{\sigma}\right)$ \\[1.00em] 
\hline
\hfill	&	&\\
$\displaystyle P(X \leq x)$          & $\displaystyle P(X \leq x + 0.5)$              & $\displaystyle P\left(Z \leq \frac{x + 0.5 - \mu}{\sigma}\right)$\\[0.75em]  
\hline
\hfill	&	&\\
$\displaystyle P(X < x)$             & $\displaystyle P(X \leq x - 0.5)$              & $\displaystyle P\left(Z \leq \frac{x - 0.5 - \mu}{\sigma}\right)$\\[0.75em] 
\hline
\hfill	&	&\\
$\displaystyle P(X \geq x)$          & $\displaystyle P(X \geq x - 0.5)$              & $\displaystyle P\left(Z \geq \frac{x - 0.5 - \mu}{\sigma}\right)$\\[0.75em]
\hline
\hfill	&	&\\
$\displaystyle P(X > x)$             & $\displaystyle P(X \geq x + 0.5)$              & $\displaystyle P\left(Z \geq \frac{x + 0.5 - \mu}{\sigma}\right)$\\[0.75em] 
\hline
\hfill	&	&\\
$\displaystyle P(a \leq X \leq b)$   & $\displaystyle P(a - 0.5 \leq X \leq b + 0.5)$ & $\displaystyle P\left(\frac{a - 0.5 - \mu}{\sigma} \leq Z \leq \frac{b + 0.5 - \mu}{\sigma}\right)$ \\
\hfill	&	&\\
\hline
\end{tabular}
\end{center}

\hfill\\[-1.50em]

\HRule
%\vspace*{-0.250cm}

\vspace*{-0.250cm}
%************************************************************
\section*{Some Relationships Between Random Variables}
%************************************************************


Let $Z_1, Z_2, \ldots, Z_n \overset{\text{iid}}{\sim} N(0, 1)$. Then
\begin{equation*}
	V = \sum_{i = 1}^{n} Z_{i}^2 \, \sim \, \rchi^2_{n}
\end{equation*}

\HRuleLight\\

Let $X_1, X_2, \ldots, X_n \overset{\text{iid}}{\sim} N(\mu, \sigma^2)$. 
Let $\bar{x}$ and $S^2$ represent the sample mean and variance of $X_1, X_2, \ldots, X_n$ respectively.
Then
\begin{equation*}
	\frac{(n-1)S^2}{\sigma^2}
	= \frac{1}{\sigma^2} \sum_{i = 1}^{n} (X_{i} - \bar{X})^2 \, \sim \, \rchi^2_{n-1}
\end{equation*}

\HRuleLight\\
Let $Z \sim N(0, 1)$ and let $W \sim \chi^2_{n}$. Then
\begin{equation*}
	T = \frac{Z}{ \displaystyle\sqrt{ \frac{W}{n}} }	\, \sim \,	t_{n}
\end{equation*}

\HRuleLight\\

%Let $W_1 \sim \rchi_{w_1}$ and let $W_2 \sim \rchi_{w_2}$ be independent random variables. Then
%\begin{equation*}
%	F = \frac{W_1 / w_1}{W_2 / w_2} \, \sim \, F_{w_1, w_2}
%\end{equation*}
%
%\HRuleLight\\

Let $X_1, X_2, \ldots, X_{n_x} \overset{\text{iid}}{\sim} N(\mu_x, \sigma^2)$ with
sample variance $S^2_x$,
and
let $Y_1, Y_2, \ldots, Y_{n_y} \overset{\text{iid}}{\sim} N(\mu_y, \sigma^2)$ with
sample variance $S^2_y$.
with the $X_i's$ and the $Y_j's$ all being independent.
Then
%\begin{equation*}
%	\frac{n-1}{\sigma^2}S^2_x \sim \rchi_{n_x}
%	\quad\quad \text{and} \quad\quad
%	\frac{n-1}{\sigma^2}S^2_y \sim \rchi_{n_y} \, .
%\end{equation*}
%and further
\begin{equation*}
	F =
	\frac{ \left( \displaystyle\frac{n_x - 1}{\sigma^2} \right) S^2_x/(n_x - 1)}{ \left( \displaystyle\frac{n_y - 1}{\sigma^2} \right) S^2_y/(n_y - 1) } \sim F_{n_x-1, \,\, n_y-1}
\end{equation*}





%\hfill\\
\HRule
%************************************************************
\section*{Inference Procedures for the Population Mean $\mu$}
%************************************************************

\subsection*{One-Sample}

%*****************************************************************
\subsubsection*{Inference Procedure for $\mu$ when $\sigma$ is known}
%*****************************************************************

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $\mu$:  \quad \quad \quad \quad \quad \quad \quad \quad \quad &   To test $H_{0} : \mu = \mu_{0}$, test statistic is:\\
&   \\
$ \bar{x} \pm \displaystyle Z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}$
&
$ Z^{*} =\displaystyle \frac{ \bar{x} - \mu_{0} }{ \sigma / \sqrt{n} }$\\
\end{tabular*}
\hfill\\
\HRuleLight
%***********************************************************************************************
\subsubsection*{Inference Procedure for $\mu$ when $\sigma$ is $\underline{\textbf{not}}$ known}
%***********************************************************************************************

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $\mu$:  \quad \quad \quad \quad \quad \quad \quad \quad \quad &   To test $H_{0} : \mu = \mu_{0}$, test statistic is:\\
&   \\
$\bar{x} \pm \displaystyle t_{(\alpha / 2, \,n-1 )} \frac{s}{\sqrt{n}}$
&
$t^{*} =\displaystyle \frac{ \bar{x} - \mu_{0} }{ s / \sqrt{n} }$\\
\end{tabular*}
%\hfill\\

\hfill\\
\HRuleLight

\subsection*{Two-Sample}

%*******************************************************************************************************************************
\subsubsection*{Inference Procedure for Difference between $\mu_{1}$ and $\mu_{2}$ when $\sigma_{1}$ and $\sigma_{2}$ are known}
%*******************************************************************************************************************************

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $\mu_{1} - \mu_{2}$:    \quad \quad \quad \quad \quad \hskip5px \hskip5px   &   To test $H_{0} : \mu_{1} - \mu_{2} = \mu_{D}$, test statistic is:\\
&   \\
$(\bar{x_{1}} - \bar{x_{2}}) \pm   \displaystyle Z_{\alpha / 2}  \displaystyle\sqrt{\frac{ \sigma_{1}^{2} }{ n_{1} } + \frac{\sigma_{2}^{2}}{ n_{2} }}$
&
$Z^{*} =  \displaystyle \frac{ (\bar{x_{1}} - \bar{x_{2}}) - \mu_{D} }{ \displaystyle\sqrt{\frac{ \sigma^{2}_{1} }{ n_{1} } + \frac{\sigma^{2}_{2}}{ n_{2} }} }$\\
\end{tabular*}
\hfill\\
\HRuleLight
%**********************************************************************************************************************************************************
\subsubsection*{Inference Procedure for Difference between $\mu_{1}$ and $\mu_{2}$ when $\sigma_{1}$ and $\sigma_{2}$ are $\underline{\textbf{not}}$ known}
%**********************************************************************************************************************************************************

$\underline{\emph{\text{Case 1: Unequal Variances}}}$

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}l|c}
Confidence interval for $\mu_{1} - \mu_{2}$:   \quad \quad \quad \quad \quad \quad \quad &   To test $H_{0} : \mu_{1} - \mu_{2} = \mu_{D}$, test statistic is:   \\
&   \\
$\quad \quad \quad ~ ~ (\bar{x_{1}} - \bar{x_{2}}) \pm    \displaystyle t_{( \alpha / 2, ~d )} \displaystyle\sqrt{\frac{ s_{1}^{2} }{ n_{1} } + \frac{s_{2}^{2} }{ n_{2} }} $
&
$t^{*} =  \displaystyle \frac{ (\bar{x_{1}} - \bar{x_{2}}) - \mu_{D} }{ \displaystyle\sqrt{\frac{ s_{1}^{2} }{ n_{1} } + \frac{s_{2}^{2}}{ n_{2} }} } $\\
where $d$ is the smaller of $n_{1} - 1$ and $n_{2} - 1$.
&   \\
\end{tabular*}
\hfill\\
\HRuleLight


\pagebreak
$\underline{\emph{\text{Case 2: Equal Variances}}}$

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $\mu_{1} - \mu_{2}$:    \quad  \quad \quad \quad  \quad  \quad \quad &   To test $H_{0} : \mu_{1} - \mu_{2} = \mu_{D}$, test statistic is:   \\
&   \\
$(\bar{x_{1}} - \bar{x_{2}}) \pm    \displaystyle t_{( \alpha / 2, \,n_{1} + n_{2} - 2 )} 
s_{p} \displaystyle\sqrt{ \bigg(  \frac{1}{n_{1}} + \frac{1}{n_{2}} \bigg)}$
&
$t^{*} =  \displaystyle \frac{ (\bar{x_{1}} - \bar{x_{2}}) - \mu_{D} }{ s_{p} \displaystyle\sqrt{ \bigg( \frac{1}{n_{1}} + \frac{1}{n_{2}} } \bigg)}$
\end{tabular*}

\hfill\\
Pooled Sample Variance:
    \begin{equation*}
        \displaystyle s_{p}^{2} = \frac{(n_{1}-1) s_{1}^{2} + (n_{2}-1) s_{2}^{2} }{ n_{1} + n_{2} - 2 }\\
    \end{equation*}

\HRule

%****************************************************************
\section*{Inference Procedures for the Population Proportion $p$}
%****************************************************************

\subsection*{One-Sample}

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $p$:    \quad  \quad \quad \quad  \quad  \quad \quad \quad \hskip3px \hskip4px \hskip3px &   
To test $H_{0} : p = p_{0}$, test statistic is: \quad \quad \quad \quad \quad \quad  ~\\
&   \\
$\hat{p} \pm \displaystyle Z_{\alpha / 2} \sqrt{ \frac{ \hat{p} (1 - \hat{p})}{n} }$
&
\vspace{-0.5cm} $Z^{*} = \displaystyle \frac{ \hat{p} - p_{0} }{ \sqrt{ \displaystyle \frac{ p_{0} (1 - p_{0})}{n} } }$ 
\end{tabular*}

%\pagebreak

\hfill
\subsection*{Two-Sample}


\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $p_{1} - p_{2}$ \quad\quad\quad\quad\quad\quad \hskip3px \hskip4px \hskip3px  &   
To test $H_{0} : p_{1} - p_{2} = p_{D}$, test statistic is: \quad \quad \quad \quad \\
    &   \\
    $( \hat{p}_{1} - \hat{p}_{2} ) \pm \displaystyle Z_{\alpha / 2} \sqrt{ \frac{ \hat{p}_{1} (1 - \hat{p}_{1})}{n_{1}} + \frac{ \hat{p}_{2} (1 - \hat{p}_{2})}{n_{2}} }$
    &
    $Z^{*} = \displaystyle \frac{ (\hat{p}_{1} -  \hat{p}_{2} ) - p_{D}}{ \sqrt{ \hat{p} (1 - \hat{p}) \bigg( \displaystyle \frac{1}{n_{1}} + \frac{1}{n_{2}} \bigg) }  }$\\
%    &   \\
    &   \hspace{-6.5cm} where \\
    &   $\hat{p} = \displaystyle \frac{ x_{1} + x_{2} }{ n_{1} + n_{2} }$
\end{tabular*}


\hfill\\
\HRule

%**********************************
\section*{ANOVA}
%**********************************

For an analysis of $k$ groups:

\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.5}
%\caption{ANOVA Summary Table}
\begin{tabular}{l | c | c | c | c}
\hline
\textbf{Source}       & \textbf{DF}             & \textbf{SS}             & \textbf{MS}                                             & \textbf{F} \\
\hline
\Gape[1.5em][1.5em]{Treatment}	& $k - 1$	& \emph{SSTrt}   & $\emph{MSTrt} = \dfrac{ \emph{SSTrt} }{k - 1}$ 
							& $F = \dfrac{ \emph{MSTrt} }{ \emph{MSE} }$ \\
\hline
\Gape[1.5em][1.5em]{Error} & $n - k$	& \emph{SSE}    & $\emph{MSE} = \dfrac{ \emph{SSE} }{n - k}$   & --- \\
\hline
Total                 & $n - 1$                 & \emph{SSTotal}     & ---                                                      & --- \\
\hline
\end{tabular}
\label{tab:anova-summary}
\end{table}


\pagebreak



%**********************************
\section*{Simple Linear Regression}
%**********************************

%\begin{equation*}
%    \begin{array}{lll | lll}
%        SS_{xx} & = \displaystyle\sum\limits_{i=1}^n (x_{i} - \bar{x})^{2}  & \quad \quad \quad & \quad \quad \quad & \hat{\beta_{1}}  & = \displaystyle\frac{SS_{xy}}{SS_{xx}}   \\
%        &   &   &  &  & \\
%        SS_{yy} & = \displaystyle\sum\limits_{i=1}^n (y_{i} - \bar{y})^{2}  &  \quad \quad \quad & \quad \quad \quad & \bar{y}    & =  \hat{\beta_{1}} \bar{x} + \hat{\beta_{0}} \\
%        &   &   &  &  & \\
%        SS_{xy} & = \displaystyle\sum\limits_{i=1}^n (x_{i} - \bar{x})(y_{i} - \bar{y})     &   & &  \\
%    \end{array}
%\end{equation*}

\begin{equation*}
%    \begin{array}{rll |  rll  |   lllllll}
	\hspace*{-0.35cm}
	\begin{array}{rll |  rll  |   ll}
        S_{xx} 	& 	= \displaystyle\sum\limits_{i=1}^n (x_{i} - \bar{x})^{2}  
        			& 	\quad	&	\quad 
	S_{yy} 	& = \displaystyle\sum\limits_{i=1}^n (y_{i} - \bar{y})^{2}  
			& 	\quad 	&	\quad 
	S_{xy} 	& = \displaystyle\sum\limits_{i=1}^n (x_{i} - \bar{x})(y_{i} - \bar{y})\\
        		 	& =  \bigg( \displaystyle\sum\limits_{i=1}^n x_{i}^{2} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} \bigg)^{2} }{n}
			& 	\quad	&	\quad 
			& =  \bigg( \displaystyle\sum\limits_{i=1}^n y_{i}^{2} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n y_{i} \bigg)^{2} }{n}
			& 	\quad	&	\quad 
			& =  \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} y_{i} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} \bigg) 
																\bigg( \displaystyle\sum\limits_{i=1}^n y_{i} \bigg)}{n}	\\
%        			\hfill\\
%        			\hfill\\
%        SS_{xx} 	& =  \bigg( \displaystyle\sum\limits_{i=1}^n x_{i}^{2} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} \bigg)^{2} }{n}
%			& 	\quad	&	\quad 
%	SS_{yy} 	& =  \bigg( \displaystyle\sum\limits_{i=1}^n y_{i}^{2} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n y_{i} \bigg)^{2} }{n}
%			& 	\quad	&	\quad 
%	SS_{xy} 	& =  \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} y_{i} \bigg) -  \frac{ \bigg( \displaystyle\sum\limits_{i=1}^n x_{i} \bigg) 
%																\bigg( \displaystyle\sum\limits_{i=1}^n y_{i} \bigg)}{n}	\\
%			&	&	&	&	&	\\
			&	&	&	&	&	\\
        %\hat{\beta_{1}}  & = \displaystyle\frac{SS_{xy}}{SS_{xx}}   & \quad \quad\quad &    \bar{y}    & =\hat{\beta_{1}} \bar{x} + \hat{\beta_{0}}   \\
    \end{array}
\end{equation*}

%\hfill\\

\smallskip
\smallskip

\begin{equation*}
    \begin{array}{rll  rlllllllll}
        \hat{\beta_{1}}  & = \displaystyle\frac{S_{xy}}{S_{xx}}   & \quad \quad\quad &    \bar{y}    & =\hat{\beta_{1}} \bar{x} + \hat{\beta_{0}}   
        & &\\
    \end{array}
\end{equation*}

\smallskip
\smallskip

%\vspace{0.25cm}

%\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c c | c c c}
%    $SS_{xx}$ & = & $\displaystyle\sum\limits_{i=1}^n (x_{i} - \bar{x})^{2}$ & $\hat{\beta_{1}}$  & = & $\displaystyle\frac{SS_{xy}}{SS_{xx}}$
%\end{tabular*}

\HRuleLight

%\vspace{0.25cm}


\begin{equation*}
	\begin{array}{llll}
		\text{Sum Square of Regression }(SSR)\quad	& = \displaystyle \sum_{i=1}^{n} \big( \hat{y}_{i} - \bar{y} \big)^{2}	\\
		\hfill\\
		\hfill\\
		\text{Sum Square Error }(SSE)				& = \displaystyle \sum_{i=1}^{n} \big( y_{i} - \hat{y}_{i} \big)^{2}	
											& = S_{yy} -\hat{\beta}_{1} S_{xy} \\
		\hfill\\
		\hfill\\
		\text{Sum Square Total }SSTotal 			& = \displaystyle \sum_{i=1}^{n} \big( y_{i} - \bar{y} \big)^{2}
	\end{array}
\end{equation*}


\hfill\\
\HRuleLight
\vspace{0.25cm}


\begin{equation*}
    \begin{array}{llll}
        \text{Coefficient of Correlation}               		&   r       	& =	\quad \displaystyle\frac{ S_{xy} }{\sqrt{ S_{xx} S_{yy} } } \\
        \hfill\\
        \text{Coefficient of Determination} \quad \quad 	&   r^{2}   	& =	\quad	\displaystyle \frac{SSR}{SSTotal}	\quad\quad = \quad	1 - \displaystyle\frac{SSE}{SS_{yy}}\\
%        										&		&										\\
%        										&		& =	\quad	1 - \displaystyle\frac{SSE}{SS_{yy}}	\\
    \end{array}
\end{equation*}
\vspace{0.25cm}


\HRuleLight
\hfill\\
\begin{equation*}
    \begin{array}{lllll}
        \text{Residuals}                        			&   e_{i}		& = ~~ y_{i} - \hat{y}_{i} \\
        \hfill\\
        \text{Estimate of Variance} \quad \quad 	&   s^{2}	~ 	& = ~~ \displaystyle\frac{ \displaystyle\sum\limits_{i=1}^n e_{i}^{2} }{ n-2 } 
        		& \quad = ~~ \displaystyle\frac{ \displaystyle\sum\limits_{i=1}^n (y_{i} - \hat{y}_{i})^{2} }{ n-2 } 
		& \quad = ~~ \displaystyle\frac{S_{yy} - \hat{\beta}_{1} S_{xy} }{n-2}\\
        \text{of Random Error}                  &           &
    \end{array}
\end{equation*}
\vspace{0.25cm}

\HRuleLight

%\hfill\\
%********************************************************
\subsection*{Inference Procedures on the Slope $\beta_{1}$}
%********************************************************

%\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
%Confidence interval for $\beta_{1}$:    \hskip2ex \quad \quad  \quad  \quad \quad \quad \quad \quad \quad & \quad \quad   
%To test $H_{0} : \beta_{1} = \beta_{hyp}$, test statistic is: \quad \quad  \quad \quad \quad \quad \\
%&   \\
%$\hat{\beta_{1}} \pm t_{(\alpha / 2, n-2)} \displaystyle \frac{s}{\sqrt{SS_{xx}}}$
%&
%$t^{*} =\displaystyle \frac{ \hat{\beta_{1}} - \beta_{hyp} }{ s / \sqrt{ SS_{xx} } } $
%\end{tabular*}

\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|c}
Confidence interval for $\beta_{1}$:    \hskip2ex \quad \quad  \quad  \quad \quad \quad \quad \quad \quad & \quad \quad   
To test $H_{0} : \beta_{1} = 0$, test statistic is: \quad \quad  \quad \quad \quad \quad \\
&   \\
$\hat{\beta_{1}} \pm t_{(\alpha / 2, n-2)} \displaystyle \frac{s}{\sqrt{S_{xx}}}$
&
$t^{*} =\displaystyle \frac{ \hat{\beta_{1}} }{ s / \sqrt{ S_{xx} } } $
\end{tabular*}

%\hfill\\
%\HRuleLight
%%**************************************
%\subsection*{Inference Procedures for $y$}
%%**************************************
%
%%Confidence interval for the mean of $y$ at $x = x_{p}$: \quad \quad
%%$\hat{y} \pm t_{(\alpha/2, n-2)} s \displaystyle\sqrt{ \frac{1}{n} + \frac{(x_{p} - \bar{x})^{2}}{SS_{xx}} } $\\
%%
%%\hfill\\
%%Prediction interval for an individual value of $y$ at $x = x_{p}$: \quad \quad
%%$\hat{y} \pm t_{(\alpha/2, n-2)} s \displaystyle\sqrt{1 + \frac{1}{n} + \frac{(x_{p} - \bar{x})^{2}}{SS_{xx}} } $\\
%
%
%
%\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}c|l}
%Estimation interval for the mean of $y$ at $x = x_{p}$:
%&
%Prediction interval for an individual value of \quad \quad \quad\\
%&
%$y$ at $x = x_{p}$:  \\
%&  \\
%$\hat{y} \pm t_{(\alpha/2, n-2)} s \displaystyle\sqrt{ \frac{1}{n} + \frac{(x_{p} - \bar{x})^{2}}{SS_{xx}} } $
%&
%\quad \quad \quad $\hat{y} \pm t_{(\alpha/2, n-2)} s \displaystyle\sqrt{1 + \frac{1}{n} + \frac{(x_{p} - \bar{x})^{2}}{SS_{xx}} } $\\
%\end{tabular*}

\end{document} 