\relax 
\let\TR@TitleReference\@firstoftwo
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {0}Overview}{1}{chapter.0}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Descriptive Statistics and an Introduction to R}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Descriptive Statistics}{4}{section.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Visualization of left skew probability distribution}}{7}{figure.caption.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Visualization of right skew probability distribution}}{8}{figure.caption.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Visualization of symmetric probability distribution}}{9}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Graphical Techniques}{10}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Histograms}{10}{subsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Visualization of histograms}}{10}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Visualization of a histogram has a left (or negative) skew probability distribution}}{11}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Visualization of a histogram has a right (or positive) skew probability distribution}}{12}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Visualization of a histogram has a symmetric probability distribution}}{12}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Box-Plots}{12}{subsection.1.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Visualization of a box-plot}}{13}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Visualization of a box-plot with skew and symmetric probability distribution}}{13}{figure.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Introduction to R}{13}{section.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces R-studio first three steps (by following the instructions, you should get this histogram)}}{14}{figure.caption.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces R-studio the forth step(by following the instructions, you should get this histogram)}}{15}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Sampling Distributions Related to a Normal Population}{16}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Normal Distribution}{16}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gamma and Chi-square Distribution}{17}{section.2.2}\protected@file@percent }
\newlabel{eq:gaussian1}{{2.2.1}{18}{Gamma and Chi-square Distribution}{equation.2.1}{}}
\newlabel{eq:gaussian2}{{2.2.2}{18}{Gamma and Chi-square Distribution}{equation.2.2}{}}
\newlabel{eq:gaussian3}{{2.2.3}{18}{Gamma and Chi-square Distribution}{equation.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Student's t-Distribution and F-Distribution}{20}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The Central Limit Theorem}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Procedure of the Central Limit Theorem}}{24}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Normal Approximation to the Binomial Distribution}{26}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{26}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Bernoulli Distribution}{27}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Sampling Distribution of the Sum and MGF Derivation}{29}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Binomial Distribution}{29}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Visualizing the PMF of Binomial Distributions}{30}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces PMF of Binomial distribution with \(n = 10\) and \(p = \frac  {1}{6}\).}}{31}{figure.caption.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces PMF of Binomial distribution with \(n = 50\) and \(p = \frac  {1}{6}\).}}{31}{figure.caption.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces PMF of Binomial distribution with \(n = 100\) and \(p = \frac  {1}{6}\).}}{32}{figure.caption.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces PMF of Binomial distribution with \(n = 300\) and \(p = \frac  {1}{6}\).}}{32}{figure.caption.17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Sampling Distribution of a Sample Proportion and the Normal Approximation}{33}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Binomial distribution with \(n = 300\), \(p = \frac  {1}{6}\) and its Normal approximation.}}{33}{figure.caption.18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Normal Approximation to Binomial}{37}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Continuity Correction}{37}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Law of Large Numbers}{40}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Convergence in Probability}{40}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Weak Law of Large Numbers (WLLN)}{41}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Simulation of running sample mean of Bernoulli(\(p = 0.5\)) trials over time.}}{43}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Simulation of 10 running sample means of Bernoulli(\(p = 0.5\)) trials converging over 100 trials.}}{43}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}One Sample Confidence Intervals on a Mean When the Population Variance is Known}{45}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{45}{section.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Parameter location within the interval.}}{46}{figure.caption.21}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figureVisualization of CI}{{\caption@xref {figureVisualization of CI}{ on input line 115}}{47}{Introduction}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Visualization of a confidence interval on the real number line. The margin of error is abbreviated as $MOE$. The estimator is the centre of the interval. The confidence interval consists of all values between the estimator$- MOE$ and the estimator$+ MOE$.}}{47}{figure.caption.22}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Interpretation}{47}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Confidence Interval for $\mu $ (Known Variance)}{48}{section.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Simulated 95\% confidence intervals for the population mean. Red “X” marks indicate intervals that do not contain the true mean (\( \mu = 0 \)).}}{50}{figure.caption.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces The central area under the standard normal curve with confidence level \( C \).}}{50}{figure.caption.24}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}APPENDIX}{55}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown}{56}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}CIs for \(\mu \)}{56}{section.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Comparison of the standard normal distribution and t-distributions with 2 and 9 degrees of freedom.}}{58}{figure.caption.25}\protected@file@percent }
\newlabel{fig:density-curves}{{7.1}{58}{Comparison of the standard normal distribution and t-distributions with 2 and 9 degrees of freedom}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}One Sample Confidence Intervals On a Proportion}{66}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Sample Size Selection using Confidence Intervals}{69}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
<<<<<<< HEAD
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.1}Empirical Rule}{69}{subsection.9.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Calculating Sample Size for a Confidence Interval on a Mean}{69}{section.9.1}\protected@file@percent }
\newlabel{secSampleSizeCIMean}{{9.1}{69}{Calculating Sample Size for a Confidence Interval on a Mean}{section.9.1}{}}
\newlabel{exSampleSizePharmaceutical}{{9.1}{70}{}{exinn.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Calculating Sample Size for a Confidence Interval on a Proportion}{71}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Two Sample Confidence Interval}{74}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Two Sample Confidence Interval on a Difference of Mean}{74}{section.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Visualization of two-sample confidence interval (Case 1, 2, 3)}}{76}{figure.caption.26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Visualization of the case when $\mu _1 < \mu _2$}}{76}{figure.caption.27}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Visualization of the case when $\mu _1 > \mu _2$}}{77}{figure.caption.28}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Visualization of the case when $\mu _1 = \mu _2$}}{77}{figure.caption.29}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Two Sample Confidence Interval on Paired Data}{79}{section.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces A table of paired data}}{80}{figure.caption.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Visualization of the case when $\bar  {M}_1 < \bar  {M}_2$}}{81}{figure.caption.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Visualization of the case when $\bar  {M}_1 > \bar  {M}_2$}}{81}{figure.caption.32}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Visualization of the case when $\bar  {M}_1 = \bar  {M}_2$}}{81}{figure.caption.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Two Sample Confidence Interval on Proportions}{82}{section.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Visualization of two population of all students from UTSG (left) and UTM (right)}}{82}{figure.caption.34}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Visualization of two selected random sample from UTSG (left) and UTM (right)}}{82}{figure.caption.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.11}{\ignorespaces Visualization of the case when $p_1 > p_2$}}{83}{figure.caption.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.12}{\ignorespaces Visualization of the case when $p_1 < p_2$}}{83}{figure.caption.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.13}{\ignorespaces Visualization of the case when $\hat  {p}_1 = \hat  {p}_2$}}{84}{figure.caption.38}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Two Sample Confidence Interval on Variances}{84}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Introduction to Hypothesis Testing}{86}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:intro-hypothesis}{{11}{86}{Introduction to Hypothesis Testing}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Test of Hypothesis for One Mean}{86}{section.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Right-tailed test: \textit  {p}-value is the area to the right of the test statistic.}}{87}{figure.caption.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces Left-tailed test: \textit  {p}-value is the area to the left of the test statistic.}}{88}{figure.caption.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Two-tailed test: p-value is the total area in both tails beyond $\pm $ test statistic.}}{88}{figure.caption.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Histogram of $z_\star $ values from 10,000 simulations under $H_0$.}}{90}{figure.caption.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces Left-tailed p-value for the test statistic \( z^* = -2.82 \)}}{92}{figure.caption.43}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Test of Hypothesis for One Proportion}{100}{section.11.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces Plot of frequencies from 60 simulations of a fair six-sided die.}}{102}{figure.caption.44}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces PMF when $n=10$ and $p=1/6$}}{104}{figure.caption.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.8}{\ignorespaces PMF when $n=100$ and $p=1/6$}}{104}{figure.caption.46}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.9}{\ignorespaces Simulation: 2000 YouTuber, $n = 100$, and $p = 1/6$}}{105}{figure.caption.47}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.10}{\ignorespaces Simulation vs Theoretical pmf}}{106}{figure.caption.48}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.11}{\ignorespaces Binomial with Normal Approximation}}{107}{figure.caption.49}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Test of Hypothesis for One Variance}{115}{section.11.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.12}{\ignorespaces Right-tailed chi-squared distribution with critical value at 16.919.}}{118}{figure.caption.50}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}One Sample Hypothesis Test on a Proportion and Variance}{119}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}One Sample Hypothesis Test on a Proportion}{119}{section.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces All possible cases of one sample hypothesis test on a proportion ($p$ represents the actual proportion of a population)}}{119}{figure.caption.51}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p > p_0$.}}{120}{figure.caption.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p < p_0$.}}{121}{figure.caption.53}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p \neq  p_0$.}}{121}{figure.caption.54}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}One Sample Hypothesis Tests for a Variance}{122}{section.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces All possible cases of one sample hypothesis test on a variance}}{122}{figure.caption.55}\protected@file@percent }
<<<<<<< HEAD
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Two Sample Hypothesis Test}{124}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Two Sample Hypothesis Test on Paired Data}{124}{section.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces A table of paired data}}{125}{figure.caption.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces All possible cases of two sample hypothesis test on paired data}}{125}{figure.caption.57}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces Data of example 14.1}}{126}{figure.caption.58}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Two Sample Hypothesis Test on Proportions}{126}{section.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces All possible cases of two sample hypothesis test on proportions}}{127}{figure.caption.59}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Two Sample Hypothesis Test on Variances}{129}{section.14.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces All possible cases of two sample hypothesis test on variances}}{130}{figure.caption.60}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Introduction to Simple Linear Regression}{131}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces An illustration of simple linear regression. The blue points are measures of height monthly, and the red line is our SLR model. In this case $m$ is the slope which tells you the rate of change, $b$ is the intercept which may have a special meaning depending on the case.}}{131}{figure.caption.61}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Measures of Linear Relationship}{132}{section.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces An illustration of strong positive correlation ($r_{xy} \approx +1$).}}{133}{figure.caption.62}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.3}{\ignorespaces An illustration of strong negative correlation ($r_{xy} \approx -1$).}}{134}{figure.caption.63}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.4}{\ignorespaces An illustration of no correlation ($r_{xy} \approx 0$).}}{134}{figure.caption.64}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.5}{\ignorespaces Data of example 15.1}}{135}{figure.caption.65}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Least Squares Method}{136}{section.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.6}{\ignorespaces Data of example 15.2}}{137}{figure.caption.66}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Simple Linear Regression}{138}{section.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.7}{\ignorespaces An illustration of a simple linear regression model. The red line is the fitted regression line, and the full black vertical lines represent the residuals (SSE). The data points deviate from the line to show errors clearly. Note that the sum of residuals is necessarily $0$.}}{139}{figure.caption.67}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.8}{\ignorespaces Data of example 15.3}}{141}{figure.caption.68}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.4}SST, SSE and SSR}{142}{section.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.9}{\ignorespaces An illustration of Total Sum of Squares (SST). The blue points represent height measurements over time, the dashed line is the mean height $\bar  {y}$, and the solid black vertical lines represent the squared deviations from the mean (SST components).}}{142}{figure.caption.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.10}{\ignorespaces A simple linear regression illustration with residuals shown. Blue points are observed data, red line is the model, dashed line is the average of $y$, and black lines represent residuals $y_i - \hat  {y_i}$.}}{143}{figure.caption.70}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.11}{\ignorespaces An illustration of simple linear regression. The blue points represent monthly height measurements with added variability. The red line is the fitted simple linear regression model. The dashed line shows the mean of the dependent variable, $\bar  {y}$, and the solid black lines illustrate the deviation of the model's predictions from this mean.}}{144}{figure.caption.71}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.12}{\ignorespaces Visual representation of regression variability. \textbf  {SST} (green) is total variability from the mean, \textbf  {SSR} (pink) is explained variability, and \textbf  {SSE} (orange curly brace) is the residual (unexplained) variability between the observed value $y_i$ and the prediction $\hat  {y}_i$.}}{145}{figure.caption.72}\protected@file@percent }
\gdef \@abspage@last{152}
=======
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Statistical Power}{124}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Statistical Power}{124}{section.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Rejection region for $Z$ with $\alpha = 0.05$}}{126}{figure.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Power curve showing shaded rejection area under $H_A$}}{126}{figure.13.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces \textit  {Power curve for a one-sided test with points at $\mu = 0.52$ and $\mu = 1.1$}}}{126}{figure.caption.56}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Type I and Type II Errors}{127}{section.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Using Power to Determine Sample Size}{129}{section.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Two Sample Hypothesis Tests}{136}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Comparing Means with Independent Samples}{136}{section.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces Structure of Two-Sample Hypothesis Tests}}{136}{figure.caption.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.1}Comparing Two Populations Means: Independent Sampling (Equal Variances Assumed)}{139}{subsection.14.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces Q-Q Plot for Group 1: Interaction with Outsiders}}{142}{figure.caption.58}\protected@file@percent }
\newlabel{fig:qqplot-group1}{{14.2}{142}{Q-Q Plot for Group 1: Interaction with Outsiders}{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces Q-Q Plot for Group 2: Fewer Interactions}}{143}{figure.14.3}\protected@file@percent }
\newlabel{fig:qqplot-group2}{{14.3}{143}{Q-Q Plot for Group 2: Fewer Interactions}{figure.14.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces Boxplot of Success Index by Group}}{143}{figure.14.4}\protected@file@percent }
\newlabel{fig:boxplot-success}{{14.4}{143}{Boxplot of Success Index by Group}{figure.14.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces Boxplot of Success Index by Group using ggplot2}}{144}{figure.caption.59}\protected@file@percent }
\newlabel{fig:boxplot-ggplot}{{14.5}{144}{Boxplot of Success Index by Group using ggplot2}{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.2}Comparing Two Populations Means: Independent Sampling (Unequal Variances Assumed)}{146}{subsection.14.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces Q-Q Plot for Treatment Group}}{149}{figure.caption.60}\protected@file@percent }
\newlabel{fig:qqplot-ggplot}{{14.6}{149}{Q-Q Plot for Treatment Group}{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces Q-Q Plot for Control Group}}{150}{figure.14.7}\protected@file@percent }
\newlabel{fig:qqplot-ggplot}{{14.7}{150}{Q-Q Plot for Control Group}{figure.14.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}The Fold Rule}{153}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Two Sample Hypothesis Test on Paired Data}{153}{section.14.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces A table of paired data}}{154}{figure.caption.61}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces All possible cases of two sample hypothesis test on paired data}}{154}{figure.caption.62}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces Data of example 14.1}}{155}{figure.caption.63}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Two Sample Hypothesis Test on Proportions}{156}{section.14.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces All possible cases of two sample hypothesis test on proportions}}{156}{figure.caption.64}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Two Sample Hypothesis Test on Variances}{159}{section.14.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces All possible cases of two sample hypothesis test on variances}}{159}{figure.caption.65}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Introduction to Simple Linear Regression}{160}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces An illustration of simple linear regression. The blue points are measures of height monthly, and the red line is our SLR model. In this case $m$ is the slope which tells you the rate of change, $b$ is the intercept which may have a special meaning depending on the case.}}{160}{figure.caption.66}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Measures of Linear Relationship}{161}{section.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces An illustration of strong positive correlation ($r_{xy} \approx +1$).}}{162}{figure.caption.67}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.3}{\ignorespaces An illustration of strong negative correlation ($r_{xy} \approx -1$).}}{163}{figure.caption.68}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.4}{\ignorespaces An illustration of no correlation ($r_{xy} \approx 0$).}}{163}{figure.caption.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.5}{\ignorespaces Data of example 15.1}}{164}{figure.caption.70}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Least Squares Method}{165}{section.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.6}{\ignorespaces Data of example 15.2}}{166}{figure.caption.71}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Simple Linear Regression}{167}{section.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.7}{\ignorespaces An illustration of a simple linear regression model. The red line is the fitted regression line, and the full black vertical lines represent the residuals (SSE). The data points deviate from the line to show errors clearly. Note that the sum of residuals is necessarily $0$.}}{168}{figure.caption.72}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.8}{\ignorespaces Data of example 15.3}}{170}{figure.caption.73}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.4}SST, SSE and SSR}{171}{section.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.9}{\ignorespaces An illustration of Total Sum of Squares (SST). The blue points represent height measurements over time, the dashed line is the mean height $\bar  {y}$, and the solid black vertical lines represent the squared deviations from the mean (SST components).}}{171}{figure.caption.74}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.10}{\ignorespaces A simple linear regression illustration with residuals shown. Blue points are observed data, red line is the model, dashed line is the average of $y$, and black lines represent residuals $y_i - \hat  {y_i}$.}}{172}{figure.caption.75}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.11}{\ignorespaces An illustration of simple linear regression. The blue points represent monthly height measurements with added variability. The red line is the fitted simple linear regression model. The dashed line shows the mean of the dependent variable, $\bar  {y}$, and the solid black lines illustrate the deviation of the model's predictions from this mean.}}{173}{figure.caption.76}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.12}{\ignorespaces  Visual representation of regression variability. \textbf  {SST} (green) is total variability from the mean, \textbf  {SSR} (pink) is explained variability, and \textbf  {SSE} (orange curly brace) is the residual (unexplained) variability between the observed value $y_i$ and the prediction $\hat  {y}_i$.}}{174}{figure.caption.77}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Inference for Simple Linear Regression}{175}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {16.1}Inference on Regression}{175}{section.16.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16.1}{\ignorespaces Regression line with normal errors at each $X$}}{176}{figure.caption.78}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16.2}ANOVA Table (ANalysis Of VAriance)}{186}{section.16.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16.2}{\ignorespaces Plot of Price vs Area for Apartments near UTM}}{188}{figure.caption.81}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {16.1}{\ignorespaces Deviation table for computing $\hat  {\beta }_1$ and $\hat  {\beta }_0$}}{189}{table.caption.82}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16.3}Residual Plots}{193}{section.16.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16.3}{\ignorespaces Residual Plots - Good and Bad Examples}}{194}{figure.caption.83}\protected@file@percent }
\gdef \@abspage@last{203}
>>>>>>> origin
=======
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Two Sample Confidence Interval on a Difference of Mean}{68}{section.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Visualization of two-sample confidence interval (Case 1, 2, 3)}}{70}{figure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Visualization of the case when $\mu _1 < \mu _2$}}{70}{figure.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Visualization of the case when $\mu _1 > \mu _2$}}{71}{figure.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Visualization of the case when $\mu _1 = \mu _2$}}{71}{figure.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Two Sample Confidence Interval on Paired Data}{73}{section.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces A table of paired data}}{74}{figure.10.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Visualization of the case when $\bar  {M}_1 < \bar  {M}_2$}}{74}{figure.10.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Visualization of the case when $\bar  {M}_1 > \bar  {M}_2$}}{75}{figure.10.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Visualization of the case when $\bar  {M}_1 = \bar  {M}_2$}}{75}{figure.10.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Two Sample Confidence Interval on Proportions}{75}{section.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Visualization of two population of all students from UTSG (left) and UTM (right)}}{76}{figure.10.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Visualization of two selected random sample from UTSG (left) and UTM (right)}}{76}{figure.10.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.11}{\ignorespaces Visualization of the case when $p_1 > p_2$}}{77}{figure.10.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.12}{\ignorespaces Visualization of the case when $p_1 < p_2$}}{77}{figure.10.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.13}{\ignorespaces Visualization of the case when $\hat  {p}_1 = \hat  {p}_2$}}{77}{figure.10.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Two Sample Confidence Interval on Variances}{78}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}One Sample Hypothesis Test on a Proportion and Variance}{79}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}One Sample Hypothesis Test on a Proportion}{79}{section.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces All possible cases of one sample hypothesis test on a proportion ($p$ represents the actual proportion of a population)}}{79}{figure.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p > p_0$.}}{80}{figure.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p < p_0$.}}{81}{figure.12.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p \neq  p_0$.}}{81}{figure.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}One Sample Hypothesis Tests for a Variance}{82}{section.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces All possible cases of one sample hypothesis test on a variance}}{82}{figure.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Two Sample Hypothesis Test}{84}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Two Sample Hypothesis Test on Paired Data}{84}{section.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces A table of paired data}}{85}{figure.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces All possible cases of two sample hypothesis test on paired data}}{85}{figure.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Two Sample Hypothesis Test on Proportions}{86}{section.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces All possible cases of two sample hypothesis test on proportions}}{86}{figure.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Two Sample Hypothesis Test on Variances}{89}{section.14.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces All possible cases of two sample hypothesis test on variances}}{89}{figure.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Introduction to Simple Linear Regression}{90}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces An illustration of simple linear regression. The blue points are measures of height monthly, and the red line is our SLR model. In this case $m$ is the slope which tells you the rate of change, $b$ is the intercept which may have a special meaning depending on the case.}}{90}{figure.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Measures of Linear Relationship}{91}{section.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces An illustration of strong positive correlation ($r_{xy} \approx +1$).}}{92}{figure.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.3}{\ignorespaces An illustration of strong negative correlation ($r_{xy} \approx -1$).}}{93}{figure.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.4}{\ignorespaces An illustration of no correlation ($r_{xy} \approx 0$).}}{93}{figure.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.5}{\ignorespaces Data of example 15.1}}{94}{figure.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Least Squares Method}{95}{section.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.6}{\ignorespaces Data of example 15.2}}{96}{figure.15.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Simple Linear Regression}{97}{section.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.7}{\ignorespaces An illustration of a simple linear regression model. The red line is the fitted regression line, and the full black vertical lines represent the residuals (SSE). The data points deviate from the line to show errors clearly. Note that the sum of residuals is necessarily $0$.}}{98}{figure.15.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.8}{\ignorespaces Data of example 15.3}}{100}{figure.15.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.4}SST, SSE and SSR}{101}{section.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.9}{\ignorespaces An illustration of Total Sum of Squares (SST). The blue points represent height measurements over time, the dashed line is the mean height $\bar  {y}$, and the solid black vertical lines represent the squared deviations from the mean (SST components).}}{101}{figure.15.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.10}{\ignorespaces A simple linear regression illustration with residuals shown. Blue points are observed data, red line is the model, dashed line is the average of $y$, and black lines represent residuals $y_i - \hat  {y_i}$.}}{102}{figure.15.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.11}{\ignorespaces An illustration of simple linear regression. The blue points represent monthly height measurements with added variability. The red line is the fitted simple linear regression model. The dashed line shows the mean of the dependent variable, $\bar  {y}$, and the solid black lines illustrate the deviation of the model's predictions from this mean.}}{103}{figure.15.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.12}{\ignorespaces Visual representation of regression variability. \textbf  {SST} (green) is total variability from the mean, \textbf  {SSR} (pink) is explained variability, and \textbf  {SSE} (orange curly brace) is the residual (unexplained) variability between the observed value $y_i$ and the prediction $\hat  {y}_i$.}}{104}{figure.15.12}\protected@file@percent }
\gdef \@abspage@last{111}
>>>>>>> BryanImages
