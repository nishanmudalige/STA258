\relax 
\let\TR@TitleReference\@firstoftwo
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {0}Overview}{1}{chapter.0}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Descriptive Statistics and an Introduction to R}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec.matrix}{{1}{2}{Descriptive Statistics and an Introduction to R}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Descriptive Statistics}{4}{section.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces An illustration of a left (negative) skewed distribution.}}{7}{figure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces An illustration of a right (positive) skewed distribution}}{8}{figure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces An illustration of symmetric distribution. Area under this curve on the left hand side of $\mu = 0$ is same as the area on the right hand side under the curve.}}{8}{figure.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces An illustration of the empirical rule.}}{9}{figure.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Graphical Techniques}{10}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Histograms}{10}{subsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces An illustration of histogram.}}{11}{figure.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces An illustration of a histogram to have a left (or negative) skew probability distribution.}}{12}{figure.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces An illustration of a histogram to have a right (or positive) skew probability distribution.}}{12}{figure.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces An illustration of a histogram which has a symmetric probability distribution.}}{13}{figure.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Box-Plots}{13}{subsection.1.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Annotated box-plot with whiskers and potential outliers.}}{13}{figure.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Box-plots showing negative skew, positive skew, and symmetry.}}{14}{figure.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Introduction to R}{14}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Sampling Distributions Related to a Normal Population}{16}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Normal Distribution}{16}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gamma and Chi-square Distribution}{17}{section.2.2}\protected@file@percent }
\newlabel{eq:gaussian1}{{2.2.1}{18}{Gamma and Chi-square Distribution}{equation.2.1}{}}
\newlabel{eq:gaussian2}{{2.2.2}{18}{Gamma and Chi-square Distribution}{equation.2.2}{}}
\newlabel{eq:gaussian3}{{2.2.3}{18}{Gamma and Chi-square Distribution}{equation.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Student's t-Distribution and F-Distribution}{20}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The Central Limit Theorem}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Procedure of the Central Limit Theorem}}{24}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Normal Approximation to the Binomial Distribution}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{25}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Bernoulli Distribution}{26}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Sampling Distribution of the Sum and MGF Derivation}{28}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Binomial Distribution}{28}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Visualizing the PMF of Binomial Distributions}{29}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces PMF of Binomial distribution with \(n = 10\) and \(p = \frac  {1}{6}\).}}{30}{figure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces PMF of Binomial distribution with \(n = 50\) and \(p = \frac  {1}{6}\).}}{30}{figure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces PMF of Binomial distribution with \(n = 100\) and \(p = \frac  {1}{6}\).}}{31}{figure.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces PMF of Binomial distribution with \(n = 300\) and \(p = \frac  {1}{6}\).}}{31}{figure.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Sampling Distribution of a Sample Proportion and the Normal Approximation}{32}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Binomial distribution with \(n = 300\), \(p = \frac  {1}{6}\) and its Normal approximation.}}{32}{figure.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Continuity Correction}{36}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Law of Large Numbers}{39}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Convergence in Probability}{39}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Weak Law of Large Numbers (WLLN)}{40}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Simulation of running sample mean of Bernoulli(\(p = 0.5\)) trials over time.}}{42}{figure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Simulation of 10 running sample means of Bernoulli(\(p = 0.5\)) trials converging over 100 trials.}}{42}{figure.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}One Sample Confidence Intervals on a Mean When the Population Variance is Known}{44}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{44}{section.6.1}\protected@file@percent }
\newlabel{figureVisualization of CI}{{6.1}{46}{Introduction}{defin.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Visualization of a confidence interval on the real number line. The margin of error is abbreviated as $MOE$. The estimator is the centre of the interval. The confidence interval consists of all values between the estimator$- MOE$ and the estimator$+ MOE$.}}{46}{figure.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Interpretation}{46}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Confidence Interval for $\mu $ (Known Variance)}{47}{section.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Simulated 95\% confidence intervals for the population mean. Red “X” marks indicate intervals that do not contain the true mean (\( \mu = 0 \)).}}{49}{figure.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces The central area under the standard normal curve with confidence level \( C \).}}{49}{figure.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}APPENDIX}{53}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown}{54}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}CIs for \(\mu \)}{54}{section.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Comparison of the standard normal distribution and t-distributions with 2 and 9 degrees of freedom.}}{56}{figure.7.1}\protected@file@percent }
\newlabel{fig:density-curves}{{7.1}{56}{Comparison of the standard normal distribution and t-distributions with 2 and 9 degrees of freedom}{figure.7.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}One Sample Confidence Intervals On a Proportion}{64}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Visualization of the result of confidence interval on a proportion.}}{65}{figure.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Two Sample Confidence Interval}{67}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Two Sample Confidence Interval on a Difference of Mean}{67}{section.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Visualization of two-sample confidence interval (Case 1, 2, 3)}}{69}{figure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Visualization of the case when $\mu _1 < \mu _2$}}{69}{figure.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Visualization of the case when $\mu _1 > \mu _2$}}{70}{figure.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Visualization of the case when $\mu _1 = \mu _2$}}{70}{figure.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Two Sample Confidence Interval on Paired Data}{72}{section.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces A table of paired data}}{73}{figure.10.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Visualization of the case when $\bar  {M}_1 < \bar  {M}_2$}}{73}{figure.10.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Visualization of the case when $\bar  {M}_1 > \bar  {M}_2$}}{74}{figure.10.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Visualization of the case when $\bar  {M}_1 = \bar  {M}_2$}}{74}{figure.10.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Two Sample Confidence Interval on Proportions}{74}{section.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Visualization of two population of all students from UTSG (left) and UTM (right)}}{75}{figure.10.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Visualization of two selected random sample from UTSG (left) and UTM (right)}}{75}{figure.10.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.11}{\ignorespaces Visualization of the case when $p_1 > p_2$}}{76}{figure.10.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.12}{\ignorespaces Visualization of the case when $p_1 < p_2$}}{76}{figure.10.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.13}{\ignorespaces Visualization of the case when $\hat  {p}_1 = \hat  {p}_2$}}{76}{figure.10.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Two Sample Confidence Interval on Variances}{77}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}One Sample Hypothesis Test on a Proportion and Variance}{78}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}One Sample Hypothesis Test on a Proportion}{78}{section.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces All possible cases of one sample hypothesis test on a proportion ($p$ represents the actual proportion of a population)}}{78}{figure.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p > p_0$.}}{79}{figure.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p < p_0$.}}{80}{figure.12.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces An illustration of hypothesis test on a proportion that $H_0: p = p_0$, $H_a: p \neq  p_0$.}}{80}{figure.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}One Sample Hypothesis Tests for a Variance}{81}{section.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces All possible cases of one sample hypothesis test on a variance}}{81}{figure.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Two Sample Hypothesis Test}{83}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Two Sample Hypothesis Test on Paired Data}{83}{section.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces A table of paired data}}{84}{figure.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces All possible cases of two sample hypothesis test on paired data}}{84}{figure.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Two Sample Hypothesis Test on Proportions}{85}{section.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces All possible cases of two sample hypothesis test on proportions}}{85}{figure.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Two Sample Hypothesis Test on Variances}{88}{section.14.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces All possible cases of two sample hypothesis test on variances}}{88}{figure.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Introduction to Simple Linear Regression}{89}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces An illustration of simple linear regression. The blue points are measures of height monthly, and the red line is our SLR model. In this case $m$ is the slope which tells you the rate of change, $b$ is the intercept which may have a special meaning depending on the case.}}{89}{figure.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Measures of Linear Relationship}{90}{section.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces An illustration of strong positive correlation ($r_{xy} \approx +1$).}}{91}{figure.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.3}{\ignorespaces An illustration of strong negative correlation ($r_{xy} \approx -1$).}}{92}{figure.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.4}{\ignorespaces An illustration of no correlation ($r_{xy} \approx 0$).}}{92}{figure.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.5}{\ignorespaces Data of example 15.1}}{93}{figure.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Least Squares Method}{94}{section.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.6}{\ignorespaces Data of example 15.2}}{95}{figure.15.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Simple Linear Regression}{96}{section.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.7}{\ignorespaces An illustration of a simple linear regression model. The red line is the fitted regression line, and the full black vertical lines represent the residuals (SSE). The data points deviate from the line to show errors clearly. Note that the sum of residuals is necessarily $0$.}}{97}{figure.15.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.8}{\ignorespaces Data of example 15.3}}{99}{figure.15.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.4}SST, SSE and SSR}{100}{section.15.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.9}{\ignorespaces An illustration of Total Sum of Squares (SST). The blue points represent height measurements over time, the dashed line is the mean height $\bar  {y}$, and the solid black vertical lines represent the squared deviations from the mean (SST components).}}{100}{figure.15.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.10}{\ignorespaces A simple linear regression illustration with residuals shown. Blue points are observed data, red line is the model, dashed line is the average of $y$, and black lines represent residuals $y_i - \hat  {y_i}$.}}{101}{figure.15.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.11}{\ignorespaces An illustration of simple linear regression. The blue points represent monthly height measurements with added variability. The red line is the fitted simple linear regression model. The dashed line shows the mean of the dependent variable, $\bar  {y}$, and the solid black lines illustrate the deviation of the model's predictions from this mean.}}{102}{figure.15.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.12}{\ignorespaces Visual representation of regression variability. \textbf  {SST} (green) is total variability from the mean, \textbf  {SSR} (pink) is explained variability, and \textbf  {SSE} (orange curly brace) is the residual (unexplained) variability between the observed value $y_i$ and the prediction $\hat  {y}_i$.}}{103}{figure.15.12}\protected@file@percent }
\gdef \@abspage@last{109}
