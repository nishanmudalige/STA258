<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Two Sample Confidence Interval | Demo Book</title>
  <meta name="description" content="Chapter 10 Two Sample Confidence Interval | Demo Book" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Two Sample Confidence Interval | Demo Book" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Two Sample Confidence Interval | Demo Book" />
  
  
  

<meta name="author" content="Nishan Mudalige" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sample-size-selection-using-confidence-intervals.html"/>
<link rel="next" href="introduction-to-hypothesis-testing.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>STA258: Statistics with Applied Probability</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nishan-mudalige-masoud-ataei-nurlana-alili-bryan-xu"><i class="fa fa-check"></i>Nishan Mudalige, Masoud Ataei, Nurlana Alili, Bryan Xu</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Descriptive Statistics and an Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#descriptive-statistics"><i class="fa fa-check"></i><b>1.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#graphical-techniques"><i class="fa fa-check"></i><b>1.3</b> Graphical Techniques</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#histograms"><i class="fa fa-check"></i><b>1.3.1</b> Histograms</a></li>
<li class="chapter" data-level="1.3.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#box-plots"><i class="fa fa-check"></i><b>1.3.2</b> Box-Plots</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-to-r"><i class="fa fa-check"></i><b>1.4</b> Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html"><i class="fa fa-check"></i><b>2</b> Sampling Distributions Related to a Normal Population</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#normal-distribution"><i class="fa fa-check"></i><b>2.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="2.2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#gamma-and-chi-square-distribution"><i class="fa fa-check"></i><b>2.2</b> Gamma and Chi-square Distribution</a></li>
<li class="chapter" data-level="2.3" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#students-t-distribution-and-f-distribution"><i class="fa fa-check"></i><b>2.3</b> Student’s t-Distribution and F-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-central-limit-theorem.html"><a href="the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html"><i class="fa fa-check"></i><b>4</b> Normal Approximation to the Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution"><i class="fa fa-check"></i><b>4.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-the-sum-and-mgf-derivation"><i class="fa fa-check"></i><b>4.3</b> Sampling Distribution of the Sum and MGF Derivation</a></li>
<li class="chapter" data-level="4.4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#binomial-distribution"><i class="fa fa-check"></i><b>4.4</b> Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#visualizing-the-pmf-of-binomial-distributions"><i class="fa fa-check"></i><b>4.4.1</b> Visualizing the PMF of Binomial Distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-a-sample-proportion-and-the-normal-approximation"><i class="fa fa-check"></i><b>4.5</b> Sampling Distribution of a Sample Proportion and the Normal Approximation</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#conditions-for-using-the-normal-approximation"><i class="fa fa-check"></i>Conditions for Using the Normal Approximation</a></li>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution-binomial-with-n-1"><i class="fa fa-check"></i>Bernoulli Distribution (Binomial with <span class="math inline">\(n = 1\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#normal-approximation-to-binomial"><i class="fa fa-check"></i><b>4.6</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="4.7" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction"><i class="fa fa-check"></i><b>4.7</b> Continuity Correction</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction-table"><i class="fa fa-check"></i>Continuity Correction Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html"><i class="fa fa-check"></i><b>5</b> Law of Large Numbers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#convergence-in-probability"><i class="fa fa-check"></i><b>5.1</b> Convergence in Probability</a></li>
<li class="chapter" data-level="5.2" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i><b>5.2</b> Weak Law of Large Numbers (WLLN)</a>
<ul>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#proof-of-the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i>Proof of the Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#empirical-probability-insight"><i class="fa fa-check"></i>Empirical Probability Insight</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><i class="fa fa-check"></i><b>6</b> One Sample Confidence Intervals on a Mean When the Population Variance is Known</a>
<ul>
<li class="chapter" data-level="6.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#interpretation"><i class="fa fa-check"></i><b>6.2</b> Interpretation</a></li>
<li class="chapter" data-level="6.3" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-mu-known-variance"><i class="fa fa-check"></i><b>6.3</b> Confidence Interval for <span class="math inline">\(\mu\)</span> (Known Variance)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-the-mean-of-a-normal-population"><i class="fa fa-check"></i>Confidence Interval for the Mean of a Normal Population</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#large-sample-ci-for-mu-normal-data"><i class="fa fa-check"></i>Large Sample CI for <span class="math inline">\(\mu\)</span> (Normal data)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#one-sample-ci-on-the-population-mean-mu"><i class="fa fa-check"></i>One Sample CI on the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#table-of-common-z-values"><i class="fa fa-check"></i>Table of Common <span class="math inline">\(z\)</span>-values</a></li>
<li class="chapter" data-level="6.4" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#appendix"><i class="fa fa-check"></i><b>6.4</b> APPENDIX</a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#pivotal-quantities"><i class="fa fa-check"></i>Pivotal quantities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><i class="fa fa-check"></i><b>7</b> One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown</a>
<ul>
<li class="chapter" data-level="7.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#cis-for-mu"><i class="fa fa-check"></i><b>7.1</b> CIs for <span class="math inline">\(\mu\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#independence-assumption"><i class="fa fa-check"></i>Independence Assumption</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#randomization-condition"><i class="fa fa-check"></i>Randomization Condition</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#standard-error"><i class="fa fa-check"></i>Standard Error</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#a-few-final-comments"><i class="fa fa-check"></i>A few final comments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="one-sample-confidence-intervals-on-a-proportion.html"><a href="one-sample-confidence-intervals-on-a-proportion.html"><i class="fa fa-check"></i><b>8</b> One Sample Confidence Intervals On a Proportion</a></li>
<li class="chapter" data-level="9" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Sample Size Selection using Confidence Intervals</a>
<ul>
<li class="chapter" data-level="9.0.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#empirical-rule"><i class="fa fa-check"></i><b>9.0.1</b> Empirical Rule</a></li>
<li class="chapter" data-level="9.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#secSampleSizeCIMean"><i class="fa fa-check"></i><b>9.1</b> Calculating Sample Size for a Confidence Interval on a Mean</a>
<ul>
<li class="chapter" data-level="" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#when-sigma-is-known"><i class="fa fa-check"></i>When <span class="math inline">\(\sigma\)</span> is Known</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#calculating-sample-size-for-a-confidence-interval-on-a-proportion"><i class="fa fa-check"></i><b>9.2</b> Calculating Sample Size for a Confidence Interval on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html"><i class="fa fa-check"></i><b>10</b> Two Sample Confidence Interval</a>
<ul>
<li class="chapter" data-level="10.1" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-a-difference-of-mean"><i class="fa fa-check"></i><b>10.1</b> Two Sample Confidence Interval on a Difference of Mean</a></li>
<li class="chapter" data-level="10.2" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-paired-data"><i class="fa fa-check"></i><b>10.2</b> Two Sample Confidence Interval on Paired Data</a></li>
<li class="chapter" data-level="10.3" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-proportions"><i class="fa fa-check"></i><b>10.3</b> Two Sample Confidence Interval on Proportions</a></li>
<li class="chapter" data-level="10.4" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-variances"><i class="fa fa-check"></i><b>10.4</b> Two Sample Confidence Interval on Variances</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-mean"><i class="fa fa-check"></i><b>11.1</b> Test of Hypothesis for One Mean</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-1-decide-on-a-level-of-significance-alpha"><i class="fa fa-check"></i>Step 1: Decide on a Level of Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-2-state-the-null-hypothesis-h_0-and-the-alternative-hypothesis-h_a"><i class="fa fa-check"></i>Step 2: State the Null Hypothesis (<span class="math inline">\(H_0\)</span>) and the Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-3-calculate-an-appropriate-test-statistic"><i class="fa fa-check"></i>Step 3: Calculate an appropriate test statistic</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-4-calculate-the-p-value"><i class="fa fa-check"></i>Step 4: Calculate the p-value</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-5-compare-p-value-to-level-of-significance-alpha-and-make-a-conclusion"><i class="fa fa-check"></i>Step 5: Compare <em>p</em>-value to level of significance <span class="math inline">\(\alpha\)</span> and make a conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-proportion"><i class="fa fa-check"></i><b>11.2</b> Test of Hypothesis for One Proportion</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing-significance-test"><i class="fa fa-check"></i>Introduction to Hypothesis Testing (Significance Test)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#steps-in-conducting-hypothesis-testing"><i class="fa fa-check"></i>Steps in conducting Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#some-additional-examples"><i class="fa fa-check"></i>Some Additional Examples</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-variance"><i class="fa fa-check"></i><b>11.3</b> Test of Hypothesis for One Variance</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><i class="fa fa-check"></i><b>12</b> One Sample Hypothesis Test on a Proportion and Variance</a>
<ul>
<li class="chapter" data-level="12.1" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html#one-sample-hypothesis-test-on-a-proportion"><i class="fa fa-check"></i><b>12.1</b> One Sample Hypothesis Test on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="statistical-power.html"><a href="statistical-power.html"><i class="fa fa-check"></i><b>13</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-ii-errors"><i class="fa fa-check"></i>Type I and II Errors</a></li>
<li class="chapter" data-level="13.1" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>13.1</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="13.2" data-path="statistical-power.html"><a href="statistical-power.html#using-power-to-determine-sample-size"><i class="fa fa-check"></i><b>13.2</b> Using Power to Determine Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html"><i class="fa fa-check"></i><b>14</b> Two Sample Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="14.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-with-independent-samples"><i class="fa fa-check"></i><b>14.1</b> Comparing Means with Independent Samples</a>
<ul>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#setting-up-hypotheses"><i class="fa fa-check"></i>Setting Up Hypotheses</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#structure-of-a-test-statistic"><i class="fa fa-check"></i>Structure of a Test Statistic</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#hypothesis-test-on-a-difference-of-means-mu_1---mu_2"><i class="fa fa-check"></i>Hypothesis Test on a Difference of Means (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-of-independent-samples-normal-population-assumptions"><i class="fa fa-check"></i>Comparing Means of Independent Samples (Normal Population Assumptions)</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-equal-variances-assumed"><i class="fa fa-check"></i><b>14.1.1</b> Comparing Two Populations Means: Independent Sampling (Equal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-with-equal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (with equal variances)</a></li>
<li class="chapter" data-level="14.1.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-unequal-variances-assumed"><i class="fa fa-check"></i><b>14.1.2</b> Comparing Two Populations Means: Independent Sampling (Unequal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-unequal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (Unequal Variances)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#degrees-of-freedom"><i class="fa fa-check"></i>Degrees of Freedom</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-t-test-unequal-variances"><i class="fa fa-check"></i>Two-Sample t-Test (Unequal Variances)</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#the-fold-rule"><i class="fa fa-check"></i><b>14.2</b> The Fold Rule</a></li>
<li class="chapter" data-level="14.3" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-paired-data"><i class="fa fa-check"></i><b>14.3</b> Two Sample Hypothesis Test on Paired Data</a></li>
<li class="chapter" data-level="14.4" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-proportions"><i class="fa fa-check"></i><b>14.4</b> Two Sample Hypothesis Test on Proportions</a></li>
<li class="chapter" data-level="14.5" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-variances"><i class="fa fa-check"></i><b>14.5</b> Two Sample Hypothesis Test on Variances</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html"><i class="fa fa-check"></i><b>15</b> Introduction to Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#measures-of-linear-relationship"><i class="fa fa-check"></i><b>15.1</b> Measures of Linear Relationship</a></li>
<li class="chapter" data-level="15.2" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#least-squares-method"><i class="fa fa-check"></i><b>15.2</b> Least Squares Method</a></li>
<li class="chapter" data-level="15.3" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>15.3</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="15.4" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#sst-sse-and-ssr"><i class="fa fa-check"></i><b>15.4</b> SST, SSE and SSR</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html"><i class="fa fa-check"></i><b>16</b> Inference for Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#inference-on-regression"><i class="fa fa-check"></i><b>16.1</b> Inference on Regression</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#estimating-variance-in-linear-regression"><i class="fa fa-check"></i>Estimating Variance in Linear Regression</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#the-regression-model"><i class="fa fa-check"></i>The Regression Model</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#interpreting-confidence-intervals-for-beta_1"><i class="fa fa-check"></i>Interpreting Confidence Intervals for <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#anova-table-analysis-of-variance"><i class="fa fa-check"></i><b>16.2</b> ANOVA Table (ANalysis Of VAriance)</a></li>
<li class="chapter" data-level="16.3" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#residual-plots"><i class="fa fa-check"></i><b>16.3</b> Residual Plots</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#what-to-look-for-in-a-good-residual-plot"><i class="fa fa-check"></i>What to Look for in a Good Residual Plot</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Demo Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="two-sample-confidence-interval" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Two Sample Confidence Interval<a href="two-sample-confidence-interval.html#two-sample-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We have discussed three distinct types of one sample confidence
interval. Now, let’s keep moving forward to see how confidence interval
works for two sample. The aim of one sample confidence interval is
giving a range of numbers to estimate population mean or proportion with
a certain percentage of confidence. For two samples, the aim is
comparing with sample has a relatively larger or smaller population mean
or proportion with a certain percentage of confidence.</p>
<div id="two-sample-confidence-interval-on-a-difference-of-mean" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Two Sample Confidence Interval on a Difference of Mean<a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-a-difference-of-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we are interested in the final mark of MAT135 from the same
semester but with different campuses at the University of Toronto (let’s
use UTSG and UTM as the two independent population groups). We want to
know which campus has a relatively higher average score, the question
is: how do we determine that? It is going to be complicated if we
proceed with the study directly by determining the sum of everyone’s
final marks and calculating the average for the two campuses. Similarly,
as one sample confidence interval, we can select two groups of random
sample from the two campuses (one group per each campus), and then
calculate each sample mean. Finally, we apply a confidence interval to
approximate which population has a higher mean (or average).<br />
<strong>Two Sample Confidence Interval for Two Independent Groups of
Population</strong></p>
<p>We are going to introduce several definitions because two sample
confidence interval has distinct cases. You need to be able to identify
which exact case you are facing from given information. If you know how
to solve one sample confidence interval, then two sample confidence
interval is going to be easy, because all the techniques from one sample
confidence interval are still usable.<br />
<strong>Case 1:</strong> Two sample confidence interval with given population
variance for both groups.<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-60" class="definition"><strong>Definition 10.1  </strong></span>Suppose we are given the population variance for both two independent
groups of population. The confidence interval of <span class="math inline">\(\mu_1 - \mu_2\)</span>
(difference of mean between population group 1 and 2) is given by the
following:
<span class="math display">\[(\bar{x}_{1} - \bar{x}_{2})  \pm z_{\small\alpha/2} \cdot \sqrt{ \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}.\]</span>
For <span class="math inline">\(\sigma_1^2\)</span>, which is population variance of population group 1;
<span class="math inline">\(n_1\)</span> is the sample size chosen form population group 1. Similarly for
<span class="math inline">\(\sigma_2^2\)</span>, which is population variance of population group 2; <span class="math inline">\(n_2\)</span>
is the sample size chosen form population group 2.</p>
</div>
<p>Additionally, case 1 is a bit unrealistic with other cases because the
population variance (<span class="math inline">\(\sigma^2\)</span>) from both groups are rare to know.<br />
<strong>Case 2:</strong> Two sample confidence interval with equal unknown population
variance<br />
Ideally, we have all the information about population variance from two
chosen samples. However, that case does not usually happen. We may face
the case with unknown variance.</p>
<div class="definition">
<p><span id="def:unlabeled-div-61" class="definition"><strong>Definition 10.2  </strong></span>Suppose that the chosen two independent samples have same unknown
population variance. Then the two sample confidence interval for
<span class="math inline">\(\mu_1 - \mu_2\)</span> is given by the following:
<span class="math display">\[(\bar{x}_1 - \bar{x}_2)  \pm  t_{n_1+n_2-2; \alpha/2} \cdot s_p \cdot \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}.\]</span>
In this case, <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are sample size from the two chosen
samples respectively; <span class="math inline">\(s_p\)</span> is aggregated variance of both samples
combined which accommodates samples of different sizes. Additionally,
<span class="math inline">\(s_p\)</span> is called pooled standard deviation which is calculated by the
following equation:
<span class="math display">\[s_p^2 = \frac{(n_1-1) \cdot s_1^2 + (n_2-1) \cdot s_2^2 }{n_1+n_2-2},\]</span>
where <span class="math inline">\(s_1^2\)</span> and <span class="math inline">\(s_2^2\)</span> are sample variance of the two chosen samples
respectively.<br />
Then we take the square root <span class="math inline">\(s_p = \sqrt{s_p^2}\)</span> to get pooled standard
deviation.</p>
</div>
<p>Alternatively, we can write the equation for two sample confidence
interval with equal unknown variance as:
<span class="math display">\[(\bar{x}_1 - \bar{x}_2)  \pm  t_{n_1+n_2-2; \alpha/2} \cdot \sqrt{s_p^2(\frac{1}{n_1} + \frac{1}{n_2})}, \text{ which is same as the one above.}\]</span></p>
<p><strong>Pooled Variance and Standard Deviation</strong></p>
<p>In statistics, pooled variance (also known as combined variance,
composite variance, or overall variance) is a method to calculate such a
value in order to estimate variance between several distinct
populations. The mean of each population may or may not be the same, but
the variance of these populations are same. Pooled standard deviation
does similar thing, we use that value to estimate standard deviation
instead of variance.<br />
<strong>Case 3:</strong> Two sample confidence interval with unequal unknown
population variance<br />
At this point, you may wonder that what if the population variance is
both unequal and unknown? Does two sample confidence interval still
doable in this case? The answer is: Yes. We can still proceed with two
sample confidence interval.</p>
<div class="definition">
<p><span id="def:unlabeled-div-62" class="definition"><strong>Definition 10.3  </strong></span>Suppose that our chosen two independent samples with unequal and unknown
population variance, then the confidence interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> is
given by:
<span class="math display">\[(\bar{x}_1 - \bar{x}_2)  \pm t_{df; \alpha/2} \cdot \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}, \text{ where: $df = min(n_1-1, n_2-1)$.}\]</span>
Moreover, <span class="math inline">\(s_1^2\)</span> and <span class="math inline">\(s_2^2\)</span> are sample variance of the two chosen
groups; and <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span> are the sample size of the two chosen groups
respectively.</p>
</div>
<p><strong>Visualization of Two Sample Confidence Interval</strong></p>
<p>Only with the equation seems hard to understand, the following number
line helps you to visualize what we try to indicate:</p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu1"></span>
<img src="ch10/two-sample-ci-1.png" alt="Visualization of two-sample confidence interval (Case 1, 2, 3)" width="80%" />
<p class="caption">
Figure 10.1: Visualization of two-sample confidence interval (Case 1, 2, 3)
</p>
</div>
<figcaption>
Visualization of two-sample confidence interval (Case 1, 2,
3)
</figcaption>
</figure>
</div>
<p>Earlier in this chapter we said that two sample confidence interval aims
to compare the mean between two populations. The number line above shows
the result of difference of means between the two populations. Now, the
question is, how do we know which population has a relatively larger
mean? While, we can summarize it from that number line, with different
cases:</p>
<p><strong>1. <span class="math inline">\(\mu_1 &lt; \mu_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-2"></span>
<img src="figures/Ca1-1.png" alt="Visualization of the case when μ₁ &lt; μ₂" width="80%" />
<p class="caption">
Figure 10.2: Visualization of the case when μ₁ &lt; μ₂
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>μ</em><sub>1</sub> &lt; <em>μ</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>Now, we know that the difference between <span class="math inline">\(\mu_1 &lt; \mu_2\)</span> lies on the
negative side on the number line, such that: <span class="math inline">\(\mu_1 - \mu_2 &lt; 0\)</span>. Hence,
by solving the inequality above we get: <span class="math inline">\(\mu_1 &lt; \mu_2\)</span> trivially.</p>
<p><strong>2. <span class="math inline">\(\mu_1 &gt; \mu_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-3"></span>
<img src="figures/Ca2-1.png" alt="Visualization of the case when μ₁ &gt; μ₂" width="80%" />
<p class="caption">
Figure 10.3: Visualization of the case when μ₁ &gt; μ₂
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>μ</em><sub>1</sub> &gt; <em>μ</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>Similarly as the case above, we know that <span class="math inline">\(\mu_1 - \mu_2 &gt; 0\)</span>, by
observing the number line. Thus, we have: <span class="math inline">\(\mu_1 &gt; \mu_2\)</span>.</p>
<p><strong>3. <span class="math inline">\(\mu_1 = \mu_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-4"></span>
<img src="figures/Ca3-1.png" alt="Visualization of the case when μ₁ = μ₂" width="80%" />
<p class="caption">
Figure 10.4: Visualization of the case when μ₁ = μ₂
</p>
</div>
</figure>
</div>
<p>However, 0 is an element in the range of the difference between
<span class="math inline">\(\mu_1 - \mu_2\)</span>, such that there is a chance when the two means could be
same. Hence, we conclude that <span class="math inline">\(\mu_1 = \mu_2\)</span> in this case. While, if
you prefer to use <span class="math inline">\(\mu_2 - \mu_1\)</span>, this strategy is going to work as
well. Just simply following the same steps, you will get the same
conclusion.<br />
<strong>Conditions of Two Sample Confidence Interval</strong></p>
<p>Same as all previous confidence intervals, we still need several
conditions that guarantee the validity two sample confidence interval:</p>
<ul>
<li><p>1. The two chosen sample is required to be independent and random;</p></li>
<li><p>2. If both sample size are small (both <span class="math inline">\(n_1 &lt; 30\)</span> and <span class="math inline">\(n_2 &lt; 30\)</span>),
then both sample should be from normal population;</p></li>
<li><p>3. If one of the sample has a small size (either <span class="math inline">\(n_1 &lt; 30\)</span> or
<span class="math inline">\(n_2 &lt; 30\)</span>), then the smaller sample must be from a normal population;</p></li>
</ul>
<p>Note that if both <span class="math inline">\(n_1 \ge 30\)</span> and <span class="math inline">\(n_2 \ge 30\)</span>, then normality
assumption is not required by the Central Limit Theorem.<br />
<strong>Example (Comparing Two Population Means Managerial Success Indexes for
Two Groups)</strong></p>
<div class="example">
<p><span id="exm:unlabeled-div-63" class="example"><strong>Example 10.1  </strong></span>Behavioural researchers have developed an index designed to measure
managerial success. The index (measured on a 100- point scale) is based
on the manager’s length of time in the organization and their level
within the term; the higher the index, the more successful the manager.
Suppose a researcher wants to compare the average index for the two
groups of managers at a large manufacturing plant. Managers in group 1
engage in high volume of interactions with people outside the managers’
work unit (such interaction include p hone and face-to-face meetings
with customers and suppliers, outside meetings, and public relation
work). Managers in group 2 rarely interact with people outside their
work unit. Independent random samples of 12 and 15 managers are selected
from groups 1 and 2, respectively, and success index of each is
recorded.<br />
Comparing Two Population Means Managerial Success Indexes for Two Group
(With Equal Variances Assumed) Note: The response variable is
“Managerial Success Indexes”.</p>
<p>Managerial success indexes is a continuous quantitative variable,</p>
<p>measured on100-point scale.</p>
<p>The explanatory variable is “Type of group”.</p>
<p>Type of group (Group 1: Interaction with outsiders, Group 2: Fewer
interactions) is a nominal categorical variable.</p>
<p>Let’s use R-code to demonstrate this example. The following lines of
code helps you to get started.</p>
<div class="tcolorbox">
<pre><code># Importing data file into R;

success=read.csv(file=&quot;success.csv&quot;,header=TRUE);

# Getting names of variables;

names(success);

# Seeing first few observations;

head(success);

# Attaching data file; attach(success);</code></pre>
</div>
<p>Now, you will get the following table by running the code above from
R-studio.</p>
<div class="tcolorbox">
<pre><code>## [1] &quot;Success_Index&quot; &quot;Group&quot; 
## Success_Index Group 
## 1 65 1 
## 2 66 1 
## 3 58 1 
## 4 70 1 
## 5 78 1 
## 6 53 1</code></pre>
</div>
<p>Then, we use R-studio to obtain some descriptive statistics.</p>
<div class="tcolorbox">
<pre><code>##  .group  min    Q1 median    Q3 max     mean       sd  n
## 1         1   53 62.25   65.5 69.25  78 65.33333 6.610368 12
## 2         2   34 42.50   50.0 54.50  68 49.46667 9.334014 15
##  missing
## 1           0
## 2           0</code></pre>
</div>
<p>Note that: Group 1 = “interaction with outsiders” and Group 2 = “fewer
interactions”. Then, we can proceed with two sample confidence interval.</p>
<div class="tcolorbox">
<pre><code># 95\% CI for the difference between means; 
# equal variances is assumed;

t.test(Success_Index~Group, 
var.equal=TRUE, conf.level=0.95)$conf.int;</code></pre>
</div>
<p>Finally, the output is:</p>
<div class="tcolorbox">
<pre><code>## [1] 9.288254 22.445079 
## attr(,&quot;conf.level&quot;) 
## [1] 0.95</code></pre>
</div>
<p>Therefore, We are 95% conﬁdent that the mean success index is between
9.28 and 22.44 points higher for group 1 than group 2.</p>
</div>
</div>
<div id="two-sample-confidence-interval-on-paired-data" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Two Sample Confidence Interval on Paired Data<a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-paired-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It seems like two sample confidence interval only works on two
independent samples, however what about two dependent samples? Suppose
we are interested the growth of height from several distinct elementary
students. We measure their height recently, then we will do it another
time with five years later. The question is: how are we going to proceed
with two confidence interval? While, the answer is yes. We are able to
do so by constructing two sample confidence interval, but with a
different strategy. Now, let’s introduce two sample confidence interval
with paired data:</p>
<div class="center">
<figure>
<table>
<tbody>
<tr>
<td style="text-align: center;">
Sample Units
</td>
<td style="text-align: center;">
Measurement 1 (<span class="math inline"><em>M</em><sub>1</sub></span>)
</td>
<td style="text-align: center;">
Measurement 2 (<span class="math inline"><em>M</em><sub>2</sub></span>)
</td>
<td style="text-align: center;">
Difference (<span class="math inline"><em>M</em><sub>2</sub> − <em>M</em><sub>1</sub></span>
or <span class="math inline"><em>M</em><sub>1</sub> − <em>M</em><sub>2</sub></span>)
</td>
</tr>
<tr>
<td style="text-align: center;">
1
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>11</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>12</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>d</em>1</sub> = <em>x</em><sub>12</sub> − <em>x</em><sub>11</sub></span>
</td>
</tr>
<tr>
<td style="text-align: center;">
2
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>21</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>22</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>d</em>2</sub> = <em>x</em><sub>22</sub> − <em>x</em><sub>21</sub></span>
</td>
</tr>
<tr>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>31</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub>32</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>d</em>2</sub> = <em>x</em><sub>32</sub> − <em>x</em><sub>31</sub></span>
</td>
</tr>
<tr>
<td style="text-align: center;">
……
</td>
<td style="text-align: center;">
</td>
<td style="text-align: center;">
</td>
<td style="text-align: center;">
</td>
</tr>
<tr>
<td style="text-align: center;">
n
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>n</em>1</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>n</em>2</sub></span>
</td>
<td style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>d</em><em>n</em></sub> = <em>x</em><sub><em>n</em>2</sub> − <em>x</em><sub><em>n</em>1</sub></span>
</td>
</tr>
</tbody>
</table>
<figcaption>
A table of paired data
</figcaption>
</figure>
</div>
<p>The table shows how to get a paired data. The first column on the left
is the sample size, the second column records the first time of
measurement of objects, the third column records the second time of
measurement of the same objects, the last column on the right is the
difference between the second and the first measurement (<span class="math inline">\(M_2 - M_1\)</span>).
Then we can use the fourth column to get the mean value, sample variance
and sample standard deviation of the difference. Now, let’s begin with
the proper definition:</p>
<div class="definition">
<p><span id="def:unlabeled-div-64" class="definition"><strong>Definition 10.4  </strong></span>Suppose we have two samples that are dependent with each other, the
confidence interval on paired data’s mean (<span class="math inline">\(\mu_d\)</span>) is given by:
<span class="math display">\[\bar{x}_d  \pm t_{n-1, \alpha/2} \cdot \frac{s_d}{\sqrt{n}}.\]</span> In this
case, the reference distribution is t-distribution with <span class="math inline">\(n-1\)</span> degrees of
freedom (sample size minus <span class="math inline">\(1\)</span>), <span class="math inline">\(\bar{x}_d\)</span> represents the sample mean
of difference between the two measurements on the paired data, <span class="math inline">\(s_d\)</span> is
the sample standard deviation of difference between the two
measurements.</p>
</div>
<p>Note that: two sample confidence interval on paired data is to calculate
a range of number on <strong>the mean of difference between the two
measurement</strong>. Then, we can continue our analysis about the data.<br />
<strong>Visualization of Two Sample Confidence Interval on Paired Data</strong></p>
<p>Next, we need to state our final conclusion from the result of two
sample confidence interval on paired data. Again, let’s construct a
number line for each case.</p>
<p><strong>1. <span class="math inline">\(\bar{M}_1 &lt; \bar{M}_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-5"></span>
<img src="figures/pa1-1.png" alt="Visualization of the case when $\bar{M}_1 &lt; \bar{M}_2$" width="80%" />
<p class="caption">
Figure 10.5: Visualization of the case when <span class="math inline">\(\bar{M}_1 &lt; \bar{M}_2\)</span>
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>M̄</em><sub>1</sub> &lt; <em>M̄</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>From the number line above, we know that the result of <span class="math inline">\(\mu_d\)</span> lies only
in the negative side of the number line, also we use <span class="math inline">\(M_1 - M_2\)</span> to get
the difference data then calculate the average of difference data. Now,
we have: <span class="math inline">\(\bar{M}_1 - \bar{M}_2 = \mu_d &lt; 0\)</span>. Hence, we conclude that
<span class="math inline">\(\bar{M}_1 &lt; \bar{M}_2.\)</span></p>
<p><strong>2. <span class="math inline">\(\bar{M}_1 &gt; \bar{M}_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-6"></span>
<img src="figures/pa2-1.png" alt="Visualization of the case when $\bar{M}_1 &gt; \bar{M}_2$" width="80%" />
<p class="caption">
Figure 10.6: Visualization of the case when <span class="math inline">\(\bar{M}_1 &gt; \bar{M}_2\)</span>
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>M̄</em><sub>1</sub> &gt; <em>M̄</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>From the number line above, we know that the result of <span class="math inline">\(\mu_d\)</span> lies only
in the positive side of the number line, also we use <span class="math inline">\(M_1 - M_2\)</span> to get
the difference data then calculate the average of difference data. Now,
we have: <span class="math inline">\(\bar{M}_1 - \bar{M}_2 = \mu_d &gt; 0\)</span>. Hence, we conclude that
<span class="math inline">\(\bar{M}_1 &gt; \bar{M}_2.\)</span></p>
<p><strong>3. <span class="math inline">\(\bar{M}_1 = \bar{M}_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-7"></span>
<img src="figures/pa3-1.png" alt="The mean $\bar{M}_1$ is equal to $\bar{M}_2$." width="80%" />
<p class="caption">
Figure 10.7: The mean <span class="math inline">\(\bar{M}_1\)</span> is equal to <span class="math inline">\(\bar{M}_2\)</span>.
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>M̄</em><sub>1</sub> = <em>M̄</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>While, 0 is included in the range of <span class="math inline">\(\mu_d\)</span>, then there is a chance
that <span class="math inline">\(\bar{M}_1 - \bar{M_2} = \mu_d = 0.\)</span> Hence, we conclude that
<span class="math inline">\(\bar{M}_1 = \bar{M}_2\)</span>.<br />
<strong>Conditions of Two Sample Confidence Interval on Paired Data</strong></p>
<p>We need the following conditions to make sure the validity of two sample
confidence interval on paired data:</p>
<ul>
<li><p>1. Units are independent (measurements are dependent on each unit)</p></li>
<li><p>2. Units must be random sample</p></li>
<li><p>3. If we have a small sample (<span class="math inline">\(n &lt; 30\)</span>), then the population of
difference should be normal (no restrictions on large samples).</p></li>
</ul>
<p>Also, note that two sample confidence interval on paired data can only
be applied with two dependent groups of data. For independent groups of
data, you need to refer chapter 10.1.</p>
</div>
<div id="two-sample-confidence-interval-on-proportions" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Two Sample Confidence Interval on Proportions<a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Furthermore, two sample confidence intervals can approximate the
proportion as well. Suppose we are interested in the proportion of
left-handed students in UTSG and UTM, and we are asked to find the
campus that has a relatively larger proportion of left-handed students.
To begin with this task, it is impossible to complete it directly by
calculation, due to its complexity and high workload. We can use select
two independent groups (one group from each campus), then apply two
sample confidence interval to approximate which campus has a larger
proportion.<br />
It may still be difficult to understand, now let’s begin with figures:</p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-8"></span>
<img src="figures/f1-1.png" alt="Visualization of two population of all students from UTSG (left) and UTM (right)." width="80%" />
<p class="caption">
Figure 10.8: Visualization of two population of all students from UTSG (left) and UTM (right).
</p>
</div>
<figcaption>
Visualization of two population of all students from UTSG
(left) and UTM (right)
</figcaption>
</figure>
</div>
<p>This figure represents the population of all students from two campuses.
To begin with our task (find the proportion of left-handed students), we
can select a group of random sample from each campus:</p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-9"></span>
<img src="figures/f2-1.png" alt="Visualization of two selected random sample from UTSG (left) and UTM (right)." width="80%" />
<p class="caption">
Figure 10.9: Visualization of two selected random sample from UTSG (left) and UTM (right).
</p>
</div>
<figcaption>
Visualization of two selected random sample from UTSG (left)
and UTM (right)
</figcaption>
</figure>
</div>
<p>As you can see, we have chosen our random sample from each campus with
sample size <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>, respectively. Now we need estimators to
construct our confidence interval: <span class="math inline">\(\hat{p}_1\)</span> and <span class="math inline">\(\hat{p}_2\)</span>. Those
are the proportion of left-handed students from each random sample
respectively. Since we have all the information we need, now we can
apply our confidence interval from the two random sample.</p>
<div class="definition">
<p><span id="def:unlabeled-div-65" class="definition"><strong>Definition 10.5  </strong></span>Draw an SRS of size <span class="math inline">\(n_1\)</span> from a population having proportion <span class="math inline">\(p_1\)</span> of
successes and draw an independent SRS of size <span class="math inline">\(n_2\)</span> from another
population having proportion <span class="math inline">\(p_2\)</span> of successes. When <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>
are large, an approximate level C confidence interval for <span class="math inline">\(p_1 - p_2\)</span> is
given by:
<span class="math display">\[(\hat{p}_1 - \hat{p}_2)  \pm z_{\alpha/2} \cdot \sqrt{ \frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}.\]</span>
Now, <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are sample size of selected random sample from each
population; <span class="math inline">\(\hat{p}_1\)</span> and <span class="math inline">\(\hat{p}_2\)</span> are the proportion of success of
each selected random sample respectively.</p>
</div>
<p>Note that,
<span class="math inline">\(\hat{p}_1 = \frac{\text{number of successes in random sample 1}}{n_1}\)</span>
and
<span class="math inline">\(\hat{p}_2 = \frac{\text{number of successes in random sample 2}}{n_2}\)</span>.</p>
<p><strong>Visualization of <span class="math inline">\(p_1 - p_2\)</span></strong></p>
<p>Similarly as confidence interval on independent and dependent data, we
are going to provide number lines, in order to help you to visualize the
result easily.</p>
<p><strong>1. <span class="math inline">\(p_1 &gt; p_2\)</span>:</strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-10"></span>
<img src="figures/po1-1.png" alt="Visualization of the case when $p_1 &gt; p_2$." width="80%" />
<p class="caption">
Figure 10.10: Visualization of the case when <span class="math inline">\(p_1 &gt; p_2\)</span>.
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>p</em><sub>1</sub> &gt; <em>p</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>From the number line, the result of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> lies only on
the positive side, such that <span class="math inline">\(\hat{p}_1 - \hat{p}_2 &gt; 0\)</span>. Hence,
<span class="math inline">\(\hat{p}_1 &gt; \hat{p}_2\)</span>. Note that proportion is a number between <span class="math inline">\(0\)</span>
and <span class="math inline">\(1\)</span>, such that the difference of two proportions only between <span class="math inline">\(-1\)</span>
and <span class="math inline">\(1\)</span>.</p>
<p><strong>2. <span class="math inline">\(\hat{p}_1 &lt; \hat{p}_2\)</span></strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-11"></span>
<img src="figures/po2-1.png" alt="Visualization of the case when $p_1 &lt; p_2$." width="80%" />
<p class="caption">
Figure 10.11: Visualization of the case when <span class="math inline">\(p_1 &lt; p_2\)</span>.
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>p</em><sub>1</sub> &lt; <em>p</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>Now, the result of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> lies only on the positive
side, such that <span class="math inline">\(\hat{p}_1 - \hat{p}_2 &lt; 0\)</span>. Hence,
<span class="math inline">\(\hat{p}_1 &lt; \hat{p}_2\)</span>.</p>
<p><strong>3. <span class="math inline">\(\hat{p}_1 = \hat{p}_2\)</span></strong></p>
<div class="center">
<figure>
<div class="figure"><span style="display:block;" id="fig:fig-mu1-lt-mu2-12"></span>
<img src="figures/po3-1.png" alt="Visualization of the case when $p_1 = p_2$." width="80%" />
<p class="caption">
Figure 10.12: Visualization of the case when <span class="math inline">\(p_1 = p_2\)</span>.
</p>
</div>
<figcaption>
Visualization of the case when <span class="math inline"><em>p̂</em><sub>1</sub> = <em>p̂</em><sub>2</sub></span>
</figcaption>
</figure>
</div>
<p>In this case, <span class="math inline">\(0\)</span> lies in the range of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>, such
that there is a chance when <span class="math inline">\(\hat{p}_1 - \hat{p}_2 = 0\)</span>. Hence, we
conclude that: <span class="math inline">\(\hat{p}_1 = \hat{p}_2\)</span>.<br />
<strong>Conditions of Two Sample Confidence Interval on Proportion</strong></p>
<ul>
<li><p>1. Randomization Condition: The data in each group should be drawn
independently and at random from a population or generated b y a
completely randomized designed experiment.</p></li>
<li><p>2. The <span class="math inline">\(10\%\)</span> Condition: If the data are sampled without replacement,
the sample should not exceed <span class="math inline">\(10\%\)</span> of the population. If samples are
bigger than <span class="math inline">\(10\%\)</span> of the target population, random draws are no
longer approximately independent.</p></li>
<li><p>3. Independent Groups Assumption: The two groups we are comparing
must be independent from each other.</p></li>
<li><p>4. Sample size requirement: both selected sample size must greater
than <span class="math inline">\(70\)</span>.</p></li>
</ul>
</div>
<div id="two-sample-confidence-interval-on-variances" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Two Sample Confidence Interval on Variances<a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-variances" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Confidence interval is a strong technique in inferential statistics, we
have discussed its application on population mean, proportion and
dependent data. Now, let’s move on to variance.<br />
One simple method involves just looking at two sample variances.
Logically, if two population variances are equal, then the two sample
variances should be very similar. When the two sample variances are
reasonably close, you can be reasonably conﬁdent that the homogeneity
assumption is satisﬁed and proceed with, for example, Student
t-interval. However, when one sample variance is three or four times
larger than the other, then there is reason for a concern. The common
statistical procedure for comparing population variances <span class="math inline">\(\sigma_1^2\)</span>
and <span class="math inline">\(\sigma_2^2\)</span> makes an inference about the ratio of
<span class="math inline">\((\sigma_1^2)/(\sigma_2^2)\)</span>.<br />
To make an inference about the ratio of <span class="math inline">\((\sigma_1^2)/(\sigma_2^2)\)</span> we
collect sample data and use the ratio of the sample variances
<span class="math inline">\((\sigma_1^2)/(\sigma_2^2)\)</span>.</p>
<p>At this point, let’s derive the confidence interval. We know that:
<span class="math inline">\(\frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2} \sim F_{n_1-1, n_2 -1}\)</span>.
Then, we can construct our confidence interval as:
<span class="math display">\[P[F_{n_1-1, n_2 -1; 1-\alpha/2} &lt; \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2} &lt; F_{n_1-1, n_2 -1; \alpha/2}]  = 1 -\alpha.\]</span>
Now, the reference distribution of this confidence interval is
F-distribution with <span class="math inline">\(n_1 - 1\)</span> and <span class="math inline">\(n_2 -1\)</span> degrees of freedom, leaving
areas of <span class="math inline">\(1 - \alpha/2\)</span> and <span class="math inline">\(\alpha/2\)</span>, respectively, to the right.
Rearranging gives us:
<span class="math display">\[P[\frac{s_1^2}{s_2^2} \cdot \frac{1}{F_{n_1-1, n_2 -1; \alpha/2}} &lt; \frac{\sigma_1^2}{\sigma_2^2} &lt; \frac{s_1^2}{s_2^2} \cdot \frac{1}{F_{n_1-1, n_2 -1; 1-\alpha/2}}] = 1 -\alpha.\]</span>
Using the face that
<span class="math inline">\(F_{n_1-1,n_2-1; 1 - \alpha/2} = \frac{1}{F_{n_2-1,n_1-1; \alpha/2}}\)</span>,
we have:
<span class="math display">\[P[\frac{s_1^2}{s_2^2} \cdot \frac{1}{F_{n_1-1, n_2-1, \alpha/2}} &lt; \frac{\sigma_1^2}{\sigma_2^2} &lt; \frac{s_1^2}{s_2^2} \cdot F_{n_2-1, n_1 - 1, \alpha/2}] = 1- \alpha.\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sample-size-selection-using-confidence-intervals.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
