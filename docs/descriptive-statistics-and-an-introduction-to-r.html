<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Descriptive Statistics and an Introduction to R | Demo Book</title>
  <meta name="description" content="Chapter 1 Descriptive Statistics and an Introduction to R | Demo Book" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Descriptive Statistics and an Introduction to R | Demo Book" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Descriptive Statistics and an Introduction to R | Demo Book" />
  
  
  

<meta name="author" content="Nishan Mudalige" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="sampling-distributions-related-to-a-normal-population.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>STA258: Statistics with Applied Probability</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nishan-mudalige-masoud-ataei-nurlana-alili-bryan-xu"><i class="fa fa-check"></i>Nishan Mudalige, Masoud Ataei, Nurlana Alili, Bryan Xu</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Descriptive Statistics and an Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#descriptive-statistics"><i class="fa fa-check"></i><b>1.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#graphical-techniques"><i class="fa fa-check"></i><b>1.3</b> Graphical Techniques</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#histograms"><i class="fa fa-check"></i><b>1.3.1</b> Histograms</a></li>
<li class="chapter" data-level="1.3.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#box-plots"><i class="fa fa-check"></i><b>1.3.2</b> Box-Plots</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-to-r"><i class="fa fa-check"></i><b>1.4</b> Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html"><i class="fa fa-check"></i><b>2</b> Sampling Distributions Related to a Normal Population</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#normal-distribution"><i class="fa fa-check"></i><b>2.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="2.2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#gamma-and-chi-square-distribution"><i class="fa fa-check"></i><b>2.2</b> Gamma and Chi-square Distribution</a></li>
<li class="chapter" data-level="2.3" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#students-t-distribution-and-f-distribution"><i class="fa fa-check"></i><b>2.3</b> Student’s t-Distribution and F-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-central-limit-theorem.html"><a href="the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html"><i class="fa fa-check"></i><b>4</b> Normal Approximation to the Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution"><i class="fa fa-check"></i><b>4.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-the-sum-and-mgf-derivation"><i class="fa fa-check"></i><b>4.3</b> Sampling Distribution of the Sum and MGF Derivation</a></li>
<li class="chapter" data-level="4.4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#binomial-distribution"><i class="fa fa-check"></i><b>4.4</b> Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#visualizing-the-pmf-of-binomial-distributions"><i class="fa fa-check"></i><b>4.4.1</b> Visualizing the PMF of Binomial Distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-a-sample-proportion-and-the-normal-approximation"><i class="fa fa-check"></i><b>4.5</b> Sampling Distribution of a Sample Proportion and the Normal Approximation</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#conditions-for-using-the-normal-approximation"><i class="fa fa-check"></i>Conditions for Using the Normal Approximation</a></li>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution-binomial-with-n-1"><i class="fa fa-check"></i>Bernoulli Distribution (Binomial with <span class="math inline">\(n = 1\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#normal-approximation-to-binomial"><i class="fa fa-check"></i><b>4.6</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="4.7" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction"><i class="fa fa-check"></i><b>4.7</b> Continuity Correction</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction-table"><i class="fa fa-check"></i>Continuity Correction Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html"><i class="fa fa-check"></i><b>5</b> Law of Large Numbers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#convergence-in-probability"><i class="fa fa-check"></i><b>5.1</b> Convergence in Probability</a></li>
<li class="chapter" data-level="5.2" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i><b>5.2</b> Weak Law of Large Numbers (WLLN)</a>
<ul>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#proof-of-the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i>Proof of the Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#empirical-probability-insight"><i class="fa fa-check"></i>Empirical Probability Insight</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><i class="fa fa-check"></i><b>6</b> One Sample Confidence Intervals on a Mean When the Population Variance is Known</a>
<ul>
<li class="chapter" data-level="6.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#interpretation"><i class="fa fa-check"></i><b>6.2</b> Interpretation</a></li>
<li class="chapter" data-level="6.3" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-mu-known-variance"><i class="fa fa-check"></i><b>6.3</b> Confidence Interval for <span class="math inline">\(\mu\)</span> (Known Variance)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-the-mean-of-a-normal-population"><i class="fa fa-check"></i>Confidence Interval for the Mean of a Normal Population</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#large-sample-ci-for-mu-normal-data"><i class="fa fa-check"></i>Large Sample CI for <span class="math inline">\(\mu\)</span> (Normal data)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#one-sample-ci-on-the-population-mean-mu"><i class="fa fa-check"></i>One Sample CI on the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#table-of-common-z-values"><i class="fa fa-check"></i>Table of Common <span class="math inline">\(z\)</span>-values</a></li>
<li class="chapter" data-level="6.4" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#appendix"><i class="fa fa-check"></i><b>6.4</b> APPENDIX</a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#pivotal-quantities"><i class="fa fa-check"></i>Pivotal quantities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><i class="fa fa-check"></i><b>7</b> One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown</a>
<ul>
<li class="chapter" data-level="7.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#cis-for-mu"><i class="fa fa-check"></i><b>7.1</b> CIs for <span class="math inline">\(\mu\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#independence-assumption"><i class="fa fa-check"></i>Independence Assumption</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#randomization-condition"><i class="fa fa-check"></i>Randomization Condition</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#standard-error"><i class="fa fa-check"></i>Standard Error</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#a-few-final-comments"><i class="fa fa-check"></i>A few final comments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="one-sample-confidence-intervals-on-a-proportion.html"><a href="one-sample-confidence-intervals-on-a-proportion.html"><i class="fa fa-check"></i><b>8</b> One Sample Confidence Intervals On a Proportion</a></li>
<li class="chapter" data-level="9" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Sample Size Selection using Confidence Intervals</a>
<ul>
<li class="chapter" data-level="9.0.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#empirical-rule"><i class="fa fa-check"></i><b>9.0.1</b> Empirical Rule</a></li>
<li class="chapter" data-level="9.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#secSampleSizeCIMean"><i class="fa fa-check"></i><b>9.1</b> Calculating Sample Size for a Confidence Interval on a Mean</a>
<ul>
<li class="chapter" data-level="" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#when-sigma-is-known"><i class="fa fa-check"></i>When <span class="math inline">\(\sigma\)</span> is Known</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#calculating-sample-size-for-a-confidence-interval-on-a-proportion"><i class="fa fa-check"></i><b>9.2</b> Calculating Sample Size for a Confidence Interval on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html"><i class="fa fa-check"></i><b>10</b> Two Sample Confidence Interval</a>
<ul>
<li class="chapter" data-level="10.1" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-a-difference-of-mean"><i class="fa fa-check"></i><b>10.1</b> Two Sample Confidence Interval on a Difference of Mean</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section.html"><a href="section.html"><i class="fa fa-check"></i><b>11</b> :::</a>
<ul>
<li class="chapter" data-level="11.1" data-path="section.html"><a href="section.html#two-sample-confidence-interval-on-paired-data"><i class="fa fa-check"></i><b>11.1</b> Two Sample Confidence Interval on Paired Data</a></li>
<li class="chapter" data-level="11.2" data-path="section.html"><a href="section.html#two-sample-confidence-interval-on-proportions"><i class="fa fa-check"></i><b>11.2</b> Two Sample Confidence Interval on Proportions</a></li>
<li class="chapter" data-level="11.3" data-path="section.html"><a href="section.html#two-sample-confidence-interval-on-variances"><i class="fa fa-check"></i><b>11.3</b> Two Sample Confidence Interval on Variances</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html"><i class="fa fa-check"></i><b>12</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="12.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-mean"><i class="fa fa-check"></i><b>12.1</b> Test of Hypothesis for One Mean</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-1-decide-on-a-level-of-significance-alpha"><i class="fa fa-check"></i>Step 1: Decide on a Level of Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-2-state-the-null-hypothesis-h_0-and-the-alternative-hypothesis-h_a"><i class="fa fa-check"></i>Step 2: State the Null Hypothesis (<span class="math inline">\(H_0\)</span>) and the Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-3-calculate-an-appropriate-test-statistic"><i class="fa fa-check"></i>Step 3: Calculate an appropriate test statistic</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-4-calculate-the-p-value"><i class="fa fa-check"></i>Step 4: Calculate the p-value</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-5-compare-p-value-to-level-of-significance-alpha-and-make-a-conclusion"><i class="fa fa-check"></i>Step 5: Compare <em>p</em>-value to level of significance <span class="math inline">\(\alpha\)</span> and make a conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-proportion"><i class="fa fa-check"></i><b>12.2</b> Test of Hypothesis for One Proportion</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing-significance-test"><i class="fa fa-check"></i>Introduction to Hypothesis Testing (Significance Test)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#steps-in-conducting-hypothesis-testing"><i class="fa fa-check"></i>Steps in conducting Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#some-additional-examples"><i class="fa fa-check"></i>Some Additional Examples</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-variance"><i class="fa fa-check"></i><b>12.3</b> Test of Hypothesis for One Variance</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><i class="fa fa-check"></i><b>13</b> One Sample Hypothesis Test on a Proportion and Variance</a>
<ul>
<li class="chapter" data-level="13.1" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html#one-sample-hypothesis-test-on-a-proportion"><i class="fa fa-check"></i><b>13.1</b> One Sample Hypothesis Test on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="statistical-power.html"><a href="statistical-power.html"><i class="fa fa-check"></i><b>14</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-ii-errors"><i class="fa fa-check"></i>Type I and II Errors</a></li>
<li class="chapter" data-level="14.1" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>14.1</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="14.2" data-path="statistical-power.html"><a href="statistical-power.html#using-power-to-determine-sample-size"><i class="fa fa-check"></i><b>14.2</b> Using Power to Determine Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html"><i class="fa fa-check"></i><b>15</b> Two Sample Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="15.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-with-independent-samples"><i class="fa fa-check"></i><b>15.1</b> Comparing Means with Independent Samples</a>
<ul>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#setting-up-hypotheses"><i class="fa fa-check"></i>Setting Up Hypotheses</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#structure-of-a-test-statistic"><i class="fa fa-check"></i>Structure of a Test Statistic</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#hypothesis-test-on-a-difference-of-means-mu_1---mu_2"><i class="fa fa-check"></i>Hypothesis Test on a Difference of Means (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-of-independent-samples-normal-population-assumptions"><i class="fa fa-check"></i>Comparing Means of Independent Samples (Normal Population Assumptions)</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-equal-variances-assumed"><i class="fa fa-check"></i><b>15.1.1</b> Comparing Two Populations Means: Independent Sampling (Equal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-with-equal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (with equal variances)</a></li>
<li class="chapter" data-level="15.1.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-unequal-variances-assumed"><i class="fa fa-check"></i><b>15.1.2</b> Comparing Two Populations Means: Independent Sampling (Unequal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-unequal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (Unequal Variances)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#degrees-of-freedom"><i class="fa fa-check"></i>Degrees of Freedom</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-t-test-unequal-variances"><i class="fa fa-check"></i>Two-Sample t-Test (Unequal Variances)</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#the-fold-rule"><i class="fa fa-check"></i><b>15.2</b> The Fold Rule</a></li>
<li class="chapter" data-level="15.3" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-paired-data"><i class="fa fa-check"></i><b>15.3</b> Two Sample Hypothesis Test on Paired Data</a></li>
<li class="chapter" data-level="15.4" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-proportions"><i class="fa fa-check"></i><b>15.4</b> Two Sample Hypothesis Test on Proportions</a></li>
<li class="chapter" data-level="15.5" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-variances"><i class="fa fa-check"></i><b>15.5</b> Two Sample Hypothesis Test on Variances</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html"><i class="fa fa-check"></i><b>16</b> Introduction to Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#measures-of-linear-relationship"><i class="fa fa-check"></i><b>16.1</b> Measures of Linear Relationship</a></li>
<li class="chapter" data-level="16.2" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#least-squares-method"><i class="fa fa-check"></i><b>16.2</b> Least Squares Method</a></li>
<li class="chapter" data-level="16.3" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>16.3</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="16.4" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#sst-sse-and-ssr"><i class="fa fa-check"></i><b>16.4</b> SST, SSE and SSR</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html"><i class="fa fa-check"></i><b>17</b> Inference for Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="17.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#inference-on-regression"><i class="fa fa-check"></i><b>17.1</b> Inference on Regression</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#estimating-variance-in-linear-regression"><i class="fa fa-check"></i>Estimating Variance in Linear Regression</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#the-regression-model"><i class="fa fa-check"></i>The Regression Model</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#interpreting-confidence-intervals-for-beta_1"><i class="fa fa-check"></i>Interpreting Confidence Intervals for <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#anova-table-analysis-of-variance"><i class="fa fa-check"></i><b>17.2</b> ANOVA Table (ANalysis Of VAriance)</a></li>
<li class="chapter" data-level="17.3" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#residual-plots"><i class="fa fa-check"></i><b>17.3</b> Residual Plots</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#what-to-look-for-in-a-good-residual-plot"><i class="fa fa-check"></i>What to Look for in a Good Residual Plot</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Demo Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="descriptive-statistics-and-an-introduction-to-r" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Descriptive Statistics and an Introduction to R<a href="descriptive-statistics-and-an-introduction-to-r.html#descriptive-statistics-and-an-introduction-to-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-1" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction<a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Intuitively, statistics can be considered the science of uncertainty.
Formally,</p>
<div class="definition">
<p><span id="def:unlabeled-div-1" class="definition"><strong>Definition 1.1  </strong></span>Statistics is the science of collecting, classifying, summarizing,
analyzing and interpreting data.</p>
</div>
<p><strong>Population, Sample, Parameter</strong></p>
<p>In statistics, researchers need to observe behavior, pattern, trends and
other types of data to give a conclusion. To make the conclusion more
persuasive, researchers require huge amount of data to support them,
that’s why study statistics need population.</p>
<div class="definition">
<p><span id="def:unlabeled-div-2" class="definition"><strong>Definition 1.2  </strong></span>In statistics, a population is a set of similar observations which is of
interest for some experimental questions. It can be a set of existing
objects such as all people in Canada, or hypothetical group of existing
objects such as the set of all possible hands in a game of poker.</p>
</div>
<p>However, data collection from population is a lot work. Usually,
researchers select a finite number of observations to study.</p>
<div class="definition">
<p><span id="def:unlabeled-div-3" class="definition"><strong>Definition 1.3  </strong></span>It refers to a selection of a subset from population that researchers
use it to estimate population characteristics.</p>
</div>
<p>Now, we have already chosen a sample, but how do we use it to estimate
population characteristics? This is the point where parameter comes to
play.</p>
<div class="definition">
<p><span id="def:unlabeled-div-4" class="definition"><strong>Definition 1.4  </strong></span>A parameter is a quantity of statistical population which summerizes
characteristics of the population. For example, mean, variance and
standard deviation.</p>
</div>
<p><strong>Descriptive and Inferential Statistics</strong></p>
<p>Now, we have set everything we need. A population, a chosen sample in
that population with its parameters. Next step is studying. There are
two major types of analysis: descriptive and Inferential statistics. In
this section, we are only going to give you a rough idea about what they
are, more detailed materials will be introduced in later chapters.</p>
<div class="definition">
<p><span id="def:unlabeled-div-5" class="definition"><strong>Definition 1.5  </strong></span>It refers to the summation of all quantitive values that describe
characteristics of the population. Usually, we use descriptive
statistics to summerize characteristics of a data set.</p>
</div>
<p>Furthermore, we use inferential statistics to do statistical analysis.</p>
<div class="definition">
<p><span id="def:unlabeled-div-6" class="definition"><strong>Definition 1.6  </strong></span>It refers to the process of using data analysis to indicate properties
of a population. For example, testing hypothesis and confidence interval
(both will be introduced in later chapters).</p>
</div>
<p><strong>Qualitative and Quantitative Data</strong></p>
<p>At this point, assume that we have finished all procedures such as
obtaining parameters and analyzing properties. Now, another important
thing is illustrating all the discovery.</p>
<div class="definition">
<p><span id="def:unlabeled-div-7" class="definition"><strong>Definition 1.7  </strong></span>This type of illustration refers to showing categorical data. For
example, lecture notes from a course, open-question survey.</p>
</div>
<p>To illustrate numerical data, we use quantitative data.</p>
<div class="definition">
<p><span id="def:unlabeled-div-8" class="definition"><strong>Definition 1.8  </strong></span>Unless the previous type of illustration, quantitative data is
represented numerically, including anything that can be counted,
measured, or given a numerical value. For example, STA258 final mark
score range from 100 different students who have taken this course.</p>
</div>
</div>
<div id="descriptive-statistics" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Descriptive Statistics<a href="descriptive-statistics-and-an-introduction-to-r.html#descriptive-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Previously, we defined descriptive statistics. Now, let’s introduce what
exact they are.<br />
<strong>Sample Mean, Variance and Standard Deviation</strong></p>
<p>Sample mean (or sample average) is the average value of a sample which
is selected from an interested population of an experiment. Usually, the
sample mean is used to estimate population mean. In other words, we say
that the sample mean is an estimator of population mean.</p>
<div class="definition">
<p><span id="def:unlabeled-div-9" class="definition"><strong>Definition 1.9  </strong></span>Let <span class="math inline">\(x_1, x_2, x_3, ..., x_n\)</span> be a sample of data points. We define
sample mean of the sample data points (<span class="math inline">\(\bar{x}\)</span>) as the following:
<span class="math display">\[\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i.\]</span> Also, we define sample
variance of the sample data points (<span class="math inline">\(s^2\)</span>) as:
<span class="math display">\[s^2 = \frac{1}{n-1} \sum_{i=1}^{n}(x_i - \bar{x})^2.\]</span> Moreover, the
standard deviation of the sample of data points (<span class="math inline">\(s\)</span>) is:
<span class="math display">\[s = \sqrt{s^2}, \quad \text{for } s &gt; 0.\]</span></p>
</div>
<p>Now, let’s move to variance. It refers to the expected value of the
squared deviation from the mean of a random variable in a population.
Similarly, we do have sample variance as well, which is the expected
value of the squared deviation from the mean of a random variable in a
selected sample. At this point, we can still use sample variance to
estimate population variance with adjustment, because the sample
variance may differ significantly based on what data points are chosen
from that population.</p>
<div class="definition">
<p><span id="def:unlabeled-div-10" class="definition"><strong>Definition 1.10  </strong></span>Let <span class="math inline">\(x_1, x_2, x_3, ..., x_n\)</span> be a sample of data points, we define
sample variance of the sample data points (<span class="math inline">\(s^2\)</span>) as:
<span class="math display">\[s^2 = \frac{1}{n-1} \sum_{i=1}^{n}(x_i - \bar{x})^2, \text{ where $\bar{x}$ is the sample mean of the data points.}\]</span></p>
</div>
<p>Next is standard deviation. It is a measure of the amount of variation
of the values of a variable about its mean. If standard deviation is
relatively larger, then data points are widely spread out from the mean.
Otherwise, data points stay close from the mean. Also, standard
deviation is obtained by taking squared root from variance which is
dependent on the choices of data points as well. To use sample standard
deviation as an estimator to population standard deviation, we still
need to adjust it.</p>
<div class="definition">
<p><span id="def:unlabeled-div-11" class="definition"><strong>Definition 1.11  </strong></span>Let <span class="math inline">\(x_1, x_2, x_3, ..., x_n\)</span> be a sample of data points. The standard
deviation of the sample of data points (<span class="math inline">\(s\)</span>) is:
<span class="math display">\[s = \sqrt{s^2}, \quad \text{for } s &gt; 0.\]</span></p>
</div>
<p><strong>Median and Mode</strong></p>
<p>The median and mode are two important measures of central tendency used
in statistics to summarize and understand data. The median represents
the middle value in a sorted dataset, giving a sense of the center that
is not affected by extreme values or outliers. In contrast, the mode is
the value that appears most frequently in a dataset, making it useful
for identifying common or repeated observations.</p>
<div class="definition">
<p><span id="def:unlabeled-div-12" class="definition"><strong>Definition 1.12  </strong></span>Let: <span class="math inline">\(x_1, x_2, x_3, ... , x_n\)</span> be a collection of data points which is
arranged in ascending order from the smallest value to the largest value
(or descending order from the largest value to the smallest value in
that collection). The median of the given collection of data points is
the middle value in that collection, which equally spreads the
collection into two parts. Half of all the collection values are above
the median value and the rest of the values in the collection is below
the median value.</p>
<ul>
<li><p>Case 1: when n is an odd number. (i.e. <span class="math inline">\(1, 3, 11, 237,...\)</span>). Then, the
median <span class="math inline">\(M\)</span> is defined as:
<span class="math display">\[M = \frac{n+1}{2} \text{, where n represents the $n^{th}$ position}.\]</span></p></li>
<li><p>Case 2: when n is an even number (i.e. <span class="math inline">\(2, 6, 100, 500,...\)</span>). Then,
the median <span class="math inline">\(M\)</span> is: the average value of <span class="math inline">\(\frac{n}{2}\)</span>’s and
<span class="math inline">\(\frac{n+2}{2}\)</span>’s position, where n represents the <span class="math inline">\(n^{th}\)</span> position.</p></li>
</ul>
</div>
<p>Now, let’s introduce mode.</p>
<div class="definition">
<p><span id="def:unlabeled-div-13" class="definition"><strong>Definition 1.13  </strong></span>It refers to a value that appears the most frequent than the appearance
of all other values in a given dataset.</p>
</div>
<p><strong>Percentile and Quartile</strong></p>
<p>Percentiles and quartiles are statistical measures used to describe the
distribution of data. A percentile indicates the value below which a
given percentage of observations fall, helping to understand relative
standing within a dataset. Quartiles, a specific type of percentile,
divide the data into four equal parts (Q1, Q2/median, and Q3), providing
insights into the spread and central tendency.</p>
<div class="definition">
<p><span id="def:unlabeled-div-14" class="definition"><strong>Definition 1.14  </strong></span>Let: <span class="math inline">\(x_1, x_2, ..., x_n\)</span> be a collection of data points in either
ascending order. Percentile is denoted as: <span class="math inline">\(p^{th}\)</span>, which indicates
<span class="math inline">\(p \%\)</span> of observations are below to a such value. Quartiles, are special
cases of percentile which equally spread the collection of data into
four parts. Each part contains <span class="math inline">\(25\%\)</span> of the entire collection. More
specifically, we define quartiles as the following:</p>
<ul>
<li><p><span class="math inline">\(Q_1\)</span>: the <span class="math inline">\(25\)</span> percentile (or <span class="math inline">\(25^{th}\)</span>), which shows that <span class="math inline">\(25\%\)</span> of
the data points are below the value <span class="math inline">\(Q_1\)</span>.</p></li>
<li><p><span class="math inline">\(Q_2\)</span>: the <span class="math inline">\(50\)</span> percentile (or <span class="math inline">\(50^{th}\)</span>), which shows that <span class="math inline">\(50\%\)</span> of
the data points are below the value <span class="math inline">\(Q_2\)</span>.</p></li>
<li><p><span class="math inline">\(Q_3\)</span>: the <span class="math inline">\(75\)</span> percentile (or <span class="math inline">\(75^{th}\)</span>), which shows that <span class="math inline">\(75\%\)</span> of
the data points are below the value <span class="math inline">\(Q_3\)</span>.</p></li>
<li><p><span class="math inline">\(Q_2\)</span> is qual to median.</p></li>
</ul>
<p>Moreover, we use <span class="math inline">\(Q_3 - Q_1\)</span> to calculate interquartile range (I.P.R),
which shows the spread of the whole data set.</p>
</div>
<p><strong>Skewness and Symmetry</strong></p>
<p>The two terms ‘skewness’ and ‘symmetry’ are used to describe the shape
of probability distribution. There are two types of skewness: left (or
negative) skew and right (or positive) skew. In real life, a famous
distribution highly used in hypothesis testing which is <span class="math inline">\(\chi_{n}^{2}\)</span>
with <span class="math inline">\(n\)</span> degrees of freedom, is right skewed probability distribution
function. Another example regarding to symmetry is normal distribution
such that its probability under its curve greater than <span class="math inline">\(\mu\)</span> is same as
the probability below than <span class="math inline">\(\mu\)</span>. Now let’s introduce the proper
definition of skewness and symmetry.</p>
<div class="definition">
<p><span id="def:unlabeled-div-15" class="definition"><strong>Definition 1.15  </strong></span>Skewness refers to such a measure of the asymmetry of the probability
distribution of a real-valued random variable about its mean. The
skewness value can be positive, zero, negative or undefined.</p>
</div>
<p>Now, let’s break down the main definition of skewness and symmetry:</p>
<div class="definition">
<p><span id="def:unlabeled-div-16" class="definition"><strong>Definition 1.16  </strong></span>By observing given probability distribution curve, if the left tail of
the curve is longer than the right tail the mass of the distribution is
concentrated on the right of the figure, then we say that probability
distribution is left skew or negative skew. (See figure below)</p>
</div>
<p>knitr::include_graphics(knitr::image_uri(“figures/Leftskew.jpg”))</p>
<div class="definition">
<p><span id="def:unlabeled-div-17" class="definition"><strong>Definition 1.17  </strong></span>By observing given probability distribution curve, if the right tail of
the curve is longer than the left tail the mass of the distribution is
concentrated on the left of the figure, then we say that probability
distribution is right skew or positive skew. (See figure below)</p>
</div>
<div class="float">
<img src="Section1/img/Rightskew.jpg" alt="Visualization of right skew probability distribution" />
<div class="figcaption">Visualization of right skew probability
distribution</div>
</div>
<p>Symmetry is a special case of skewness when the value of skewness is
<span class="math inline">\(0\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-18" class="definition"><strong>Definition 1.18  </strong></span>In statistics, symmetry s a probability distribution is reflected around
a vertical line at some value of the random variable represented by the
distribution. Probability under the curve below that value is equal to
probability under the curve greater than that value. (see figure below)</p>
</div>
<p>Since symmetry is a special case, so that it has a unique property as
the following:</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-19" class="theorem"><strong>Theorem 1.1  </strong></span>For any symmetric (bell-shaped) curve, let <span class="math inline">\(\mu\)</span> be its mean and
<span class="math inline">\(\sigma\)</span> be its standard deviation, the following probability set
function is true:</p>
<ul>
<li><p><span class="math inline">\(1.\)</span> <span class="math inline">\(P(\mu - \sigma &lt; X &lt; \mu + \sigma) = 68.27\%;\)</span></p></li>
<li><p><span class="math inline">\(2.\)</span> <span class="math inline">\(P(\mu - 2\sigma &lt; X &lt; \mu + 2\sigma) = 95.45\%;\)</span></p></li>
<li><p><span class="math inline">\(3.\)</span> <span class="math inline">\(P(\mu - 3\sigma &lt; X &lt; \mu + 3\sigma) = 99.73\%.\)</span></p></li>
</ul>
</div>
<div class="float">
<img src="Section1/img/Symmetry.jpg" alt="Visualization of symmetric probability distribution" />
<div class="figcaption">Visualization of symmetric probability
distribution</div>
</div>
<p><strong>Practice Example</strong></p>
<div class="example">
<p><span id="exm:unlabeled-div-20" class="example"><strong>Example 1.1  </strong></span>Let: <span class="math inline">\(x_1 = 1, x_2 = 3\)</span> and <span class="math inline">\(x_3 = 7\)</span>. Calculate the sample mean, sample
variance and sample standard deviation for this collection of data
points.<br />
Solution (all results are kept in four digits):<br />
By Definition <span class="math inline">\(1.9 \text{, } 1.10 \text{, } 1.11\)</span>, sample mean:
<span class="math display">\[\bar{x} = \frac{1+3+7}{3} \approx 3.6667.\]</span> Then, we use sample mean
to calculate sample variance:
<span class="math display">\[s^2 = \frac{1}{3-1} \times [(1-3.6667)^2+(3-3.6667)^2+(7-3.6667)^2] \approx 9.3333.\]</span>
Finally, we take the square root of sample variance to get sample
deviation, and remember that <span class="math inline">\(s &gt; 0\)</span>: <span class="math display">\[s = \sqrt{s^2} \approx 3.0551.\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>Example 1.2  </strong></span>Given two distinct collections of data points: <span class="math inline">\(S_1\)</span> = <span class="math inline">\(\{2, 4, 6\}\)</span> and
<span class="math inline">\(S_2\)</span> = <span class="math inline">\(\{1, 5, 16, 28\}\)</span>. Calculate the median of both two sets.<br />
Solution:<br />
For <span class="math inline">\(S_1\)</span>, since <span class="math inline">\(n = 3\)</span> which is an odd number, so by
<span class="math inline">\(Definition \text{ } 1.3\)</span>, <span class="math inline">\(M_{S_1} = 4\)</span>. For <span class="math inline">\(S_2\)</span>, <span class="math inline">\(n = 4\)</span> in this
case, so that we need to calculate the average of <span class="math inline">\(\frac{n}{2}\)</span> and
<span class="math inline">\(\frac{n+1}{2}\)</span>. Then, <span class="math display">\[M_{S_2} = \frac{5+16}{2} = 10.5.\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-22" class="example"><strong>Example 1.3  </strong></span>Consider the data set <span class="math inline">\(S =\)</span>
<span class="math inline">\(\{4, 25, 30, 30, 30, 32, 32, 35, 50, 50, 50, 55, 60, 74, 110\}\)</span>.
Calculate its median and <span class="math inline">\(Q_1\)</span> (<span class="math inline">\(25^{th}\)</span>).<br />
Solution:<br />
Simply counting the number of data points, <span class="math inline">\(n = 15\)</span>, such that <span class="math inline">\(M_{S}\)</span> =
<span class="math inline">\(\frac{15 + 1}{2}\)</span> = <span class="math inline">\(8\)</span>. Thus, the <span class="math inline">\(8^{th}\)</span> value in the set which is
<span class="math inline">\(35\)</span>.<br />
Since we know the median of this collection of data points, we just need
to find the median of the lower half of this data, which is exactly
going to be <span class="math inline">\(25\)</span> percentile (<span class="math inline">\(25^{th}\)</span>). In the lower half of the given
collection (all values below the median), <span class="math inline">\(n_{lower} = 7\)</span>. By
<span class="math inline">\(Definition \text{ } 1.3\)</span>, then median of the lower half (<span class="math inline">\(25^{th}\)</span>) is
going to be:
<span class="math display">\[25^{th} = \frac{7+1}{2} = 4, \text{ the $4^{th}$ position in the data set}.\]</span>
Thus, <span class="math inline">\(Q_1\)</span> (<span class="math inline">\(25^{th}\)</span>) <span class="math inline">\(= 30\)</span>. To find <span class="math inline">\(Q_3\)</span> (<span class="math inline">\(75^{th}\)</span>), apply the
same strategy will guide you to find the correct answer, and we leave
this as an exercise to you.</p>
</div>
</div>
<div id="graphical-techniques" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Graphical Techniques<a href="descriptive-statistics-and-an-introduction-to-r.html#graphical-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In statistics, there are lots of types of graph to illustrate data, for
example histograms and box-plots. This technique is used in the field of
statistics for data visualization. Our objective is to both be able to
identify some classical types of graph and interpret key statistical
values (descriptive statistical values) from it.</p>
<div id="histograms" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Histograms<a href="descriptive-statistics-and-an-introduction-to-r.html#histograms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Introduction to Histograms</strong></p>
<p>Histogram is a graphical representation of data that uses bars to
display the frequency distribution of a dataset. Unlike bar graphs,
which represent categorical data, histograms group numerical data into
intervals (bins) and show how many values fall into each range. This
makes histograms ideal for visualizing the shape, spread, and central
tendency of continuous data, helping identify patterns such as symmetry,
skewness, and outliers.</p>
<div class="float">
<img src="Section1/img/Histogram.jpg" alt="Visualization of histograms" />
<div class="figcaption">Visualization of histograms</div>
</div>
<p><strong>Advantages and Disadvantages of Histograms</strong></p>
<ul>
<li><p>Advantages of Histograms:<br />
<span class="math inline">\(1.\)</span> Histograms are easily to used for visualise data (relatively). It
allows us to get the idea of the "shape" of distribution (i.e.
skewness which will be discussed late in this section).<br />
<span class="math inline">\(2.\)</span> It is also flexible that people are able to modify bin widths.</p></li>
<li><p>Disadvantages of Histograms:<br />
<span class="math inline">\(1.\)</span> It is not suitable for small data sets.<br />
<span class="math inline">\(2.\)</span> The values from histograms close to breaking points are likely
similar, in fact they need to be classified into different bins (i.e.
Student A and B scores 79 and 80 respectively in STA258, we consider a
breaking point between 79 and 80. The two students have similar score,
but student A is <span class="math inline">\(B+\)</span> and student B is <span class="math inline">\(A-\)</span> in GPA from).</p></li>
</ul>
<p><strong>Histograms with Skewness and Symmetry</strong></p>
<p>A histogram visually represents the distribution of numerical data,
making it a useful tool for assessing skewness and symmetry. It is quite
straightforward to estimate the skewness of histograms by simply drawing
a curve above bins on the histogram.<br />
For a histogram to have a left (or negative) skew probability
distribution:</p>
<div class="float">
<img src="Section1/img/HisL.jpg" alt="Visualization of a histogram has a left (or negative) skew probability distribution" />
<div class="figcaption">Visualization of a histogram has a left (or negative) skew probability
distribution</div>
</div>
<p>For a histogram to have a right (or positive) skew probability
distribution:</p>
<div class="float">
<img src="Section1/img/HisR.jpg" alt="Visualization of a histogram has a right (or positive) skew probability distribution" />
<div class="figcaption">Visualization of a histogram has a right (or positive) skew
probability distribution</div>
</div>
<p>For a histogram to have a symmetric probability distribution:</p>
<div class="float">
<img src="Section1/img/HisS.jpg" alt="Visualization of a histogram has a symmetric probability distribution" />
<div class="figcaption">Visualization of a histogram has a symmetric probability
distribution</div>
</div>
</div>
<div id="box-plots" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Box-Plots<a href="descriptive-statistics-and-an-introduction-to-r.html#box-plots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A boxplot (or box-and-whisker plot) is a standardized way to display
data distribution based on a five-number summary: minimum, first
quartile (Q1), median (Q2), third quartile (Q3), and maximum. The box
represents the interquartile range (IQR), while the whiskers show
variability outside Q1 and Q3. Outliers are plotted as individual
points. Boxplots efficiently compare distributions and highlight
skewness, spread, and outliers. (See figure below)</p>
<div class="float">
<img src="Section1/img/BoxPlot.jpg" alt="Visualization of a box-plot" />
<div class="figcaption">Visualization of a box-plot</div>
</div>
<p>Similar to histograms, we can still obtain information about skewness
and symmetry, by observing the cut from the line of Q2.<br />
If the median (Q2) cuts the box with upper area smaller than lower area,
then we say that box-plot with left skew probability distribution. Or,
if the median (Q2) cuts the box with upper area larger than lower area,
then we say that box-plot with right skew probability distribution.<br />
Otherwise, if the median (Q2) cuts the box with upper area equal to
lower area, then we say that box-plot with symmetric probability
distribution.</p>
<div class="float">
<img src="Section1/img/Bskew.jpg" alt="Visualization of a box-plot with skew and symmetric probability distribution" />
<div class="figcaption">Visualization of a box-plot with skew and symmetric probability
distribution</div>
</div>
</div>
</div>
<div id="introduction-to-r" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Introduction to R<a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-to-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R is used for data manipulation, statistics, and graphics. It is made
of: operations (<span class="math inline">\(+\)</span>,<span class="math inline">\(-\)</span>, <span class="math inline">\(&lt;\)</span>) which is for calculations on vectors,
arrays and matrices; a huge collection of functions; facilities for
making unlimited types quality graphs; user contributed packages (sets
of related functions); the ability to interface with procedures written
in C, C+, or FORTRAN and to write additional primitives. R is also an
open-source computing package which has seen a huge growth in popularity
in the last few years (Please use this website:
<a href="https://cran.r-project.org" class="uri">https://cran.r-project.org</a>, to download R).<br />
<strong>What is R-studio?</strong></p>
<p>RStudio is a relatively new editor specially targeted at R. RStudio is
cross-platform, free and open-source software (Please use:
<a href="https://www.rstudio.com" class="uri">https://www.rstudio.com</a>, to download Rstudio).<br />
<strong>Make a Histogram Using R-studio</strong></p>
<p>This is just a demonstration of how to start and use R-studio.</p>
<p>. First of all, we need to know which dataset are we going to make into
a histogram. In this case, as an example, we are going to use the
waiting time in faithful in R-studio.<br />
2. For any dataset, use the code: names(faithful) to get it. (inside the
parentheses, type the names of variables you want in faithful dataset)<br />
3. Then, we proceed with the code: hist(faithful$waiting) to get a
basic plot.<br />
</p>
<div class="float">
<img src="Section1/img/R1.jpg" alt="R-studio first three steps (by following the instructions, you should get this histogram)" />
<div class="figcaption">R-studio first three steps (by following the instructions, you should
get this histogram)</div>
</div>
<p>. Furthermore, we can also get more information. For example, by keep
proceeding with the code: hist(faithful$waiting,plot=FALSE)$breaks,
R-studio will show you all the breaking points between histogram cells.</p>
<div class="float">
<img src="Section1/img/R2.jpg" alt="R-studio the forth step(by following the instructions, you should get this histogram)" />
<div class="figcaption">R-studio the forth step(by following the instructions, you should get
this histogram)</div>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sampling-distributions-related-to-a-normal-population.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
