<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>32 Inference for Simple Linear Regression | Demo Book</title>
  <meta name="description" content="32 Inference for Simple Linear Regression | Demo Book" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="32 Inference for Simple Linear Regression | Demo Book" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="32 Inference for Simple Linear Regression | Demo Book" />
  
  
  

<meta name="author" content="Nishan Mudalige" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-to-simple-linear-regression-1.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>STA258: Statistics with Applied Probability</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nishan-mudalige-masoud-ataei-nurlana-alili-bryan-xu"><i class="fa fa-check"></i>Nishan Mudalige, Masoud Ataei, Nurlana Alili, Bryan Xu</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Descriptive Statistics and an Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#descriptive-statistics"><i class="fa fa-check"></i><b>1.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#graphical-techniques"><i class="fa fa-check"></i><b>1.3</b> Graphical Techniques</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#histograms"><i class="fa fa-check"></i><b>1.3.1</b> Histograms</a></li>
<li class="chapter" data-level="1.3.2" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#box-plots"><i class="fa fa-check"></i><b>1.3.2</b> Box-Plots</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="descriptive-statistics-and-an-introduction-to-r.html"><a href="descriptive-statistics-and-an-introduction-to-r.html#introduction-to-r"><i class="fa fa-check"></i><b>1.4</b> Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html"><i class="fa fa-check"></i><b>2</b> Sampling Distributions Related to a Normal Population</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#normal-distribution"><i class="fa fa-check"></i><b>2.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="2.2" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#gamma-and-chi-square-distribution"><i class="fa fa-check"></i><b>2.2</b> Gamma and Chi-square Distribution</a></li>
<li class="chapter" data-level="2.3" data-path="sampling-distributions-related-to-a-normal-population.html"><a href="sampling-distributions-related-to-a-normal-population.html#students-t-distribution-and-f-distribution"><i class="fa fa-check"></i><b>2.3</b> Studentâ€™s t-Distribution and F-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-central-limit-theorem.html"><a href="the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html"><i class="fa fa-check"></i><b>4</b> Normal Approximation to the Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution"><i class="fa fa-check"></i><b>4.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-the-sum-and-mgf-derivation"><i class="fa fa-check"></i><b>4.3</b> Sampling Distribution of the Sum and MGF Derivation</a></li>
<li class="chapter" data-level="4.4" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#binomial-distribution"><i class="fa fa-check"></i><b>4.4</b> Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#visualizing-the-pmf-of-binomial-distributions"><i class="fa fa-check"></i><b>4.4.1</b> Visualizing the PMF of Binomial Distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#sampling-distribution-of-a-sample-proportion-and-the-normal-approximation"><i class="fa fa-check"></i><b>4.5</b> Sampling Distribution of a Sample Proportion and the Normal Approximation</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#conditions-for-using-the-normal-approximation"><i class="fa fa-check"></i>Conditions for Using the Normal Approximation</a></li>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution-binomial-with-n-1"><i class="fa fa-check"></i>Bernoulli Distribution (Binomial with <span class="math inline">\(n = 1\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#normal-approximation-to-binomial"><i class="fa fa-check"></i><b>4.6</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="4.7" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction"><i class="fa fa-check"></i><b>4.7</b> Continuity Correction</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction-table"><i class="fa fa-check"></i>Continuity Correction Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html"><i class="fa fa-check"></i><b>5</b> Law of Large Numbers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#convergence-in-probability"><i class="fa fa-check"></i><b>5.1</b> Convergence in Probability</a></li>
<li class="chapter" data-level="5.2" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i><b>5.2</b> Weak Law of Large Numbers (WLLN)</a>
<ul>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#proof-of-the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i>Proof of the Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#empirical-probability-insight"><i class="fa fa-check"></i>Empirical Probability Insight</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><i class="fa fa-check"></i><b>6</b> One Sample Confidence Intervals on a Mean When the Population Variance is Known</a>
<ul>
<li class="chapter" data-level="6.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#interpretation"><i class="fa fa-check"></i><b>6.2</b> Interpretation</a></li>
<li class="chapter" data-level="6.3" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-mu-known-variance"><i class="fa fa-check"></i><b>6.3</b> Confidence Interval for <span class="math inline">\(\mu\)</span> (Known Variance)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-the-mean-of-a-normal-population"><i class="fa fa-check"></i>Confidence Interval for the Mean of a Normal Population</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#large-sample-ci-for-mu-normal-data"><i class="fa fa-check"></i>Large Sample CI for <span class="math inline">\(\mu\)</span> (Normal data)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#one-sample-ci-on-the-population-mean-mu"><i class="fa fa-check"></i>One Sample CI on the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#table-of-common-z-values"><i class="fa fa-check"></i>Table of Common <span class="math inline">\(z\)</span>-values</a></li>
<li class="chapter" data-level="6.4" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#appendix"><i class="fa fa-check"></i><b>6.4</b> APPENDIX</a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#pivotal-quantities"><i class="fa fa-check"></i>Pivotal quantities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><i class="fa fa-check"></i><b>7</b> One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown</a>
<ul>
<li class="chapter" data-level="7.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#cis-for-mu"><i class="fa fa-check"></i><b>7.1</b> CIs for <span class="math inline">\(\mu\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#independence-assumption"><i class="fa fa-check"></i>Independence Assumption</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#randomization-condition"><i class="fa fa-check"></i>Randomization Condition</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#standard-error"><i class="fa fa-check"></i>Standard Error</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#a-few-final-comments"><i class="fa fa-check"></i>A few final comments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="one-sample-confidence-intervals-on-a-proportion.html"><a href="one-sample-confidence-intervals-on-a-proportion.html"><i class="fa fa-check"></i><b>8</b> One Sample Confidence Intervals On a Proportion</a></li>
<li class="chapter" data-level="9" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Sample Size Selection using Confidence Intervals</a>
<ul>
<li class="chapter" data-level="9.0.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#empirical-rule"><i class="fa fa-check"></i><b>9.0.1</b> Empirical Rule</a></li>
<li class="chapter" data-level="9.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#secSampleSizeCIMean"><i class="fa fa-check"></i><b>9.1</b> Calculating Sample Size for a Confidence Interval on a Mean</a>
<ul>
<li class="chapter" data-level="" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#when-sigma-is-known"><i class="fa fa-check"></i>When <span class="math inline">\(\sigma\)</span> is Known</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#calculating-sample-size-for-a-confidence-interval-on-a-proportion"><i class="fa fa-check"></i><b>9.2</b> Calculating Sample Size for a Confidence Interval on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html"><i class="fa fa-check"></i><b>10</b> Two Sample Confidence Interval</a>
<ul>
<li class="chapter" data-level="10.1" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-a-difference-of-mean"><i class="fa fa-check"></i><b>10.1</b> Two Sample Confidence Interval on a Difference of Mean</a></li>
<li class="chapter" data-level="10.2" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-paired-data"><i class="fa fa-check"></i><b>10.2</b> Two Sample Confidence Interval on Paired Data</a></li>
<li class="chapter" data-level="10.3" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-proportions"><i class="fa fa-check"></i><b>10.3</b> Two Sample Confidence Interval on Proportions</a></li>
<li class="chapter" data-level="10.4" data-path="two-sample-confidence-interval.html"><a href="two-sample-confidence-interval.html#two-sample-confidence-interval-on-variances"><i class="fa fa-check"></i><b>10.4</b> Two Sample Confidence Interval on Variances</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-mean"><i class="fa fa-check"></i><b>11.1</b> Test of Hypothesis for One Mean</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-1-decide-on-a-level-of-significance-alpha"><i class="fa fa-check"></i>Step 1: Decide on a Level of Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-2-state-the-null-hypothesis-h_0-and-the-alternative-hypothesis-h_a"><i class="fa fa-check"></i>Step 2: State the Null Hypothesis (<span class="math inline">\(H_0\)</span>) and the Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-3-calculate-an-appropriate-test-statistic"><i class="fa fa-check"></i>Step 3: Calculate an appropriate test statistic</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-4-calculate-the-p-value"><i class="fa fa-check"></i>Step 4: Calculate the p-value</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-5-compare-p-value-to-level-of-significance-alpha-and-make-a-conclusion"><i class="fa fa-check"></i>Step 5: Compare <em>p</em>-value to level of significance <span class="math inline">\(\alpha\)</span> and make a conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-proportion"><i class="fa fa-check"></i><b>11.2</b> Test of Hypothesis for One Proportion</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing-significance-test"><i class="fa fa-check"></i>Introduction to Hypothesis Testing (Significance Test)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#steps-in-conducting-hypothesis-testing"><i class="fa fa-check"></i>Steps in conducting Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#some-additional-examples"><i class="fa fa-check"></i>Some Additional Examples</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-of-hypothesis-for-one-variance"><i class="fa fa-check"></i><b>11.3</b> Test of Hypothesis for One Variance</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><i class="fa fa-check"></i><b>12</b> One Sample Hypothesis Test on a Proportion and Variance</a>
<ul>
<li class="chapter" data-level="12.1" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance.html#one-sample-hypothesis-test-on-a-proportion"><i class="fa fa-check"></i><b>12.1</b> One Sample Hypothesis Test on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="statistical-power.html"><a href="statistical-power.html"><i class="fa fa-check"></i><b>13</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-ii-errors"><i class="fa fa-check"></i>Type I and II Errors</a></li>
<li class="chapter" data-level="13.1" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>13.1</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="13.2" data-path="statistical-power.html"><a href="statistical-power.html#using-power-to-determine-sample-size"><i class="fa fa-check"></i><b>13.2</b> Using Power to Determine Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html"><i class="fa fa-check"></i><b>14</b> Two Sample Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="14.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-with-independent-samples"><i class="fa fa-check"></i><b>14.1</b> Comparing Means with Independent Samples</a>
<ul>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#setting-up-hypotheses"><i class="fa fa-check"></i>Setting Up Hypotheses</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#structure-of-a-test-statistic"><i class="fa fa-check"></i>Structure of a Test Statistic</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#hypothesis-test-on-a-difference-of-means-mu_1---mu_2"><i class="fa fa-check"></i>Hypothesis Test on a Difference of Means (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-of-independent-samples-normal-population-assumptions"><i class="fa fa-check"></i>Comparing Means of Independent Samples (Normal Population Assumptions)</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-equal-variances-assumed"><i class="fa fa-check"></i><b>14.1.1</b> Comparing Two Populations Means: Independent Sampling (Equal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-with-equal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (with equal variances)</a></li>
<li class="chapter" data-level="14.1.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-two-populations-means-independent-sampling-unequal-variances-assumed"><i class="fa fa-check"></i><b>14.1.2</b> Comparing Two Populations Means: Independent Sampling (Unequal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-unequal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (Unequal Variances)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#degrees-of-freedom"><i class="fa fa-check"></i>Degrees of Freedom</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-t-test-unequal-variances"><i class="fa fa-check"></i>Two-Sample t-Test (Unequal Variances)</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#the-fold-rule"><i class="fa fa-check"></i><b>14.2</b> The Fold Rule</a></li>
<li class="chapter" data-level="14.3" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-paired-data"><i class="fa fa-check"></i><b>14.3</b> Two Sample Hypothesis Test on Paired Data</a></li>
<li class="chapter" data-level="14.4" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-proportions"><i class="fa fa-check"></i><b>14.4</b> Two Sample Hypothesis Test on Proportions</a></li>
<li class="chapter" data-level="14.5" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-hypothesis-test-on-variances"><i class="fa fa-check"></i><b>14.5</b> Two Sample Hypothesis Test on Variances</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html"><i class="fa fa-check"></i><b>15</b> Introduction to Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#measures-of-linear-relationship"><i class="fa fa-check"></i><b>15.1</b> Measures of Linear Relationship</a></li>
<li class="chapter" data-level="15.2" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#least-squares-method"><i class="fa fa-check"></i><b>15.2</b> Least Squares Method</a></li>
<li class="chapter" data-level="15.3" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>15.3</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="15.4" data-path="introduction-to-simple-linear-regression.html"><a href="introduction-to-simple-linear-regression.html#sst-sse-and-ssr"><i class="fa fa-check"></i><b>15.4</b> SST, SSE and SSR</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html"><i class="fa fa-check"></i><b>16</b> Inference for Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#inference-on-regression"><i class="fa fa-check"></i><b>16.1</b> Inference on Regression</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#estimating-variance-in-linear-regression"><i class="fa fa-check"></i>Estimating Variance in Linear Regression</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#the-regression-model"><i class="fa fa-check"></i>The Regression Model</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#interpreting-confidence-intervals-for-beta_1"><i class="fa fa-check"></i>Interpreting Confidence Intervals for <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#anova-table-analysis-of-variance"><i class="fa fa-check"></i><b>16.2</b> ANOVA Table (ANalysis Of VAriance)</a></li>
<li class="chapter" data-level="16.3" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#residual-plots"><i class="fa fa-check"></i><b>16.3</b> Residual Plots</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#what-to-look-for-in-a-good-residual-plot"><i class="fa fa-check"></i>What to Look for in a Good Residual Plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="sta258-statistics-with-applied-probability-1.html"><a href="sta258-statistics-with-applied-probability-1.html"><i class="fa fa-check"></i>STA258: Statistics with Applied Probability</a>
<ul>
<li class="chapter" data-level="" data-path="sta258-statistics-with-applied-probability-1.html"><a href="sta258-statistics-with-applied-probability-1.html#nishan-mudalige-masoud-ataei-nurlana-alili-bryan-xu-1"><i class="fa fa-check"></i>Nishan Mudalige, Masoud Ataei, Nurlana Alili, Bryan Xu</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="17" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html"><i class="fa fa-check"></i><b>17</b> Descriptive Statistics and an Introduction to R</a>
<ul>
<li class="chapter" data-level="17.1" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#introduction-5"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>17.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="17.3" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#graphical-techniques-1"><i class="fa fa-check"></i><b>17.3</b> Graphical Techniques</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#histograms-1"><i class="fa fa-check"></i><b>17.3.1</b> Histograms</a></li>
<li class="chapter" data-level="17.3.2" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#box-plots-1"><i class="fa fa-check"></i><b>17.3.2</b> Box-Plots</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="descriptive-statistics-and-an-introduction-to-r-1.html"><a href="descriptive-statistics-and-an-introduction-to-r-1.html#introduction-to-r-1"><i class="fa fa-check"></i><b>17.4</b> Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="sampling-distributions-related-to-a-normal-population-1.html"><a href="sampling-distributions-related-to-a-normal-population-1.html"><i class="fa fa-check"></i><b>18</b> Sampling Distributions Related to a Normal Population</a>
<ul>
<li class="chapter" data-level="18.1" data-path="sampling-distributions-related-to-a-normal-population-1.html"><a href="sampling-distributions-related-to-a-normal-population-1.html#normal-distribution-1"><i class="fa fa-check"></i><b>18.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="18.2" data-path="sampling-distributions-related-to-a-normal-population-1.html"><a href="sampling-distributions-related-to-a-normal-population-1.html#gamma-and-chi-square-distribution-1"><i class="fa fa-check"></i><b>18.2</b> Gamma and Chi-square Distribution</a></li>
<li class="chapter" data-level="18.3" data-path="sampling-distributions-related-to-a-normal-population-1.html"><a href="sampling-distributions-related-to-a-normal-population-1.html#students-t-distribution-and-f-distribution-1"><i class="fa fa-check"></i><b>18.3</b> Studentâ€™s t-Distribution and F-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="the-central-limit-theorem-1.html"><a href="the-central-limit-theorem-1.html"><i class="fa fa-check"></i><b>19</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="20" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html"><i class="fa fa-check"></i><b>20</b> Normal Approximation to the Binomial Distribution</a>
<ul>
<li class="chapter" data-level="20.1" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#introduction-6"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#bernoulli-distribution-1"><i class="fa fa-check"></i><b>20.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="20.3" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#sampling-distribution-of-the-sum-and-mgf-derivation-1"><i class="fa fa-check"></i><b>20.3</b> Sampling Distribution of the Sum and MGF Derivation</a></li>
<li class="chapter" data-level="20.4" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#binomial-distribution-1"><i class="fa fa-check"></i><b>20.4</b> Binomial Distribution</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#visualizing-the-pmf-of-binomial-distributions-1"><i class="fa fa-check"></i><b>20.4.1</b> Visualizing the PMF of Binomial Distributions</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#sampling-distribution-of-a-sample-proportion-and-the-normal-approximation-1"><i class="fa fa-check"></i><b>20.5</b> Sampling Distribution of a Sample Proportion and the Normal Approximation</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#conditions-for-using-the-normal-approximation"><i class="fa fa-check"></i>Conditions for Using the Normal Approximation</a></li>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#bernoulli-distribution-binomial-with-n-1"><i class="fa fa-check"></i>Bernoulli Distribution (Binomial with <span class="math inline">\(n = 1\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#normal-approximation-to-binomial-1"><i class="fa fa-check"></i><b>20.6</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="20.7" data-path="normal-approximation-to-the-binomial-distribution-1.html"><a href="normal-approximation-to-the-binomial-distribution-1.html#continuity-correction-1"><i class="fa fa-check"></i><b>20.7</b> Continuity Correction</a>
<ul>
<li class="chapter" data-level="" data-path="normal-approximation-to-the-binomial-distribution.html"><a href="normal-approximation-to-the-binomial-distribution.html#continuity-correction-table"><i class="fa fa-check"></i>Continuity Correction Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="law-of-large-numbers-1.html"><a href="law-of-large-numbers-1.html"><i class="fa fa-check"></i><b>21</b> Law of Large Numbers</a>
<ul>
<li class="chapter" data-level="21.1" data-path="law-of-large-numbers-1.html"><a href="law-of-large-numbers-1.html#convergence-in-probability-1"><i class="fa fa-check"></i><b>21.1</b> Convergence in Probability</a></li>
<li class="chapter" data-level="21.2" data-path="law-of-large-numbers-1.html"><a href="law-of-large-numbers-1.html#weak-law-of-large-numbers-wlln-1"><i class="fa fa-check"></i><b>21.2</b> Weak Law of Large Numbers (WLLN)</a>
<ul>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#proof-of-the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i>Proof of the Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html#empirical-probability-insight"><i class="fa fa-check"></i>Empirical Probability Insight</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><i class="fa fa-check"></i><b>22</b> One Sample Confidence Intervals on a Mean When the Population Variance is Known</a>
<ul>
<li class="chapter" data-level="22.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html#introduction-7"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html#interpretation-1"><i class="fa fa-check"></i><b>22.2</b> Interpretation</a></li>
<li class="chapter" data-level="22.3" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html#confidence-interval-for-mu-known-variance-1"><i class="fa fa-check"></i><b>22.3</b> Confidence Interval for <span class="math inline">\(\mu\)</span> (Known Variance)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#confidence-interval-for-the-mean-of-a-normal-population"><i class="fa fa-check"></i>Confidence Interval for the Mean of a Normal Population</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#large-sample-ci-for-mu-normal-data"><i class="fa fa-check"></i>Large Sample CI for <span class="math inline">\(\mu\)</span> (Normal data)</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#one-sample-ci-on-the-population-mean-mu"><i class="fa fa-check"></i>One Sample CI on the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#table-of-common-z-values"><i class="fa fa-check"></i>Table of Common <span class="math inline">\(z\)</span>-values</a></li>
<li class="chapter" data-level="22.4" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known-1.html#appendix-1"><i class="fa fa-check"></i><b>22.4</b> APPENDIX</a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-known.html#pivotal-quantities"><i class="fa fa-check"></i>Pivotal quantities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown-1.html"><i class="fa fa-check"></i><b>23</b> One-Sample Confidence Intervals on a Mean When the Population Variance is Unknown</a>
<ul>
<li class="chapter" data-level="23.1" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown-1.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown-1.html#cis-for-mu-1"><i class="fa fa-check"></i><b>23.1</b> CIs for <span class="math inline">\(\mu\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#independence-assumption"><i class="fa fa-check"></i>Independence Assumption</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#randomization-condition"><i class="fa fa-check"></i>Randomization Condition</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#standard-error"><i class="fa fa-check"></i>Standard Error</a></li>
<li class="chapter" data-level="" data-path="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html"><a href="one-sample-confidence-intervals-on-a-mean-when-the-population-variance-is-unknown.html#a-few-final-comments"><i class="fa fa-check"></i>A few final comments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="one-sample-confidence-intervals-on-a-proportion-1.html"><a href="one-sample-confidence-intervals-on-a-proportion-1.html"><i class="fa fa-check"></i><b>24</b> One Sample Confidence Intervals On a Proportion</a></li>
<li class="chapter" data-level="25" data-path="sample-size-selection-using-confidence-intervals-1.html"><a href="sample-size-selection-using-confidence-intervals-1.html"><i class="fa fa-check"></i><b>25</b> Sample Size Selection using Confidence Intervals</a>
<ul>
<li class="chapter" data-level="25.0.1" data-path="sample-size-selection-using-confidence-intervals-1.html"><a href="sample-size-selection-using-confidence-intervals-1.html#empirical-rule-1"><i class="fa fa-check"></i><b>25.0.1</b> Empirical Rule</a></li>
<li class="chapter" data-level="25.1" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#secSampleSizeCIMean"><i class="fa fa-check"></i><b>25.1</b> Calculating Sample Size for a Confidence Interval on a Mean</a>
<ul>
<li class="chapter" data-level="" data-path="sample-size-selection-using-confidence-intervals.html"><a href="sample-size-selection-using-confidence-intervals.html#when-sigma-is-known"><i class="fa fa-check"></i>When <span class="math inline">\(\sigma\)</span> is Known</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="sample-size-selection-using-confidence-intervals-1.html"><a href="sample-size-selection-using-confidence-intervals-1.html#calculating-sample-size-for-a-confidence-interval-on-a-proportion-1"><i class="fa fa-check"></i><b>25.2</b> Calculating Sample Size for a Confidence Interval on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="two-sample-confidence-interval-1.html"><a href="two-sample-confidence-interval-1.html"><i class="fa fa-check"></i><b>26</b> Two Sample Confidence Interval</a>
<ul>
<li class="chapter" data-level="26.1" data-path="two-sample-confidence-interval-1.html"><a href="two-sample-confidence-interval-1.html#two-sample-confidence-interval-on-a-difference-of-mean-1"><i class="fa fa-check"></i><b>26.1</b> Two Sample Confidence Interval on a Difference of Mean</a></li>
<li class="chapter" data-level="26.2" data-path="two-sample-confidence-interval-1.html"><a href="two-sample-confidence-interval-1.html#two-sample-confidence-interval-on-paired-data-1"><i class="fa fa-check"></i><b>26.2</b> Two Sample Confidence Interval on Paired Data</a></li>
<li class="chapter" data-level="26.3" data-path="two-sample-confidence-interval-1.html"><a href="two-sample-confidence-interval-1.html#two-sample-confidence-interval-on-proportions-1"><i class="fa fa-check"></i><b>26.3</b> Two Sample Confidence Interval on Proportions</a></li>
<li class="chapter" data-level="26.4" data-path="two-sample-confidence-interval-1.html"><a href="two-sample-confidence-interval-1.html#two-sample-confidence-interval-on-variances-1"><i class="fa fa-check"></i><b>26.4</b> Two Sample Confidence Interval on Variances</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="introduction-to-hypothesis-testing-1.html"><a href="introduction-to-hypothesis-testing-1.html"><i class="fa fa-check"></i><b>27</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="27.1" data-path="introduction-to-hypothesis-testing-1.html"><a href="introduction-to-hypothesis-testing-1.html#test-of-hypothesis-for-one-mean-1"><i class="fa fa-check"></i><b>27.1</b> Test of Hypothesis for One Mean</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-1-decide-on-a-level-of-significance-alpha"><i class="fa fa-check"></i>Step 1: Decide on a Level of Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-2-state-the-null-hypothesis-h_0-and-the-alternative-hypothesis-h_a"><i class="fa fa-check"></i>Step 2: State the Null Hypothesis (<span class="math inline">\(H_0\)</span>) and the Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-3-calculate-an-appropriate-test-statistic"><i class="fa fa-check"></i>Step 3: Calculate an appropriate test statistic</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-4-calculate-the-p-value"><i class="fa fa-check"></i>Step 4: Calculate the p-value</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#step-5-compare-p-value-to-level-of-significance-alpha-and-make-a-conclusion"><i class="fa fa-check"></i>Step 5: Compare <em>p</em>-value to level of significance <span class="math inline">\(\alpha\)</span> and make a conclusion</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="introduction-to-hypothesis-testing-1.html"><a href="introduction-to-hypothesis-testing-1.html#test-of-hypothesis-for-one-proportion-1"><i class="fa fa-check"></i><b>27.2</b> Test of Hypothesis for One Proportion</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing-significance-test"><i class="fa fa-check"></i>Introduction to Hypothesis Testing (Significance Test)</a></li>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#steps-in-conducting-hypothesis-testing"><i class="fa fa-check"></i>Steps in conducting Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#some-additional-examples"><i class="fa fa-check"></i>Some Additional Examples</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="introduction-to-hypothesis-testing-1.html"><a href="introduction-to-hypothesis-testing-1.html#test-of-hypothesis-for-one-variance-1"><i class="fa fa-check"></i><b>27.3</b> Test of Hypothesis for One Variance</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance-1.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance-1.html"><i class="fa fa-check"></i><b>28</b> One Sample Hypothesis Test on a Proportion and Variance</a>
<ul>
<li class="chapter" data-level="28.1" data-path="one-sample-hypothesis-test-on-a-proportion-and-variance-1.html"><a href="one-sample-hypothesis-test-on-a-proportion-and-variance-1.html#one-sample-hypothesis-test-on-a-proportion-1"><i class="fa fa-check"></i><b>28.1</b> One Sample Hypothesis Test on a Proportion</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="statistical-power-2.html"><a href="statistical-power-2.html"><i class="fa fa-check"></i><b>29</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-power.html"><a href="statistical-power.html#type-i-and-ii-errors"><i class="fa fa-check"></i>Type I and II Errors</a></li>
<li class="chapter" data-level="29.1" data-path="statistical-power-2.html"><a href="statistical-power-2.html#type-i-and-type-ii-errors-1"><i class="fa fa-check"></i><b>29.1</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="29.2" data-path="statistical-power-2.html"><a href="statistical-power-2.html#using-power-to-determine-sample-size-1"><i class="fa fa-check"></i><b>29.2</b> Using Power to Determine Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html"><i class="fa fa-check"></i><b>30</b> Two Sample Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="30.1" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#comparing-means-with-independent-samples-1"><i class="fa fa-check"></i><b>30.1</b> Comparing Means with Independent Samples</a>
<ul>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#setting-up-hypotheses"><i class="fa fa-check"></i>Setting Up Hypotheses</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#structure-of-a-test-statistic"><i class="fa fa-check"></i>Structure of a Test Statistic</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#hypothesis-test-on-a-difference-of-means-mu_1---mu_2"><i class="fa fa-check"></i>Hypothesis Test on a Difference of Means (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#comparing-means-of-independent-samples-normal-population-assumptions"><i class="fa fa-check"></i>Comparing Means of Independent Samples (Normal Population Assumptions)</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#comparing-two-populations-means-independent-sampling-equal-variances-assumed-1"><i class="fa fa-check"></i><b>30.1.1</b> Comparing Two Populations Means: Independent Sampling (Equal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-with-equal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (with equal variances)</a></li>
<li class="chapter" data-level="30.1.2" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#comparing-two-populations-means-independent-sampling-unequal-variances-assumed-1"><i class="fa fa-check"></i><b>30.1.2</b> Comparing Two Populations Means: Independent Sampling (Unequal Variances Assumed)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#small-sample-confidence-interval-for-mu_1---mu_2-unequal-variances"><i class="fa fa-check"></i>Small-Sample Confidence Interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> (Unequal Variances)</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#degrees-of-freedom"><i class="fa fa-check"></i>Degrees of Freedom</a></li>
<li class="chapter" data-level="" data-path="two-sample-hypothesis-tests.html"><a href="two-sample-hypothesis-tests.html#two-sample-t-test-unequal-variances"><i class="fa fa-check"></i>Two-Sample t-Test (Unequal Variances)</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#the-fold-rule-1"><i class="fa fa-check"></i><b>30.2</b> The Fold Rule</a></li>
<li class="chapter" data-level="30.3" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#two-sample-hypothesis-test-on-paired-data-1"><i class="fa fa-check"></i><b>30.3</b> Two Sample Hypothesis Test on Paired Data</a></li>
<li class="chapter" data-level="30.4" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#two-sample-hypothesis-test-on-proportions-1"><i class="fa fa-check"></i><b>30.4</b> Two Sample Hypothesis Test on Proportions</a></li>
<li class="chapter" data-level="30.5" data-path="two-sample-hypothesis-tests-1.html"><a href="two-sample-hypothesis-tests-1.html#two-sample-hypothesis-test-on-variances-1"><i class="fa fa-check"></i><b>30.5</b> Two Sample Hypothesis Test on Variances</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="introduction-to-simple-linear-regression-1.html"><a href="introduction-to-simple-linear-regression-1.html"><i class="fa fa-check"></i><b>31</b> Introduction to Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="31.1" data-path="introduction-to-simple-linear-regression-1.html"><a href="introduction-to-simple-linear-regression-1.html#measures-of-linear-relationship-1"><i class="fa fa-check"></i><b>31.1</b> Measures of Linear Relationship</a></li>
<li class="chapter" data-level="31.2" data-path="introduction-to-simple-linear-regression-1.html"><a href="introduction-to-simple-linear-regression-1.html#least-squares-method-1"><i class="fa fa-check"></i><b>31.2</b> Least Squares Method</a></li>
<li class="chapter" data-level="31.3" data-path="introduction-to-simple-linear-regression-1.html"><a href="introduction-to-simple-linear-regression-1.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>31.3</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="31.4" data-path="introduction-to-simple-linear-regression-1.html"><a href="introduction-to-simple-linear-regression-1.html#sst-sse-and-ssr-1"><i class="fa fa-check"></i><b>31.4</b> SST, SSE and SSR</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="inference-for-simple-linear-regression-1.html"><a href="inference-for-simple-linear-regression-1.html"><i class="fa fa-check"></i><b>32</b> Inference for Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="32.1" data-path="inference-for-simple-linear-regression-1.html"><a href="inference-for-simple-linear-regression-1.html#inference-on-regression-1"><i class="fa fa-check"></i><b>32.1</b> Inference on Regression</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#estimating-variance-in-linear-regression"><i class="fa fa-check"></i>Estimating Variance in Linear Regression</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#the-regression-model"><i class="fa fa-check"></i>The Regression Model</a></li>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#interpreting-confidence-intervals-for-beta_1"><i class="fa fa-check"></i>Interpreting Confidence Intervals for <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="32.2" data-path="inference-for-simple-linear-regression-1.html"><a href="inference-for-simple-linear-regression-1.html#anova-table-analysis-of-variance-1"><i class="fa fa-check"></i><b>32.2</b> ANOVA Table (ANalysis Of VAriance)</a></li>
<li class="chapter" data-level="32.3" data-path="inference-for-simple-linear-regression-1.html"><a href="inference-for-simple-linear-regression-1.html#residual-plots-1"><i class="fa fa-check"></i><b>32.3</b> Residual Plots</a>
<ul>
<li class="chapter" data-level="" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#what-to-look-for-in-a-good-residual-plot"><i class="fa fa-check"></i>What to Look for in a Good Residual Plot</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Demo Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-for-simple-linear-regression-1" class="section level1 hasAnchor" number="32">
<h1><span class="header-section-number">32</span> Inference for Simple Linear Regression<a href="inference-for-simple-linear-regression-1.html#inference-for-simple-linear-regression-1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="inference-on-regression-1" class="section level2 hasAnchor" number="32.1">
<h2><span class="header-section-number">32.1</span> Inference on Regression<a href="inference-for-simple-linear-regression-1.html#inference-on-regression-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In previous chapters, we focused on estimating regression parameters and
interpreting the fitted line. In this chapter, we take a step further by
conducting formal inference on the slope and intercept of a simple
linear regression model. We examine the distribution of errors, assess
variability, and introduce the idea of using hypothesis tests and
confidence intervals to evaluate whether the linear relationship
observed in the data is statistically significant.</p>
<p>We begin by introducing the regression model and exploring the
assumptions necessary to perform inference on the coefficients,
particularly the slope.</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma^2)\]</span></p>
<p>Can perform inference on <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, however we are usually
more interested in <span class="math inline">\(\beta_1\)</span>.<br />
What does the error term <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma^2)\)</span>
mean?<br />
<strong>At each</strong> value of <span class="math inline">\(X\)</span>, the errors are distributed normally with a
mean of zero and a constant variance.</p>
<p>Can verify with residual plots (assumptions).</p>
<p>We estimate <span class="math inline">\(\sigma^2\)</span> with a value we call <span class="math inline">\(S^2\)</span> and use <span class="math inline">\(S^2\)</span> for
inference.</p>
<div id="estimating-variance-in-linear-regression" class="section level3 unnumbered hasAnchor">
<h3>Estimating Variance in Linear Regression<a href="inference-for-simple-linear-regression.html#estimating-variance-in-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma^2)\]</span></p>
<p><strong>Estimate <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(S^2\)</span></strong>:</p>
<p><span class="math display">\[S^2 = \frac{\sum_{i=1}^n e_i^2}{n - 2}
= \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n - 2}
= \frac{SSE}{n - 2}\]</span></p>
<p><span style="color: red"><em>notice similarity</em></span></p>
<p><span class="math display">\[S_x^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n - 1}
\quad {\text{(sample variance, }\bar{x} \text{ estimated)}}\]</span></p>
<p><span class="math display">\[S = +\sqrt{S^2}
\quad {\text{(estimate of standard deviation)}} \\\]</span></p>
<p><strong>In calculating <span class="math inline">\(S^2\)</span>, why do we divide by <span class="math inline">\(n-2\)</span>?</strong></p>
<p>Since we estimate 2 unknown parameters in the model (both <span class="math inline">\(\beta_0\)</span> and
<span class="math inline">\(\beta_1\)</span>), which are used in the calculation of <span class="math inline">\(S^2\)</span>.</p>
<div class="tcolorbox">
<p>We have data on an explanatory variable <span class="math inline">\(x\)</span> and a response variable <span class="math inline">\(y\)</span>
for <span class="math inline">\(n\)</span> individuals. From the data, calculate the means <span class="math inline">\(\bar{x}\)</span> and
<span class="math inline">\(\bar{y}\)</span> and the standard deviations <span class="math inline">\(S_x\)</span> and <span class="math inline">\(S_y\)</span> of the two
variables, and their correlation <span class="math inline">\(r\)</span>. The least-squares regression line
is the line:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_1 x\]</span></p>
<p>with <em>slope</em></p>
<p><span class="math display">\[b_1 = r \frac{S_y}{S_x}\]</span></p>
<p>and <em>intercept</em></p>
<p><span class="math display">\[b_0 = \bar{y} - b_1 \bar{x}\]</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-241" class="definition"><strong>Definition 32.1  </strong></span>The <strong>least-squares regression line</strong> of <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span> is the line that
makes the sum of the squares of the vertical distances of the data
points from the line as small as possible.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-242" class="example"><strong>Example 32.1  </strong></span>Suppose an appliance store conducts a 5-month experiment to determine
the effect of advertising on sales revenue. The results are shown in a
table below. The relationship between sales revenue, <span class="math inline">\(y\)</span>, and
advertising expenditure, <span class="math inline">\(x\)</span>, is hypothesized to follow a first-order
linear model, that is,</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x + \varepsilon\]</span></p>
<p>where</p>
<p><span class="math display">\[\begin{aligned}
y &amp; = \text{dependent variable} \\
x &amp; = \text{independent variable} \\
\beta_0 &amp; = \text{$y$-intercept} \\
\beta_1 &amp; = \text{slope of the line} \\
\varepsilon &amp; = \text{error variable}
\end{aligned}\]</span></p>
<table>
<thead>
<tr class="header">
<th>Month</th>
<th>Expenditure <span class="math inline">\(x\)</span> (hundreds)</th>
<th>Revenue <span class="math inline">\(y\)</span> (thousands)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr class="even">
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="odd">
<td>5</td>
<td>5</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>The question is this: How can we best use the information in the sample
of five observations in our table to estimate the unknown <span class="math inline">\(y\)</span>-intercept
<span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span>?</p>
<p>We are given:
<span class="math display">\[\bar{x} = 3, \quad \bar{y} = 2, \quad S_x = 1.5811, \quad S_y = 1.2247, \quad S_{xy} = 1.75\]</span></p>
<p>Then, the slope of the least squares line is</p>
<p><span class="math display">\[b_1 = r \frac{S_y}{S_x} = (0.9037) \left( \frac{1.2247}{1.5811} \right) = 0.7\]</span></p>
<p>and</p>
<p><span class="math display">\[b_0 = \bar{y} - b_1 \bar{x} = 2 - (0.7)(3) = -0.1\]</span></p>
<p>The least squares line is thus:</p>
<p><span class="math display">\[\hat{y} = -0.1 + 0.7x\]</span></p>
</div>
</div>
<div id="the-regression-model" class="section level3 unnumbered hasAnchor">
<h3>The Regression Model<a href="inference-for-simple-linear-regression.html#the-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have <span class="math inline">\(n\)</span> observations on an explanatory variable <span class="math inline">\(x\)</span> and a response
variable <span class="math inline">\(y\)</span>. Our goal is to study or predict the behavior of <span class="math inline">\(y\)</span> for
given values of <span class="math inline">\(x\)</span>.</p>
<ul>
<li><p>For any fixed value of <span class="math inline">\(x\)</span>, the response <span class="math inline">\(y\)</span> varies according to a
Normal distribution. Repeated measures <span class="math inline">\(y\)</span> are independent of each
other.</p></li>
<li><p>The mean response <span class="math inline">\(\mu_y\)</span> has a straight-line relationship with <span class="math inline">\(x\)</span>:
<span class="math inline">\(\mu_y = \beta_0 + \beta_1 x\)</span>. The slope <span class="math inline">\(\beta_1\)</span> and intercept
<span class="math inline">\(\beta_0\)</span> are <strong>unknown</strong> parameters.</p></li>
<li><p>The standard deviation of <span class="math inline">\(y\)</span> (call it <span class="math inline">\(\sigma\)</span>) is the same for all
values of <span class="math inline">\(x\)</span>. The value of <span class="math inline">\(\sigma\)</span> is <strong>unknown</strong>. The regression
model has three parameters, <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\sigma\)</span>.</p></li>
</ul>
<p>Thus, if <span class="math display">\[\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i\]</span> is the
predicted value of the <span class="math inline">\(i\)</span>th <span class="math inline">\(y\)</span> value, then the deviation of the
observed value <span class="math inline">\(y_i\)</span> from <span class="math inline">\(\hat{y}_i\)</span> is the difference
<span class="math inline">\(y_i - \hat{y}_i\)</span> and the sum of squares of deviations to be minimized
is</p>
<p><span class="math display">\[SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} [y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)]^2.\]</span></p>
<p>The quantity <em>SSE</em> is also called the <strong>sum of squares for error</strong>.
<span class="math display">\[\begin{aligned}
\text{Fitted Value:} \quad &amp; \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i \\
\text{Residual:} \quad &amp; \hat{\varepsilon}_i = y_i - \hat{y}_i
\end{aligned}\]</span></p>
<p>The <strong>regression standard error</strong> is</p>
<p><span class="math display">\[s = \sqrt{\frac{1}{n - 2} \sum \text{residual}^2}
= \sqrt{\frac{1}{n - 2} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
= \sqrt{\frac{SSE}{n - 2}}\]</span></p>
<p>Use <span class="math inline">\(s\)</span> to estimate the <strong>unknown</strong> <span class="math inline">\(\sigma\)</span> in the regression model.<br />
The standard error of <span class="math inline">\(\hat{\beta}_1\)</span> is the standard deviation of the
sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span> (estimate of slope <span class="math inline">\(\beta_1\)</span>):</p>
<p><span class="math display">\[SE(\hat{\beta}_1) = \frac{s}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2}}
= \frac{s}{\sqrt{(n - 1) s_x^2}}\]</span></p>
<p><strong>Confidence Interval for the Slope</strong></p>
<p><span class="math display">\[\hat{\beta}_1 \pm t_{(n-2, \, \alpha/2)} \cdot SE(\hat{\beta}_1)
\quad = \quad
\hat{\beta}_1 \pm t_{(n-2, \, \alpha/2)} \cdot \frac{s}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2}}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-243" class="example"><strong>Example 32.2  </strong></span>Revisit the example on advertising and sales and construct a 95%
confidence interval on the slope. Provide an interpretation of the CI.</p>
<p>From earlier: <span class="math display">\[\hat{y} = -0.1 + 0.7x\]</span></p>
<div class="center">
<table>
<thead>
<tr class="header">
<th align="center"><strong><span class="math inline">\(x\)</span></strong></th>
<th align="center"><strong><span class="math inline">\(y\)</span></strong></th>
<th align="center"><strong><span class="math inline">\(\hat{y}\)</span></strong></th>
<th align="center"><strong><span class="math inline">\(y - \hat{y}\)</span></strong></th>
<th align="center"><strong><span class="math inline">\((y - \hat{y})^2\)</span></strong></th>
<th align="center"><strong><span class="math inline">\((x - \bar{x})^2\)</span></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.6</td>
<td align="center">0.4</td>
<td align="center">0.16</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1.3</td>
<td align="center">-0.3</td>
<td align="center">0.09</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">2</td>
<td align="center">2.0</td>
<td align="center">0.0</td>
<td align="center">0.00</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">2</td>
<td align="center">2.7</td>
<td align="center">-0.7</td>
<td align="center">0.49</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">4</td>
<td align="center">3.4</td>
<td align="center">0.6</td>
<td align="center">0.36</td>
<td align="center">4</td>
</tr>
</tbody>
</table>
</div>
<p>We are given:
<span class="math display">\[\sum x_i = 15, \quad \bar{x} = \frac{15}{5} = 3, \quad SSE = 1.10, \quad \sum (x_i - \bar{x})^2 = 10\]</span></p>
<p><strong>Step 1: Estimate variance and standard deviation</strong>
<span class="math display">\[s^2 = \frac{SSE}{n-2} = \frac{1.10}{5 - 2} = 0.3667
\quad \Rightarrow \quad
s = \sqrt{0.3667} = 0.6055\]</span></p>
<p><strong>Step 2: Compute standard error of <span class="math inline">\(\hat{\beta}_1\)</span></strong>
<span class="math display">\[SE(\hat{\beta}_1) = \frac{s}{\sqrt{\sum (x_i - \bar{x})^2}}
= \frac{0.6055}{\sqrt{10}} = 0.1914\]</span></p>
<p><strong>Step 3: Determine critical <span class="math inline">\(t\)</span>-value</strong></p>
<p><span class="math display">\[n - 2 = 3, \quad \alpha = 0.05, \quad \alpha/2 = 0.025
\Rightarrow \quad
t_{(3, 0.025)} = 3.182\]</span></p>
<p><strong>Step 4: Construct CI for the slope</strong>
<span class="math display">\[\hat{\beta}_1 \pm t_{(n-2, \alpha/2)} \cdot SE(\hat{\beta}_1)
= 0.7 \pm 3.182 \cdot 0.1914 = 0.7 \pm 0.6092\]</span></p>
<p><span class="math display">\[\Rightarrow \text{CI: } (0.0908, \; 1.3092)\]</span></p>
<p><strong>Interpretation:</strong> We are 95% confident the slope (<span class="math inline">\(\beta_1\)</span>) for this
model lies between 0.0908 and 1.3092.</p>
</div>
</div>
<div id="interpreting-confidence-intervals-for-beta_1" class="section level3 unnumbered hasAnchor">
<h3>Interpreting Confidence Intervals for <span class="math inline">\(\beta_1\)</span><a href="inference-for-simple-linear-regression.html#interpreting-confidence-intervals-for-beta_1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="center">
<table style="width:97%;">
<colgroup>
<col width="22%" />
<col width="74%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="right"><strong>Suppose CI:</strong></td>
<td align="left"><span class="math inline">\((-, -)\)</span>
Suggests <span class="math inline">\(\beta_1\)</span> has a <strong>negative</strong> sign.
Suggests negative correlation, potentially good model.</td>
</tr>
<tr class="even">
<td align="right"><strong>Suppose CI:</strong></td>
<td align="left"><span class="math inline">\((+, +)\)</span>
Suggests <span class="math inline">\(\beta_1\)</span> has a <strong>positive</strong> sign.
Suggests positive correlation, potentially good model.</td>
</tr>
<tr class="odd">
<td align="right"><strong>Suppose CI:</strong></td>
<td align="left"><span class="math inline">\((-, +)\)</span>
<span class="math inline">\(\beta_1 = 0\)</span> is plausible.
Suggests <strong>no linear relationship</strong> between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</td>
</tr>
</tbody>
</table>
</div>
<p>In cases where the CI does not contain zero, we can infer the sign of
the slope (just not the steepness).<br />
The <strong>regression standard error</strong> is</p>
<p><span class="math display">\[s = \sqrt{\frac{1}{n - 2} \sum_{i=1}^n (y_i - \hat{y}_i)^2} = \sqrt{\frac{SSE}{n - 2}} = \sqrt{\frac{1.1}{3}} = 0.6055\]</span></p>
<p>Use <span class="math inline">\(s\)</span> to estimate the <strong>unknown</strong> <span class="math inline">\(\sigma\)</span> in the regression model.<br />
A level <span class="math inline">\(C\)</span> confidence interval for the slope <span class="math inline">\(\beta_1\)</span> of the true
regression line is</p>
<p><span class="math display">\[b_1 \pm t^* SE_{b_1}\]</span></p>
<p>In this formula, the standard error of the least-squares slope <span class="math inline">\(b\)</span> is</p>
<p><span class="math display">\[SE_{b_1} = \frac{s}{\sqrt{\sum (x_i - \bar{x})^2}} = \frac{s}{\sqrt{(n - 1) S_x^2}}\]</span></p>
<p>and <span class="math inline">\(t^*\)</span> is the critical value for the <span class="math inline">\(t(n - 2)\)</span> density curve with
area <span class="math inline">\(C\)</span> between <span class="math inline">\(-t^*\)</span> and <span class="math inline">\(t^*\)</span>.</p>
<div class="tcolorbox">
<p><strong>Hypotheses:</strong> <span class="math display">\[\begin{aligned}
H_0\!: \beta_1 = 0 \quad &amp; \text{vs.} \quad H_a\!: \beta_1 &gt; 0 \\
H_0\!: \beta_1 = 0 \quad &amp; \text{vs.} \quad H_a\!: \beta_1 &lt; 0 \\
H_0\!: \beta_1 = 0 \quad &amp; \text{vs.} \quad H_a\!: \beta_1 \neq 0 \quad \text{\textit{(most common)}}
\end{aligned}\]</span></p>
<p><strong>Test Statistic:</strong>
<span class="math display">\[t = \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)} = \frac{\hat{\beta}_1}{\dfrac{s}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}}}\]</span></p>
<p><strong>Reference distribution:</strong> <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n - 2\)</span> degrees of
freedom.</p>
<p><em>Note:</em> A test statistic always follows the form:
<span class="math display">\[\text{test stat} = \frac{\text{statistic} - \text{hypothesized value}}{\text{SE(statistic)}}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-244" class="example"><strong>Example 32.3  </strong></span>For the advertising example, perform a two-sided hypothesis test on the
slope.</p>
<p><strong>Hypotheses:</strong> <span class="math display">\[H_0\!: \beta_1 = 0
\qquad
H_a\!: \beta_1 \neq 0\]</span></p>
<p><strong>Test Statistic:</strong>
<span class="math display">\[t^* = \frac{\hat{\beta}_1 - 0}{\dfrac{s}{\sqrt{\sum (x_i - \bar{x})^2}}}
= \frac{0.7 - 0}{0.6055 / \sqrt{10}} = 3.6558\]</span></p>
<p><strong>Reference Distribution:</strong> <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n - 2 = 5 - 2 = 3\)</span>
degrees of freedom.</p>
<p><strong>Decision Rule:</strong></p>
<p>Using a two-tailed test:
<span class="math display">\[\text{p-value} = 2 \cdot P(T_3 &gt; 3.6558) &lt; 0.01 \Rightarrow \text{p-value} &lt; 0.05\]</span></p>
<p><strong>Conclusion:</strong> Since <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span> and conclude
<span class="math inline">\(H_a\!: \beta_1 \neq 0\)</span>.</p>
<p><em>Interpretation:</em> The slope should be included in the model. There is
significant evidence of a linear relationship between advertising and
sales revenue.<br />
For the advertising-sales example, a 95% Confidence Interval for the
slope <span class="math inline">\(\beta_1\)</span> is
<span class="math display">\[0.7 \pm 3.182 \left( \frac{0.6055}{\sqrt{10}} \right)\]</span>
<span class="math display">\[0.7 \pm 0.6092\]</span></p>
<p>Thus, we estimate with 95% confidence that the interval from 0.0908 and
1.3092 includes the parameter <span class="math inline">\(\beta_1\)</span>.</p>
</div>
<p>We can also test hypotheses about the slope <span class="math inline">\(\beta_1\)</span>. The most common
hypothesis is</p>
<p><span class="math display">\[H_0 : \beta_1 = 0.\]</span></p>
<p>A regression line with slope 0 is horizontal. That is, the mean of <span class="math inline">\(y\)</span>
does not change at all when <span class="math inline">\(x\)</span> changes. So this <span class="math inline">\(H_0\)</span> says that there
is no true linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<div class="tcolorbox">
<p>To test the hypothesis <span class="math inline">\(H_0 : \beta_1 = 0\)</span>, compute the <span class="math inline">\(t\)</span> statistic
<span class="math display">\[t = \frac{b_1}{SE_{b_1}}.\]</span></p>
<p>In terms of a random variable <span class="math inline">\(T\)</span> having the <span class="math inline">\(t(n - 2)\)</span> distribution,
the P-value for a test of <span class="math inline">\(H_0\)</span> against: <span class="math display">\[\begin{aligned}
H_a : \beta_1 \ne 0 &amp; \quad \text{is } 2P(T &gt; |t|). \\
H_a : \beta_1 &gt; 0 &amp; \quad \text{is } P(T &gt; t). \\
H_a : \beta_1 &lt; 0 &amp; \quad \text{is } P(T &lt; t).
\end{aligned}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-245" class="example"><strong>Example 32.4  </strong></span><span class="math display">\[\alpha = 0.05\]</span></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(H_0: \beta_1 = 0 \quad \text{vs} \quad H_a: \beta_1 &gt; 0\)</span></p></li>
<li><p><span class="math inline">\(t^* = \frac{b_1}{SE_{b_1}} = \frac{0.7}{0.1914} = 3.6572\)</span></p></li>
<li><p><span class="math inline">\(P\text{-value} = P(T &gt; t) = P(T &gt; 3.6572) \quad \text{d.f.} = n - 2 = 5 - 2 = 3.\)</span><br />
Using t-distribution table, <span class="math inline">\(0.01 &lt; P\text{ value} &lt; 0.025\)</span></p></li>
<li><p>Since <span class="math inline">\(P\text{-value} &lt; \alpha = 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span>.</p></li>
</ol>
<p>Our example (different <span class="math inline">\(H_a\)</span>) <span class="math display">\[\alpha = 0.05\]</span></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(H_0: \beta_1 = 0 \quad \text{vs} \quad H_a: \beta_1 \neq 0\)</span></p></li>
<li><p><span class="math inline">\(t^* = \frac{b_1}{SE_{b_1}} = \frac{0.7}{0.1914} = 3.6572\)</span></p></li>
<li><p><span class="math inline">\(P\text{-value} = 2P(T &gt; |t|) = 2P(T &gt; 3.6572) \quad \text{d.f.} = n - 2 = 5 - 2 = 3.\)</span><br />
Using Table 3, <span class="math inline">\(0.02 &lt; P\text{ value} &lt; 0.05\)</span></p></li>
<li><p>Since <span class="math inline">\(P\text{-value} &lt; \alpha = 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span>.</p></li>
</ol>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>x = c(1, 2, 3, 4, 5);
y = c(1, 1, 2, 2, 4);
mod = lm(y~x);
summary(mod);</code></pre>
</div>
<p><strong>R Output</strong></p>
<div class="tcolorbox">
<pre><code>## 
## Call:
## lm(formula = y~x)
## 
## Residuals:
##       1        2        3        4        5 
##  4.000e-01 -3.000e-01 -3.886e-16 -7.000e-01  6.000e-01 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  -0.1000     0.6351  -0.157  0.8849    
## x             0.7000     0.1915   3.656  0.0354 *  
## ---
## Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
## 
## Residual standard error: 0.6055 on 3 degrees of freedom</code></pre>
</div>
<p><span class="math display">\[\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x = -0.10 + 0.70x\]</span>
<span class="math display">\[SE(\hat{\beta}_1) = 0.1915\]</span></p>
<p>By default, R conducts the following test for each coefficient:</p>
<p><span class="math display">\[\begin{aligned}
    H_0&amp;: \beta_j = 0 \\
    H_a&amp;: \beta_j \ne 0 \quad \text{(two sided)}
\end{aligned}\]</span></p>
<p>Test statistic: <span class="math display">\[t^* = \frac{\hat{\beta}_j - 0}{SE(\hat{\beta}_j)}\]</span></p>
<p>For advertising and sales data: <span class="math display">\[\begin{aligned}
    H_0&amp;: \beta_1 = 0 \\
    H_a&amp;: \beta_1 \ne 0
\end{aligned}\]</span></p>
<p><span class="math display">\[t^* = \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)} = \frac{0.70}{0.1915} = 3.656\]</span></p>
</div>
<div class="nt">
<p><strong>Review</strong></p>
<p><span class="math display">\[\begin{aligned}
y &amp;= \beta_0 + \beta_1 x + \varepsilon, \quad \varepsilon \sim N(0, \sigma^2) \\
\hat{y} &amp;= \hat{\beta}_0 + \hat{\beta}_1 x \\
\hat{\beta}_1 &amp;= \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2} = \frac{s_{xy}}{s_{xx}} \\
\hat{\beta}_0 &amp;= \bar{y} - \hat{\beta}_1 \bar{x} \\
\end{aligned}\]</span></p>
<p><strong>r:</strong> coefficient of correlation (strength)<br />
<strong>r<span class="math inline">\(^2\)</span>:</strong> coefficient of determination (% variability)</p>
<p><span class="math display">\[\begin{aligned}
s^2 &amp;= \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n - 2} = \frac{SSE}{n - 2} \\
s &amp;= \sqrt{s^2} \\
SE(\hat{\beta}_1) &amp;= \frac{s}{\sqrt{s_{xx}}} \\
CI &amp;: \hat{\beta}_1 \pm t_{n - 2, \alpha/2} \cdot SE(\hat{\beta}_1) \\
\end{aligned}\]</span> Hypothesis test: <span class="math display">\[\begin{aligned}
H_0 &amp;: \beta_1 = 0 \\
\text{Test stat:}\quad t &amp;= \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)}
\end{aligned}\]</span></p>
</div>
<p>We square all three deviations for each one of our data points, and sum
over all <span class="math inline">\(n\)</span> points. Here, cross terms drop out, and we are left with
the following equation:</p>
<p><span class="math display">\[\sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2\]</span></p>
<p><span class="math display">\[\text{SST} = \text{SSE} + \text{SSR}\]</span></p>
<p>Total sum of squares = Sum of squares for error + Sum of squares for
regression.<br />
<span class="math display">\[\begin{aligned}
SSE &amp;= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \\
    &amp;= \sum_{i=1}^{n} (y_i - \bar{y})^2 - \hat{\beta}_1 \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y}) \\
    &amp;= S_{YY} - \hat{\beta}_1 S_{XY}
\end{aligned}\]</span></p>
<p>Notice that this provides an easier computational method of finding
SSE.<br />
<strong>R output (Additional example)</strong></p>
<div class="tcolorbox">
<pre><code>&gt; summary(model);

Call:
lm(formula = camrys$Price ~ Odometer, data = camrys)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.68679 -0.27263  0.00521  0.23210  0.70071 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  17.248727   0.182093   94.72   &lt;2e-16 ***
Odometer     -0.066861   0.004975  -13.44   &lt;2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.3265 on 98 degrees of freedom
Multiple R-squared:  0.6483,    Adjusted R-squared:  0.6447 
F-statistic: 180.6 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
<div id="anova-table-analysis-of-variance-1" class="section level2 hasAnchor" number="32.2">
<h2><span class="header-section-number">32.2</span> ANOVA Table (ANalysis Of VAriance)<a href="inference-for-simple-linear-regression-1.html#anova-table-analysis-of-variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Analysis of Variance (ANOVA) is a statistical method used to assess
whether variation in a response variable can be explained by predictor
variables in a regression model. It summarizes sources of variation
using sums of squares, degrees of freedom, and mean squares in a
structured table format.</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong>Source of Variation</strong></th>
<th align="center"><strong>Sum of Squares</strong></th>
<th align="center"><strong>Degrees of Freedom</strong></th>
<th align="center"><strong>Mean Square</strong></th>
<th align="center"><strong>Computed F</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Regression</td>
<td align="center">SSR</td>
<td align="center">1</td>
<td align="center">SSR</td>
<td align="center"><span class="math inline">\(\dfrac{SSR}{SSE / (n - 2)}\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="center">SSE</td>
<td align="center"><span class="math inline">\(n - 2\)</span></td>
<td align="center"><span class="math inline">\(s^2 = \dfrac{SSE}{n - 2}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center">SST</td>
<td align="center"><span class="math inline">\(n - 1\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>For the general multivariate regression model: <span class="math display">\[\begin{aligned}
    Y &amp;= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p + \varepsilon, \\
      &amp;\quad \varepsilon \sim N(0, \sigma^2)
\end{aligned}\]</span> with <span class="math inline">\(p\)</span> predictors.<br />
ANOVA can be used for testing: <span class="math display">\[\begin{aligned}
    H_0&amp;: \beta_1 = \beta_2 = \cdots = \beta_p = 0 \\
    H_a&amp;: \text{At least one } \beta_j \ne 0, \quad j = 1, \ldots, p
\end{aligned}\]</span></p>
<p><strong>Test Statistic:</strong> <span class="math display">\[\begin{aligned}
    F &amp;= \dfrac{MSR}{MSE} = \dfrac{SSR/p}{SSE / (n - p - 1)} \sim F(p, n - p - 1)
\end{aligned}\]</span></p>
<p><strong>Reference distribution:</strong> <span class="math inline">\(F\)</span> with numerator df = <span class="math inline">\(p\)</span>, denominator df
= <span class="math inline">\(n - p - 1\)</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-246" class="example"><strong>Example 32.5  </strong></span>We fitted a simple linear regression model using:</p>
<div class="tcolorbox">
<pre><code>x = c(1,2,3,4,5);
y = c(1,1,2,2,4);
mod = lm(y~x);
anova(mod);</code></pre>
</div>
<p>The ANOVA output was:</p>
<div class="tcolorbox">
<pre><code>## Analysis of Variance Table
##
## Response: y
##             Df  Sum Sq Mean Sq F value   Pr(&gt;F)
## x            1     4.9    4.9000  13.364  0.03535 *
## Residuals    3     1.1    0.3667
## ---
## Signif. codes:
## 0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1</code></pre>
</div>
<p><strong>Interpretation:</strong></p>
<ul>
<li><p>The regression model includes one predictor <span class="math inline">\(x\)</span>, so the degrees of
freedom for regression is 1.</p></li>
<li><p>The sum of squares for regression is <span class="math inline">\(SSR = 4.9\)</span>, and for residuals
<span class="math inline">\(SSE = 1.1\)</span>.</p></li>
<li><p>Mean squares are calculated as:
<span class="math display">\[MSR = \frac{SSR}{1} = 4.9, \quad MSE = \frac{SSE}{n - 2} = \frac{1.1}{3} = 0.3667\]</span></p></li>
<li><p>The F-statistic is:
<span class="math display">\[F = \frac{MSR}{MSE} = \frac{4.9}{0.3667} \approx 13.364\]</span></p></li>
<li><p>The p-value is <span class="math inline">\(\approx 0.03535\)</span>, indicating that the predictor is
significant at the 5% level.</p></li>
</ul>
<p><strong>Conclusion:</strong> Since the p-value is less than 0.05, we reject <span class="math inline">\(H_0\)</span> and
conclude that <span class="math inline">\(x\)</span> has a statistically significant linear relationship
with <span class="math inline">\(y\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-247" class="example"><strong>Example 32.6  </strong></span>We consider data on apartments near UTM, with price (in thousands of
dollars), area (in 100 square feet), and number of beds and baths.</p>
<div class="center">
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>Price</strong></td>
<td align="center"><strong>Area</strong></td>
<td align="center"><strong>Beds</strong></td>
<td align="center"><strong>Baths</strong></td>
</tr>
<tr class="even">
<td align="center">(<span class="math inline">\(\times 1000\)</span>)</td>
<td align="center">(<span class="math inline">\(\times 100\)</span> sq ft)</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">620</td>
<td align="center">11.0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">590</td>
<td align="center">6.5</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">620</td>
<td align="center">10.0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">700</td>
<td align="center">8.4</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">680</td>
<td align="center">8.0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">500</td>
<td align="center">5.7</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">760</td>
<td align="center">12.0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">800</td>
<td align="center">14.0</td>
<td align="center">3</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">660</td>
<td align="center">7.3</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-75"></span>
<img src="_main_files/figure-html/unnamed-chunk-75-1.png" alt="Plot of Price vs Area for Apartments near UTM" width="60%" />
<p class="caption">
Figure 32.1: Plot of Price vs Area for Apartments near UTM
</p>
</div>
<table>
<caption>Deviation table for computing <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span></caption>
<thead>
<tr class="header">
<th align="center"><strong>Price</strong></th>
<th align="center"><strong>Area</strong></th>
<th align="center"><span class="math inline">\((x - \bar{x})\)</span></th>
<th align="center"><span class="math inline">\((y - \bar{y})\)</span></th>
<th align="center"><span class="math inline">\((x - \bar{x})(y - \bar{y})\)</span></th>
<th align="center"><span class="math inline">\((x - \bar{x})^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">620</td>
<td align="center">11.0</td>
<td align="center">1.8</td>
<td align="center">-38.9</td>
<td align="center">-70.02</td>
<td align="center">3.24</td>
</tr>
<tr class="even">
<td align="center">590</td>
<td align="center">6.5</td>
<td align="center">-2.7</td>
<td align="center">-68.9</td>
<td align="center">186.03</td>
<td align="center">7.29</td>
</tr>
<tr class="odd">
<td align="center">620</td>
<td align="center">10.0</td>
<td align="center">0.8</td>
<td align="center">-38.9</td>
<td align="center">-31.12</td>
<td align="center">0.64</td>
</tr>
<tr class="even">
<td align="center">700</td>
<td align="center">8.4</td>
<td align="center">-0.8</td>
<td align="center">41.1</td>
<td align="center">-32.88</td>
<td align="center">0.64</td>
</tr>
<tr class="odd">
<td align="center">680</td>
<td align="center">8.0</td>
<td align="center">-1.2</td>
<td align="center">21.1</td>
<td align="center">-25.32</td>
<td align="center">1.44</td>
</tr>
<tr class="even">
<td align="center">500</td>
<td align="center">5.7</td>
<td align="center">-3.5</td>
<td align="center">-158.9</td>
<td align="center">556.15</td>
<td align="center">12.25</td>
</tr>
<tr class="odd">
<td align="center">760</td>
<td align="center">12.0</td>
<td align="center">2.8</td>
<td align="center">101.1</td>
<td align="center">283.08</td>
<td align="center">7.84</td>
</tr>
<tr class="even">
<td align="center">800</td>
<td align="center">14.0</td>
<td align="center">4.8</td>
<td align="center">141.1</td>
<td align="center">677.28</td>
<td align="center">23.04</td>
</tr>
<tr class="odd">
<td align="center">660</td>
<td align="center">7.3</td>
<td align="center">-1.9</td>
<td align="center">1.1</td>
<td align="center">-2.09</td>
<td align="center">3.61</td>
</tr>
<tr class="even">
<td align="center"><strong>Sum</strong></td>
<td align="center">82.9</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\sum (x - \bar{x})(y - \bar{y}) = 1541.11\)</span></td>
<td align="center"><span class="math inline">\(\sum (x - \bar{x})^2 = 60.00\)</span></td>
</tr>
</tbody>
</table>
<p>The sample means are:
<span class="math display">\[\bar{y} = \frac{\sum y}{n} = \frac{5930}{9} = 658.89, \qquad
\bar{x} = \frac{\sum x}{n} = \frac{82.9}{9} = 9.21\]</span></p>
<div id="finding-the-regression-coefficients" class="section level4 unnumbered hasAnchor">
<h4>Finding the Regression Coefficients<a href="inference-for-simple-linear-regression.html#finding-the-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To compute the least squares regression line, we calculate the slope and
intercept using the formulas:</p>
<p><span class="math display">\[\hat{\beta}_1 = \frac{S_{xy}}{S_{xx}} = \frac{1541.11}{60} = 25.69\]</span>
<span class="math display">\[\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} = 658.89 - (25.69)(9.21) = 422.28\]</span></p>
</div>
<div id="equation-of-the-regression-line" class="section level4 unnumbered hasAnchor">
<h4>Equation of the Regression Line<a href="inference-for-simple-linear-regression.html#equation-of-the-regression-line" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Using the values above, we write the estimated regression equation as:</p>
<p><span class="math display">\[\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x = 422.28 + 25.69x\]</span></p>
<p>This equation gives the predicted apartment price (in $1000s) based on
area (in 100 sq ft).</p>
</div>
<div id="interpretation-of-coefficients" class="section level4 unnumbered hasAnchor">
<h4>Interpretation of Coefficients<a href="inference-for-simple-linear-regression.html#interpretation-of-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The slope <span class="math inline">\(\hat{\beta}_1 = 25.69\)</span> means that for every additional 100 sq
ft in area, we expect the apartment price to increase by approximately
$25,690 on average.<br />
The intercept <span class="math inline">\(\hat{\beta}_0 = 422.28\)</span> suggests the predicted price when
the area is zero. While this has no practical interpretation in this
context, it is a necessary component of the regression model.</p>
</div>
<div id="interpolation-and-extrapolation" class="section level4 unnumbered hasAnchor">
<h4>Interpolation and Extrapolation<a href="inference-for-simple-linear-regression.html#interpolation-and-extrapolation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To estimate the price of an apartment with an area of 800 sq ft (i.e.,
<span class="math inline">\(x = 8\)</span>), we compute:</p>
<p><span class="math display">\[\hat{y} = 422.28 + 25.69(8) = 627.8 \quad (\$1000)\]</span></p>
<p>Since 8 is within the range of observed values, this is an example of
<strong>interpolation.</strong></p>
<p>For an apartment with 2,500 sq ft (<span class="math inline">\(x = 25\)</span>):</p>
<p><span class="math display">\[\hat{y} = 422.28 + 25.69(25) = 1064.53 \quad (\$1000)\]</span></p>
<p>This is an example of <strong>extrapolation</strong>, and such predictions should be
treated with caution since they lie outside the data range.<br />
We can create a simple linear regression model in R using the <code>lm</code>
command:</p>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>lm(y ~ x, data = data_source)</code></pre>
</div>
<p>The data is available in the <code>apt_around_utm.csv</code> file.</p>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>apt = read.csv(file.choose())
# apt = read.csv(&quot;~/PATH_TO_FILE/apt_around_utm.csv&quot;)

apt_model = lm(price ~ area, data = apt)</code></pre>
</div>
<p><strong>R output</strong></p>
<div class="tcolorbox">
<pre><code>&gt; apt_model

Call:
lm(formula = price ~ area, data = apt)

Coefficients:
(Intercept)       area  
     422.26       25.69  </code></pre>
</div>
<p>We can compute the residuals and the sum of squared errors (SSE) using
the table below:</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(y\)</span></th>
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(\hat{y}\)</span></th>
<th align="center"><span class="math inline">\(y - \hat{y}\)</span></th>
<th align="center"><span class="math inline">\((y - \hat{y})^2\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">620</td>
<td align="center">11.0</td>
<td align="center">704.85</td>
<td align="center">-84.85</td>
<td align="center">7198.73</td>
<td></td>
</tr>
<tr class="even">
<td align="center">590</td>
<td align="center">6.5</td>
<td align="center">589.24</td>
<td align="center">0.76</td>
<td align="center">0.58</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">620</td>
<td align="center">10.0</td>
<td align="center">679.16</td>
<td align="center">-59.16</td>
<td align="center">3499.36</td>
<td></td>
</tr>
<tr class="even">
<td align="center">700</td>
<td align="center">8.4</td>
<td align="center">638.05</td>
<td align="center">61.95</td>
<td align="center">3837.62</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">680</td>
<td align="center">8.0</td>
<td align="center">627.78</td>
<td align="center">52.22</td>
<td align="center">2727.4</td>
<td></td>
</tr>
<tr class="even">
<td align="center">500</td>
<td align="center">5.7</td>
<td align="center">568.69</td>
<td align="center">-68.69</td>
<td align="center">4718.13</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">760</td>
<td align="center">12.0</td>
<td align="center">730.54</td>
<td align="center">29.46</td>
<td align="center">868.17</td>
<td></td>
</tr>
<tr class="even">
<td align="center">800</td>
<td align="center">14.0</td>
<td align="center">781.92</td>
<td align="center">18.08</td>
<td align="center">327.06</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">660</td>
<td align="center">7.3</td>
<td align="center">609.79</td>
<td align="center">50.21</td>
<td align="center">2520.79</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>Recall our fitted regression model: <span class="math display">\[\hat{y} = 25.69x + 422.26\]</span></p>
<p><span class="math display">\[\text{SSE} = \sum (y_i - \hat{y}_i)^2 = 25,\!697.83\]</span></p>
<p>We now conduct a hypothesis test on the slope <span class="math inline">\(\beta_1\)</span> at the 5%
significance level.</p>
<p><strong>Step 1: Hypotheses</strong>
<span class="math display">\[H_0: \beta_1 = 0 \quad \text{vs.} \quad H_a: \beta_1 \ne 0\]</span></p>
<p><strong>Step 2: Test statistic</strong>
<span class="math display">\[s^2 = \frac{SSE}{n - 2} = \frac{25,\!697.83}{7} = 3670.26\]</span>
<span class="math display">\[s = \sqrt{3670.26} = 60.58\]</span>
<span class="math display">\[SE(\hat{\beta}_1) = \frac{s}{\sqrt{S_{xx}}} = \frac{60.58}{\sqrt{60}} = 7.82\]</span>
<span class="math display">\[t = \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)} = \frac{25.69}{7.82} = 3.284\]</span></p>
<p><strong>Step 3: Conclusion</strong> Using <span class="math inline">\(t\)</span>-distribution with 7 degrees of freedom:</p>
<p><span class="math display">\[0.005 &lt; p\text{-value} &lt; 0.01\]</span></p>
<p>Since <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span> and conclude that there is
sufficient evidence that <span class="math inline">\(\beta_1 \ne 0\)</span>.This suggests there is a
statistically significant relationship between price and area for
apartments near UTM.</p>
<p><strong>Final Check: Total Sum of Squares</strong></p>
<div class="center">
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(y\)</span></th>
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(\hat{y}\)</span></th>
<th align="center"><span class="math inline">\((y - \hat{y})^2\)</span></th>
<th align="center"><span class="math inline">\((y - \bar{y})^2\)</span></th>
<th align="center"><span class="math inline">\((\hat{y} - \bar{y})^2\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">620</td>
<td align="center">11.0</td>
<td align="center">704.85</td>
<td align="center">7198.73</td>
<td align="center">2112.00</td>
<td align="center">1512.35</td>
<td></td>
</tr>
<tr class="even">
<td align="center">590</td>
<td align="center">6.5</td>
<td align="center">589.24</td>
<td align="center">0.58</td>
<td align="center">4850.88</td>
<td align="center">4745.68</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">620</td>
<td align="center">10.0</td>
<td align="center">679.16</td>
<td align="center">3499.36</td>
<td align="center">410.73</td>
<td align="center">1512.35</td>
<td></td>
</tr>
<tr class="even">
<td align="center">700</td>
<td align="center">8.4</td>
<td align="center">638.05</td>
<td align="center">3837.62</td>
<td align="center">434.20</td>
<td align="center">1690.12</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">680</td>
<td align="center">8.0</td>
<td align="center">627.78</td>
<td align="center">2727.4</td>
<td align="center">968.04</td>
<td align="center">445.68</td>
<td></td>
</tr>
<tr class="even">
<td align="center">500</td>
<td align="center">5.7</td>
<td align="center">568.69</td>
<td align="center">4718.13</td>
<td align="center">8136.08</td>
<td align="center">2524.68</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">760</td>
<td align="center">12.0</td>
<td align="center">730.54</td>
<td align="center">868.17</td>
<td align="center">5133.21</td>
<td align="center">10223.46</td>
<td></td>
</tr>
<tr class="even">
<td align="center">800</td>
<td align="center">14.0</td>
<td align="center">781.92</td>
<td align="center">327.06</td>
<td align="center">1513.47</td>
<td align="center">19912.35</td>
<td></td>
</tr>
<tr class="odd">
<td align="center">660</td>
<td align="center">7.3</td>
<td align="center">609.79</td>
<td align="center">2520.79</td>
<td align="center">2410.45</td>
<td align="center">1.23</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><span class="math display">\[SSE + SSR = SST = 25,\!697.83 + 39,\!591.06 = 65,\!288.90\]</span> This
confirms the ANOVA identity: Total = Explained + Residual</p>
<p>We previously estimated the model:</p>
<p><span class="math display">\[\hat{y} = 25.69x + 422.26\]</span></p>
<p><strong>Coefficient of Determination and Correlation</strong></p>
<p><span class="math display">\[r^2 = \frac{SSR}{SST} = \frac{39591.06}{65288.90} = 0.6063 = 60.63\%\]</span></p>
<p>Interpretation: Approximately 60.63% of the variability in price is
explained by the regression model.</p>
<p><span class="math display">\[r = \pm \sqrt{r^2} = \pm \sqrt{0.6063} = \pm 0.779\]</span></p>
<p>Since <span class="math inline">\(\hat{\beta}_1 &gt; 0\)</span>, we choose the positive root:</p>
<p><span class="math display">\[r = 0.779\]</span></p>
<p>Interpretation: There is a strong positive correlation between apartment
area and price.</p>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>model = lm(y~x, data = data\_source) 
summary(model)</code></pre>
</div>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>apt\_model = lm(price ~ area, data = apt)
summary(apt\_model)</code></pre>
</div>
<p><strong>R code</strong></p>
<div class="tcolorbox">
<pre><code>Call:
lm(formula = price ~ area, data = apt)

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  422.256   74.834     5.643  0.00078 ***
area         25.690    7.823      3.284  0.01341 *

Residual standard error: 60.59 on 7 degrees of freedom
Multiple R-squared: 0.6064,    Adjusted R-squared: 0.5502 
F-statistic: 10.78 on 1 and 7 DF,  p-value: 0.01341</code></pre>
</div>
<p><strong>Two-sided Test for Slope Coefficient</strong></p>
<p>By default, R performs a two-sided test:
<span class="math display">\[H_0: \beta_1 = 0 \quad \text{vs.} \quad H_a: \beta_1 \neq 0\]</span></p>
<p>Test statistic:
<span class="math display">\[t^* = \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)} = \frac{25.690 - 0}{7.823} = 3.284\]</span></p>
<p><span class="math display">\[t^* \sim t_{(n - 2)}  \quad \text{with } df = 9 - 2 = 7\]</span></p>
<p><strong>p-value</strong> is the total shaded area in both tails. From R output:
<span class="math display">\[\text{p-value} = 0.01341\]</span></p>
</div>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-248" class="definition"><strong>Definition 32.2  </strong></span></p>
<ul>
<li><p><strong>Interpolation</strong> is calculating predicted values of <span class="math inline">\(y\)</span> using our
linear model while working within the range of <span class="math inline">\(x\)</span> in which data was
available to construct our model.</p></li>
<li><p><strong>Extrapolation</strong> is calculating predicted values of <span class="math inline">\(y\)</span> using our
linear model outside the range of <span class="math inline">\(x\)</span> used to obtain the linear model.</p></li>
<li><p>Interpolation is usually safe if we have a good linear model.</p></li>
<li><p>Extrapolation must be performed carefully since extrapolations that
are done without any foresight can be very inaccurate.</p></li>
</ul>
</div>
</div>
<div id="residual-plots-1" class="section level2 hasAnchor" number="32.3">
<h2><span class="header-section-number">32.3</span> Residual Plots<a href="inference-for-simple-linear-regression-1.html#residual-plots-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Residual plots are used to verify assumptions related to the error terms
in a regression model.</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma^2)\]</span></p>
<p>The assumption <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma^2)\)</span> implies:</p>
<ul>
<li><p>Mean of errors is 0</p></li>
<li><p>Constant variance of errors (homoscedasticity)</p></li>
</ul>
<p>We plot the residuals: <span class="math display">\[e_i = y_i - \hat{y}_i\]</span> against the fitted
values <span class="math inline">\(\hat{y}_i\)</span> to assess these assumptions.</p>
<div id="what-to-look-for-in-a-good-residual-plot" class="section level3 unnumbered hasAnchor">
<h3>What to Look for in a Good Residual Plot<a href="inference-for-simple-linear-regression.html#what-to-look-for-in-a-good-residual-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If the assumption <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma^2)\)</span> is
satisfied, the residual plot should have the following features:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Random scattering:</strong> No obvious pattern in residuals.</p>
<ul>
<li><p>A pattern (e.g., curve) may indicate a non-linear relationship.</p></li>
<li><p>Random scattering also suggests independence of errors.</p></li>
</ul></li>
<li><p><strong>Constant variance:</strong> Residuals should fall within a horizontal
band, roughly half above and half below zero.</p>
<ul>
<li>Suggests constant variance (homoscedasticity).</li>
</ul></li>
<li><p><strong>No influential points or clustering:</strong> The plot should not show
isolated influential observations or clustering.</p></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-76"></span>
<img src="_main_files/figure-html/unnamed-chunk-76-1.png" alt="Residual Plots - Good and Bad Examples" width="70%" />
<p class="caption">
Figure 32.2: Residual Plots - Good and Bad Examples
</p>
</div>
<div class="tcolorbox">
<p>The model is: <span class="math inline">\(Y = \beta_0 + \beta_1 X + \varepsilon\)</span>, where
<span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma^2)\)</span></p>
<ul>
<li><p>The relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is linear.</p></li>
<li><p>Residuals:</p>
<ul>
<li><p>are independent</p></li>
<li><p>have constant variance</p></li>
<li><p>are normally distributed</p></li>
</ul>
<p>These assumptions can be verified using residual plots.</p></li>
</ul>
</div>
<div class="center">

</div>


</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-simple-linear-regression-1.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
